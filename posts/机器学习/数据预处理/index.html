<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>数据预处理 | lu</title>
<meta name=keywords content><meta name=description content="无量纲化
归一化(Normalization)

对异常值很敏感！

将所有数据收敛到 [0, 1] 之间。归一化由中心化和缩放组成。
中心化：让所有数据减去一个固定值，让数据样本平移到某个位置。
缩放处理(Scale)：所有数据除以一个固定值，将数据固定在某个范围内（取对数也算）。
归一化公式如下：       x* = ( x - min(x) ) / ( max(x) - min(x) )
sklearn.preprocessing.MinMaxScaler 类可实现归一化操作。该函数中的feature_range参数控制我们希望把数据压缩到的范围，默认为[0, 1]。
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]
# 实现归一化
scaler = MinMaxScaler()      # 实例化
scaler = scaler.fit(data)    # fit. 在这里本质是生成Min(x)和 max(x)
result = scaler.transform(data)  # 通过接口导出结果
# 至此，已经得出归一化之后的结果，就是result。（会发现是按列归一化的）

# 下方语句将训练和导出结果一步达成，相当于上方两步一起执行，作用一样。
result = scaler.fit_transform(data)

# 下方将归一化后的结果逆转,即输入归一化之后的结果会返回没归一化的值
original_data = scaler.inverse_transform(result)     

# 归一化到其他范围
data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]
scaler = MinMaxScaler(feature_range=[5, 10])
result = scaler.fit_transform(data)

# 当X中的特征数量非常多的时候，fit会报错，表示数据量太大我计算不了
# 此时可以使用partial_fit训练，用法和 fit 一样
# scaler = scaler.partial_fit(data)
标准化(Standardization)

由于归一化对异常值很敏感，故一般使用标准化。"><meta name=author content="lu"><link rel=canonical href=https://ethereal-lu.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/><link crossorigin=anonymous href=/assets/css/stylesheet.d72444526d7ecbdb0015438a7fa89054a658bf759d0542e2e5df81ce94b493ee.css integrity="sha256-1yREUm1+y9sAFUOKf6iQVKZYv3WdBULi5d+BzpS0k+4=" rel="preload stylesheet" as=style><link rel=icon href=https://ethereal-lu.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://ethereal-lu.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://ethereal-lu.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://ethereal-lu.github.io/apple-touch-icon.png><link rel=mask-icon href=https://ethereal-lu.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://ethereal-lu.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://ethereal-lu.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/"><meta property="og:site_name" content="lu"><meta property="og:title" content="数据预处理"><meta property="og:description" content="无量纲化 归一化(Normalization) 对异常值很敏感！
将所有数据收敛到 [0, 1] 之间。归一化由中心化和缩放组成。
中心化：让所有数据减去一个固定值，让数据样本平移到某个位置。
缩放处理(Scale)：所有数据除以一个固定值，将数据固定在某个范围内（取对数也算）。
归一化公式如下： x* = ( x - min(x) ) / ( max(x) - min(x) )
sklearn.preprocessing.MinMaxScaler 类可实现归一化操作。该函数中的feature_range参数控制我们希望把数据压缩到的范围，默认为[0, 1]。
import pandas as pd from sklearn.preprocessing import MinMaxScaler data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]] # 实现归一化 scaler = MinMaxScaler() # 实例化 scaler = scaler.fit(data) # fit. 在这里本质是生成Min(x)和 max(x) result = scaler.transform(data) # 通过接口导出结果 # 至此，已经得出归一化之后的结果，就是result。（会发现是按列归一化的） # 下方语句将训练和导出结果一步达成，相当于上方两步一起执行，作用一样。 result = scaler.fit_transform(data) # 下方将归一化后的结果逆转,即输入归一化之后的结果会返回没归一化的值 original_data = scaler.inverse_transform(result) # 归一化到其他范围 data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]] scaler = MinMaxScaler(feature_range=[5, 10]) result = scaler.fit_transform(data) # 当X中的特征数量非常多的时候，fit会报错，表示数据量太大我计算不了 # 此时可以使用partial_fit训练，用法和 fit 一样 # scaler = scaler.partial_fit(data) 标准化(Standardization) 由于归一化对异常值很敏感，故一般使用标准化。"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-07-02T17:45:10+00:00"><meta property="article:modified_time" content="2021-07-02T17:45:10+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="数据预处理"><meta name=twitter:description content="无量纲化
归一化(Normalization)

对异常值很敏感！

将所有数据收敛到 [0, 1] 之间。归一化由中心化和缩放组成。
中心化：让所有数据减去一个固定值，让数据样本平移到某个位置。
缩放处理(Scale)：所有数据除以一个固定值，将数据固定在某个范围内（取对数也算）。
归一化公式如下：       x* = ( x - min(x) ) / ( max(x) - min(x) )
sklearn.preprocessing.MinMaxScaler 类可实现归一化操作。该函数中的feature_range参数控制我们希望把数据压缩到的范围，默认为[0, 1]。
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]
# 实现归一化
scaler = MinMaxScaler()      # 实例化
scaler = scaler.fit(data)    # fit. 在这里本质是生成Min(x)和 max(x)
result = scaler.transform(data)  # 通过接口导出结果
# 至此，已经得出归一化之后的结果，就是result。（会发现是按列归一化的）

# 下方语句将训练和导出结果一步达成，相当于上方两步一起执行，作用一样。
result = scaler.fit_transform(data)

# 下方将归一化后的结果逆转,即输入归一化之后的结果会返回没归一化的值
original_data = scaler.inverse_transform(result)     

# 归一化到其他范围
data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]
scaler = MinMaxScaler(feature_range=[5, 10])
result = scaler.fit_transform(data)

# 当X中的特征数量非常多的时候，fit会报错，表示数据量太大我计算不了
# 此时可以使用partial_fit训练，用法和 fit 一样
# scaler = scaler.partial_fit(data)
标准化(Standardization)

由于归一化对异常值很敏感，故一般使用标准化。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://ethereal-lu.github.io/posts/"},{"@type":"ListItem","position":2,"name":"数据预处理","item":"https://ethereal-lu.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"数据预处理","name":"数据预处理","description":"无量纲化 归一化(Normalization) 对异常值很敏感！\n将所有数据收敛到 [0, 1] 之间。归一化由中心化和缩放组成。\n中心化：让所有数据减去一个固定值，让数据样本平移到某个位置。\n缩放处理(Scale)：所有数据除以一个固定值，将数据固定在某个范围内（取对数也算）。\n归一化公式如下： x* = ( x - min(x) ) / ( max(x) - min(x) )\nsklearn.preprocessing.MinMaxScaler 类可实现归一化操作。该函数中的feature_range参数控制我们希望把数据压缩到的范围，默认为[0, 1]。\nimport pandas as pd from sklearn.preprocessing import MinMaxScaler data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]] # 实现归一化 scaler = MinMaxScaler() # 实例化 scaler = scaler.fit(data) # fit. 在这里本质是生成Min(x)和 max(x) result = scaler.transform(data) # 通过接口导出结果 # 至此，已经得出归一化之后的结果，就是result。（会发现是按列归一化的） # 下方语句将训练和导出结果一步达成，相当于上方两步一起执行，作用一样。 result = scaler.fit_transform(data) # 下方将归一化后的结果逆转,即输入归一化之后的结果会返回没归一化的值 original_data = scaler.inverse_transform(result) # 归一化到其他范围 data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]] scaler = MinMaxScaler(feature_range=[5, 10]) result = scaler.fit_transform(data) # 当X中的特征数量非常多的时候，fit会报错，表示数据量太大我计算不了 # 此时可以使用partial_fit训练，用法和 fit 一样 # scaler = scaler.partial_fit(data) 标准化(Standardization) 由于归一化对异常值很敏感，故一般使用标准化。\n","keywords":[],"articleBody":"无量纲化 归一化(Normalization) 对异常值很敏感！\n将所有数据收敛到 [0, 1] 之间。归一化由中心化和缩放组成。\n中心化：让所有数据减去一个固定值，让数据样本平移到某个位置。\n缩放处理(Scale)：所有数据除以一个固定值，将数据固定在某个范围内（取对数也算）。\n归一化公式如下： x* = ( x - min(x) ) / ( max(x) - min(x) )\nsklearn.preprocessing.MinMaxScaler 类可实现归一化操作。该函数中的feature_range参数控制我们希望把数据压缩到的范围，默认为[0, 1]。\nimport pandas as pd from sklearn.preprocessing import MinMaxScaler data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]] # 实现归一化 scaler = MinMaxScaler() # 实例化 scaler = scaler.fit(data) # fit. 在这里本质是生成Min(x)和 max(x) result = scaler.transform(data) # 通过接口导出结果 # 至此，已经得出归一化之后的结果，就是result。（会发现是按列归一化的） # 下方语句将训练和导出结果一步达成，相当于上方两步一起执行，作用一样。 result = scaler.fit_transform(data) # 下方将归一化后的结果逆转,即输入归一化之后的结果会返回没归一化的值 original_data = scaler.inverse_transform(result) # 归一化到其他范围 data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]] scaler = MinMaxScaler(feature_range=[5, 10]) result = scaler.fit_transform(data) # 当X中的特征数量非常多的时候，fit会报错，表示数据量太大我计算不了 # 此时可以使用partial_fit训练，用法和 fit 一样 # scaler = scaler.partial_fit(data) 标准化(Standardization) 由于归一化对异常值很敏感，故一般使用标准化。\n数据按照均值中心化，再按照标准差缩放，就会服从(0，1)正态分布。此过程即为数据标准化。\n公式： x* = (x - μ) / σ\nsklearn.preprocessing.StandardScaler 类可实现标准化操作。\nfrom sklearn.preprocessing import StandardScaler data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]] scaler = StandardScaler() # 实例化 scaler.fit(data) # fit. 在这里本质是生成均值和方差 scaler.mean_ # 查看均值 scaler.var_ # 查看方差 result = scaler.transform(data) # 导出结果 # 至此，已经得出标准化之后的结果，就是result。 result.mean() # 查看标准化之后的均值，为0 result.std() # 为1 result = scaler.fit_transform(data) # 一步到位 original_data = scaler.inverse_transform(result) # 两极反转 填补缺失值 sklearn.impute.SimpleImputer class sklearn.impute.SimpleImputer(*, missing_values=nan, strategy='mean', fill_value=None, verbose=0, copy=True, add_indicator=False) # 参数解释 # missing_values：缺失值的占位符。即缺失值长啥样，默认为np.nan # strategy：填补策略。 #\t- 如果是“mean”，则使用每列中的平均值替换缺失值。只能与数字数据一起使用。 #\t- 如果为“median”，则使用每列中的中位数替换缺失值。只能与数字数据一起使用。 #\t- 如果为“ most_frequent”，则使用每一列中的众数替换缺失值。字符串或数字 #\t- 如果为“constant”，则将缺失的值替换为fill_value。字符串或数字 # fill_value：当strategy ==“ constant”时，fill_value用于替换所有缺失值。 # copy：如果为True，将创建X的副本。如果为False，对原数据修改。 示例\nage = data.iloc[:, 0].values.reshape(-1, 1) # 将数值型数据转为2维 imp = SimpleImputer() # 实例化 result = imp.fit_transform(age) # 一步到位 pandas.DataFrame.fillna （ 更简单，感觉这个好）。当有缺失值的行很少时，可直接删除，用 dropna()。\ndata.loc[:, 'Age'] = data.loc[:, 'Age'].fillna(data.loc[:, 'Age'].median()) 处理离散型特征：编码与哑变量 普通编码 普通编码将变量 编码为 0，1，2，3 等等。\n# 标签编码 from sklearn.preprocessing import LabelEncoder # 下方为链式编程，先实例化 LabelEncoder 类，再用fit_transform方法将标签列编码，并替换原标签列。 data.iloc[:, -1] = LabelEncoder().fit_transform(data.iloc[:, -1]) LabelEncoder().fit(data.iloc[:, -1]).classes_ # 获取原标签列有哪些标签 # 特征编码 from sklearn.preprocessing import OrdinalEncoder # 这里数据为 DataFrame 格式，第一列为 index， 最后一列为 标签 data.iloc[:, 1: -1] = OrdinalEncoder().fit_transform(data.iloc[:, 1: -1]) OrdinalEncoder().fit(data.iloc[:, 1: -1]).categories_ # 获取原数据有哪些特征 哑变量 哑变量即 One-Hot 编码，当类别为名义变量，即变量之间相互独立不具备任何数学可计算性时，若使用普通编码为0，1，2 ，则会向算法传递一种可以可以通过计算转换的误导性。此时应该使用 One-Hot 编码。\nclass sklearn.preprocessing.OneHotEncoder(*, categories='auto', drop=None, sparse=True, dtype=\u003cclass 'numpy.float64'\u003e, handle_unknown='error') from sklearn.preprocessing import OneHotEncoder # categories='auto' 可以不用写，为默认。表示自动查看共有多少种类别并建立相应的 One-Hot 编码。 # 这行代码会生成一个numpy矩阵，列数为所有特征总类别的数量。 result = OneHotEncoder(categories='auto').fit_transform(data.iloc[:, 1: -1]).toarray() # 这行代码返回上述生成的矩阵中的每一列分别对应那个类别。只是起辅助查看作用。 OneHotEncoder(categories='auto').fit(data.iloc[:, 1: -1]).get_feature_names() # 将原数据与编码结果合并作为新数据。 axis=0为上下合并，axis=1为左右合并。 newdata = pd.concat([data, pd.DataFrame(result)], axis=1) newdata.drop(['Sex', 'Embarked'], axis=1, inplace=True) # 删除编码前的列 newdata.columns = [\"Age\", \"Survived\", 'female', 'male', 'Embarked_C', 'Embarked_S'] # 改列名 # Over Perfect！ 标签也可以做哑变量，但是不常见，因为分类算法知道标签不同即表示不同的类别，不会有 经过运算得以转换标签 这种误解，故无需变为哑变量。普通编码即可。\n处理连续性特征：二值化与分段 二值化 将连续型变量根据阈值划分为 0 或 1 就叫二值化。\nfrom sklearn.preprocessing import Binarizer # 该类专用于处理特征，故不能传递一维数组 X = data.iloc[:, 0].values.reshape(-1, 1) data.iloc[:, 0] = Binarizer(threshold=30).fit_transform(X) # 二值化并取代。大于30为1，否则为0 分段 将连续型变量排序后按顺序分段编码\n# 该类专用于处理特征，故不能传递一维数组 class sklearn.preprocessing.KBinsDiscretizer(n_bins=5, *, encode='onehot', strategy='quantile', dtype=None) # n_bins：分段后的段数 # encode：编码方式，默认为 onehot，返回值与 OneHotEncoder().fit_transform() 一样 # ordinal，返回值与 OrdinalEncoder().fit_transform() 一样 # strategy：定义段的宽度。uniform：等宽分段，即若数据在[1, 100]，则分为[0, 20],[20, 40],[40, 60]... # quantile：等位分段，所有段中样本数量相等，默认。 # kmeans：按聚类分段。 from sklearn.preprocessing import KBinsDiscretizer X = data.iloc[:, 0].values.reshape(-1, 1) result = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='quantile').fit_transform(X) ","wordCount":"417","inLanguage":"en","datePublished":"2021-07-02T17:45:10Z","dateModified":"2021-07-02T17:45:10Z","author":{"@type":"Person","name":"lu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://ethereal-lu.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/"},"publisher":{"@type":"Organization","name":"lu","logo":{"@type":"ImageObject","url":"https://ethereal-lu.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://ethereal-lu.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://ethereal-lu.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://ethereal-lu.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://ethereal-lu.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://ethereal-lu.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://ethereal-lu.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">数据预处理</h1><div class=post-meta><span title='2021-07-02 17:45:10 +0000 UTC'>2021-07-02</span>&nbsp;·&nbsp;417 words&nbsp;·&nbsp;lu</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#无量纲化>无量纲化</a><ul><li></li></ul></li><li><a href=#填补缺失值>填补缺失值</a><ul><li></li></ul></li><li><a href=#处理离散型特征编码与哑变量>处理离散型特征：编码与哑变量</a><ul><li></li></ul></li><li><a href=#处理连续性特征二值化与分段>处理连续性特征：二值化与分段</a><ul><li></li></ul></li></ul></nav></div></details></div><div class=post-content><h2 id=无量纲化>无量纲化<a hidden class=anchor aria-hidden=true href=#无量纲化>#</a></h2><h4 id=归一化normalization>归一化(Normalization)<a hidden class=anchor aria-hidden=true href=#归一化normalization>#</a></h4><blockquote><p>对异常值很敏感！</p></blockquote><p>将所有数据收敛到 [0, 1] 之间。归一化由中心化和缩放组成。</p><p><strong>中心化</strong>：让所有数据减去一个固定值，让数据样本平移到某个位置。</p><p><strong>缩放处理(Scale)</strong>：所有数据除以一个固定值，将数据固定在某个范围内（取对数也算）。</p><p>归一化公式如下： x* = ( x - min(x) ) / ( max(x) - min(x) )</p><p><strong>sklearn.preprocessing.MinMaxScaler</strong> 类可实现归一化操作。该函数中的<code>feature_range</code>参数控制我们希望把数据压缩到的范围，默认为[0, 1]。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> MinMaxScaler
</span></span><span style=display:flex><span>data <span style=color:#f92672>=</span> [[<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>], [<span style=color:#f92672>-</span><span style=color:#ae81ff>0.5</span>, <span style=color:#ae81ff>6</span>], [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>10</span>], [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>18</span>]]
</span></span><span style=display:flex><span><span style=color:#75715e># 实现归一化</span>
</span></span><span style=display:flex><span>scaler <span style=color:#f92672>=</span> MinMaxScaler()      <span style=color:#75715e># 实例化</span>
</span></span><span style=display:flex><span>scaler <span style=color:#f92672>=</span> scaler<span style=color:#f92672>.</span>fit(data)    <span style=color:#75715e># fit. 在这里本质是生成Min(x)和 max(x)</span>
</span></span><span style=display:flex><span>result <span style=color:#f92672>=</span> scaler<span style=color:#f92672>.</span>transform(data)  <span style=color:#75715e># 通过接口导出结果</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 至此，已经得出归一化之后的结果，就是result。（会发现是按列归一化的）</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 下方语句将训练和导出结果一步达成，相当于上方两步一起执行，作用一样。</span>
</span></span><span style=display:flex><span>result <span style=color:#f92672>=</span> scaler<span style=color:#f92672>.</span>fit_transform(data)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 下方将归一化后的结果逆转,即输入归一化之后的结果会返回没归一化的值</span>
</span></span><span style=display:flex><span>original_data <span style=color:#f92672>=</span> scaler<span style=color:#f92672>.</span>inverse_transform(result)     
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 归一化到其他范围</span>
</span></span><span style=display:flex><span>data <span style=color:#f92672>=</span> [[<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>], [<span style=color:#f92672>-</span><span style=color:#ae81ff>0.5</span>, <span style=color:#ae81ff>6</span>], [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>10</span>], [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>18</span>]]
</span></span><span style=display:flex><span>scaler <span style=color:#f92672>=</span> MinMaxScaler(feature_range<span style=color:#f92672>=</span>[<span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>10</span>])
</span></span><span style=display:flex><span>result <span style=color:#f92672>=</span> scaler<span style=color:#f92672>.</span>fit_transform(data)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 当X中的特征数量非常多的时候，fit会报错，表示数据量太大我计算不了</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 此时可以使用partial_fit训练，用法和 fit 一样</span>
</span></span><span style=display:flex><span><span style=color:#75715e># scaler = scaler.partial_fit(data)</span>
</span></span></code></pre></div><h4 id=标准化standardization>标准化(Standardization)<a hidden class=anchor aria-hidden=true href=#标准化standardization>#</a></h4><blockquote><p>由于归一化对异常值很敏感，故一般使用标准化。</p></blockquote><p>数据按照均值中心化，再按照标准差缩放，就会服从(0，1)正态分布。此过程即为数据标准化。</p><p>公式： x* = (x - μ) / σ</p><p><strong>sklearn.preprocessing.StandardScaler</strong> 类可实现标准化操作。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> StandardScaler
</span></span><span style=display:flex><span>data <span style=color:#f92672>=</span> [[<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>], [<span style=color:#f92672>-</span><span style=color:#ae81ff>0.5</span>, <span style=color:#ae81ff>6</span>], [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>10</span>], [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>18</span>]]
</span></span><span style=display:flex><span>scaler <span style=color:#f92672>=</span> StandardScaler()     <span style=color:#75715e># 实例化</span>
</span></span><span style=display:flex><span>scaler<span style=color:#f92672>.</span>fit(data)              <span style=color:#75715e># fit. 在这里本质是生成均值和方差</span>
</span></span><span style=display:flex><span>scaler<span style=color:#f92672>.</span>mean_                  <span style=color:#75715e># 查看均值</span>
</span></span><span style=display:flex><span>scaler<span style=color:#f92672>.</span>var_                   <span style=color:#75715e># 查看方差</span>
</span></span><span style=display:flex><span>result <span style=color:#f92672>=</span> scaler<span style=color:#f92672>.</span>transform(data) <span style=color:#75715e># 导出结果</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 至此，已经得出标准化之后的结果，就是result。</span>
</span></span><span style=display:flex><span>result<span style=color:#f92672>.</span>mean()                  <span style=color:#75715e># 查看标准化之后的均值，为0</span>
</span></span><span style=display:flex><span>result<span style=color:#f92672>.</span>std()                   <span style=color:#75715e># 为1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>result <span style=color:#f92672>=</span> scaler<span style=color:#f92672>.</span>fit_transform(data)  <span style=color:#75715e># 一步到位</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>original_data <span style=color:#f92672>=</span> scaler<span style=color:#f92672>.</span>inverse_transform(result)  <span style=color:#75715e># 两极反转</span>
</span></span></code></pre></div><h2 id=填补缺失值>填补缺失值<a hidden class=anchor aria-hidden=true href=#填补缺失值>#</a></h2><h4 id=sklearnimputesimpleimputer>sklearn.impute.SimpleImputer<a hidden class=anchor aria-hidden=true href=#sklearnimputesimpleimputer>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>sklearn</span><span style=color:#f92672>.</span>impute<span style=color:#f92672>.</span>SimpleImputer(<span style=color:#f92672>*</span>, missing_values<span style=color:#f92672>=</span>nan, strategy<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;mean&#39;</span>,
</span></span><span style=display:flex><span>fill_value<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>, verbose<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, copy<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, add_indicator<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span><span style=color:#75715e># 参数解释</span>
</span></span><span style=display:flex><span><span style=color:#75715e># missing_values：缺失值的占位符。即缺失值长啥样，默认为np.nan</span>
</span></span><span style=display:flex><span><span style=color:#75715e># strategy：填补策略。</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#	- 如果是“mean”，则使用每列中的平均值替换缺失值。只能与数字数据一起使用。</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#	- 如果为“median”，则使用每列中的中位数替换缺失值。只能与数字数据一起使用。</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#	- 如果为“ most_frequent”，则使用每一列中的众数替换缺失值。字符串或数字</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#	- 如果为“constant”，则将缺失的值替换为fill_value。字符串或数字</span>
</span></span><span style=display:flex><span><span style=color:#75715e># fill_value：当strategy ==“ constant”时，fill_value用于替换所有缺失值。</span>
</span></span><span style=display:flex><span><span style=color:#75715e># copy：如果为True，将创建X的副本。如果为False，对原数据修改。</span>
</span></span></code></pre></div><p>示例</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>age <span style=color:#f92672>=</span> data<span style=color:#f92672>.</span>iloc[:, <span style=color:#ae81ff>0</span>]<span style=color:#f92672>.</span>values<span style=color:#f92672>.</span>reshape(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>)   <span style=color:#75715e># 将数值型数据转为2维</span>
</span></span><span style=display:flex><span>imp <span style=color:#f92672>=</span> SimpleImputer()                         <span style=color:#75715e># 实例化</span>
</span></span><span style=display:flex><span>result <span style=color:#f92672>=</span> imp<span style=color:#f92672>.</span>fit_transform(age)               <span style=color:#75715e># 一步到位</span>
</span></span></code></pre></div><h4 id=pandasdataframefillna>pandas.DataFrame.fillna<a hidden class=anchor aria-hidden=true href=#pandasdataframefillna>#</a></h4><blockquote><p>（ 更简单，感觉这个好）。当有缺失值的行很少时，可直接删除，用 dropna()。</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>data<span style=color:#f92672>.</span>loc[:, <span style=color:#e6db74>&#39;Age&#39;</span>] <span style=color:#f92672>=</span> data<span style=color:#f92672>.</span>loc[:, <span style=color:#e6db74>&#39;Age&#39;</span>]<span style=color:#f92672>.</span>fillna(data<span style=color:#f92672>.</span>loc[:, <span style=color:#e6db74>&#39;Age&#39;</span>]<span style=color:#f92672>.</span>median())
</span></span></code></pre></div><h2 id=处理离散型特征编码与哑变量>处理离散型特征：编码与哑变量<a hidden class=anchor aria-hidden=true href=#处理离散型特征编码与哑变量>#</a></h2><h4 id=普通编码>普通编码<a hidden class=anchor aria-hidden=true href=#普通编码>#</a></h4><p>普通编码将变量 编码为 0，1，2，3 等等。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 标签编码</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> LabelEncoder
</span></span><span style=display:flex><span><span style=color:#75715e># 下方为链式编程，先实例化 LabelEncoder 类，再用fit_transform方法将标签列编码，并替换原标签列。</span>
</span></span><span style=display:flex><span>data<span style=color:#f92672>.</span>iloc[:, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>] <span style=color:#f92672>=</span> LabelEncoder()<span style=color:#f92672>.</span>fit_transform(data<span style=color:#f92672>.</span>iloc[:, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>])
</span></span><span style=display:flex><span>LabelEncoder()<span style=color:#f92672>.</span>fit(data<span style=color:#f92672>.</span>iloc[:, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>])<span style=color:#f92672>.</span>classes_   <span style=color:#75715e># 获取原标签列有哪些标签</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 特征编码</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> OrdinalEncoder
</span></span><span style=display:flex><span><span style=color:#75715e># 这里数据为 DataFrame 格式，第一列为 index， 最后一列为 标签</span>
</span></span><span style=display:flex><span>data<span style=color:#f92672>.</span>iloc[:, <span style=color:#ae81ff>1</span>: <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>] <span style=color:#f92672>=</span> OrdinalEncoder()<span style=color:#f92672>.</span>fit_transform(data<span style=color:#f92672>.</span>iloc[:, <span style=color:#ae81ff>1</span>: <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>])
</span></span><span style=display:flex><span>OrdinalEncoder()<span style=color:#f92672>.</span>fit(data<span style=color:#f92672>.</span>iloc[:, <span style=color:#ae81ff>1</span>: <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>])<span style=color:#f92672>.</span>categories_   <span style=color:#75715e># 获取原数据有哪些特征</span>
</span></span></code></pre></div><h4 id=哑变量>哑变量<a hidden class=anchor aria-hidden=true href=#哑变量>#</a></h4><p>哑变量即 One-Hot 编码，当类别为名义变量，即变量之间相互独立不具备任何数学可计算性时，若使用普通编码为0，1，2 ，则会向算法传递一种可以可以通过计算转换的误导性。此时应该使用 One-Hot 编码。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>sklearn</span><span style=color:#f92672>.</span>preprocessing<span style=color:#f92672>.</span>OneHotEncoder(<span style=color:#f92672>*</span>, categories<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;auto&#39;</span>, drop<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>, sparse<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, 
</span></span><span style=display:flex><span>									   dtype<span style=color:#f92672>=&lt;</span><span style=color:#66d9ef>class</span> <span style=color:#960050;background-color:#1e0010>&#39;</span><span style=color:#a6e22e>numpy</span><span style=color:#f92672>.</span>float64<span style=color:#e6db74>&#39;&gt;, handle_unknown=&#39;</span>error<span style=color:#e6db74>&#39;)</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> OneHotEncoder
</span></span><span style=display:flex><span><span style=color:#75715e># categories=&#39;auto&#39;  可以不用写，为默认。表示自动查看共有多少种类别并建立相应的 One-Hot 编码。</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 这行代码会生成一个numpy矩阵，列数为所有特征总类别的数量。</span>
</span></span><span style=display:flex><span>result <span style=color:#f92672>=</span> OneHotEncoder(categories<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;auto&#39;</span>)<span style=color:#f92672>.</span>fit_transform(data<span style=color:#f92672>.</span>iloc[:, <span style=color:#ae81ff>1</span>: <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>])<span style=color:#f92672>.</span>toarray()
</span></span><span style=display:flex><span><span style=color:#75715e># 这行代码返回上述生成的矩阵中的每一列分别对应那个类别。只是起辅助查看作用。</span>
</span></span><span style=display:flex><span>OneHotEncoder(categories<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;auto&#39;</span>)<span style=color:#f92672>.</span>fit(data<span style=color:#f92672>.</span>iloc[:, <span style=color:#ae81ff>1</span>: <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>])<span style=color:#f92672>.</span>get_feature_names()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 将原数据与编码结果合并作为新数据。 axis=0为上下合并，axis=1为左右合并。</span>
</span></span><span style=display:flex><span>newdata <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>concat([data, pd<span style=color:#f92672>.</span>DataFrame(result)], axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>newdata<span style=color:#f92672>.</span>drop([<span style=color:#e6db74>&#39;Sex&#39;</span>, <span style=color:#e6db74>&#39;Embarked&#39;</span>], axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)  <span style=color:#75715e># 删除编码前的列</span>
</span></span><span style=display:flex><span>newdata<span style=color:#f92672>.</span>columns <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#34;Age&#34;</span>, <span style=color:#e6db74>&#34;Survived&#34;</span>, <span style=color:#e6db74>&#39;female&#39;</span>, <span style=color:#e6db74>&#39;male&#39;</span>, <span style=color:#e6db74>&#39;Embarked_C&#39;</span>, <span style=color:#e6db74>&#39;Embarked_S&#39;</span>] <span style=color:#75715e># 改列名</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Over Perfect！</span>
</span></span></code></pre></div><p>标签也可以做哑变量，但是<strong>不常见</strong>，因为分类算法知道标签不同即表示不同的类别，不会有 经过运算得以转换标签 这种误解，故无需变为哑变量。普通编码即可。</p><h2 id=处理连续性特征二值化与分段>处理连续性特征：二值化与分段<a hidden class=anchor aria-hidden=true href=#处理连续性特征二值化与分段>#</a></h2><h4 id=二值化>二值化<a hidden class=anchor aria-hidden=true href=#二值化>#</a></h4><p>将连续型变量根据阈值划分为 0 或 1 就叫二值化。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> Binarizer  <span style=color:#75715e># 该类专用于处理特征，故不能传递一维数组</span>
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> data<span style=color:#f92672>.</span>iloc[:, <span style=color:#ae81ff>0</span>]<span style=color:#f92672>.</span>values<span style=color:#f92672>.</span>reshape(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>data<span style=color:#f92672>.</span>iloc[:, <span style=color:#ae81ff>0</span>] <span style=color:#f92672>=</span> Binarizer(threshold<span style=color:#f92672>=</span><span style=color:#ae81ff>30</span>)<span style=color:#f92672>.</span>fit_transform(X)  <span style=color:#75715e># 二值化并取代。大于30为1，否则为0</span>
</span></span></code></pre></div><h4 id=分段>分段<a hidden class=anchor aria-hidden=true href=#分段>#</a></h4><p>将连续型变量排序后按顺序分段编码</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 该类专用于处理特征，故不能传递一维数组</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>sklearn</span><span style=color:#f92672>.</span>preprocessing<span style=color:#f92672>.</span>KBinsDiscretizer(n_bins<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>, <span style=color:#f92672>*</span>, encode<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;onehot&#39;</span>, 
</span></span><span style=display:flex><span>										 strategy<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;quantile&#39;</span>, dtype<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>)
</span></span><span style=display:flex><span><span style=color:#75715e># n_bins：分段后的段数</span>
</span></span><span style=display:flex><span><span style=color:#75715e># encode：编码方式，默认为 onehot，返回值与 OneHotEncoder().fit_transform() 一样</span>
</span></span><span style=display:flex><span>                        <span style=color:#75715e># ordinal，返回值与 OrdinalEncoder().fit_transform() 一样</span>
</span></span><span style=display:flex><span><span style=color:#75715e># strategy：定义段的宽度。uniform：等宽分段，即若数据在[1, 100]，则分为[0, 20],[20, 40],[40, 60]...</span>
</span></span><span style=display:flex><span>                       <span style=color:#75715e># quantile：等位分段，所有段中样本数量相等，默认。</span>
</span></span><span style=display:flex><span>                       <span style=color:#75715e># kmeans：按聚类分段。</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> KBinsDiscretizer
</span></span><span style=display:flex><span>X <span style=color:#f92672>=</span> data<span style=color:#f92672>.</span>iloc[:, <span style=color:#ae81ff>0</span>]<span style=color:#f92672>.</span>values<span style=color:#f92672>.</span>reshape(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>result <span style=color:#f92672>=</span> KBinsDiscretizer(n_bins<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, encode<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;ordinal&#39;</span>, strategy<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;quantile&#39;</span>)<span style=color:#f92672>.</span>fit_transform(X)
</span></span></code></pre></div></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://ethereal-lu.github.io/posts/java/jvm%E7%AC%94%E8%AE%B0/><span class=title>« Prev</span><br><span>JVM学习笔记</span>
</a><a class=next href=https://ethereal-lu.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/matplotlib%E5%AD%A6%E4%B9%A0/><span class=title>Next »</span><br><span>Matplotlib笔记</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://ethereal-lu.github.io/>lu</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>