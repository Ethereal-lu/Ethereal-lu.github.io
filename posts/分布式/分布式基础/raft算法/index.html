<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Raft算法 | lu</title>
<meta name=keywords content><meta name=description content="一、 概述
分布式一致性算法Raft将一致性分解为多个子问题：Leader选举、日志同步、安全性、日志压缩、成员变更等。
Raft将系统中的角色分为领导者（Leader）、跟从者（Follower）和候选人（Candidate）：

Leader：接受客户端请求，并向Follower同步请求日志，当日志同步到大多数节点上后告诉Follower提交日志。
Follower：接受并持久化Leader同步的日志，在Leader告之日志可以提交之后，提交日志。
Candidate：Leader选举过程中的临时角色。

Raft要求系统在任意时刻最多只有一个Leader，正常工作期间只有Leader和Followers。
只有 Leader 节点能够处理客户端的一切请求（如果客户端的请求发到了 Follower，Follower 将会把请求重定向到 Leader）。Raft算法将时间分为一个个的任期（term），每一个term的开始都是Leader选举。在成功选举Leader之后，Leader会在整个term内管理整个集群。如果Leader选举失败，该term就会因为没有Leader而结束。

二、Leader选举
Raft 使用心跳（heartbeat）触发Leader选举。Leader向所有Followers周期性发送heartbeat。如果Follower在超时时间内没有收到Leader的heartbeat（也许此时还没有选出Leader，大家都在等；也许Leader挂了；也许只是Leader与该Follower之间网络故障），就会随机睡眠一段时间后发起Leader选举。
当服务器启动时，初始化为Follower，此时可能是集群刚启动，那么所有节点全部等待leader的心跳，当某个或某些节点超时后变为Candidate发起选举；也可能是新节点加入集群，那它会直接收到leader的心跳。
不论外部环境如何，只要一个节点在超时时间内没有收到Leader的心跳，那它就会发起选举。也即选举时只有一个或几个节点会成为Candidate，并不是所有节点都成为Candidate。
Follower按如下规则投票：

每个 term 只能投一票
只能给 term 和 logindex 不低于自己的 Candidate 投票

注意：只有Candidate会给自己投票，Follower不能给自己投票，Follower按上方规则给自己收到的第一个投票请求投票。醒的最早的Candidate最有可能成为Leader。
Follower将其当前term加一然后转换为Candidate。它首先给自己投票并且给集群中的其他服务器发送 RequestVote RPC。结果有以下三种情况：

赢得了多数的选票，成功选举为Leader；
收到了Leader的消息，表示有其它服务器已经抢先当选了Leader；
没有服务器赢得多数的选票，Leader选举失败，等待选举时间超时后发起下一次选举。

选举出Leader后，Leader通过定期向所有Followers发送心跳信息维持其统治。若Follower一段时间未收到Leader的心跳则认为Leader可能已经挂了，再次发起Leader选举过程。
Raft保证选举出的Leader上一定具有最新的已提交的日志，这一点将在四、安全性中说明。
三、日志同步
Leader选出后，就开始接收客户端的请求。Leader把请求作为日志条目（Log entries）加入到它的日志中，然后并行的向其他服务器发起 AppendEntries RPC 复制日志条目。当这条日志被复制到大多数服务器上，Leader将这条日志应用到它的状态机并向客户端返回执行结果。

某些Followers可能没有成功的复制日志，Leader会无限的重试 AppendEntries RPC直到所有的Followers最终存储了所有的日志条目。
日志由有序编号（log index，索引）的日志条目组成。每个日志条目包含它被创建时的任期号（term），和用于状态机执行的命令。如果一个日志条目被复制到大多数服务器上，就被认为可以提交（commit）了。log index 与 term 无关，Leader 每生成一条日志条目都会消耗一个 log index ，log index 只会一直递增。
Raft日志同步保证如下两点：

如果不同日志中的两个条目有着相同的索引和任期号，则它们所存储的命令是相同的。
如果不同日志中的两个条目有着相同的索引和任期号，则它们之前的所有条目都是完全一样的。

第一条特性源于Leader在一个term内在给定的一个log index最多创建一条日志条目，同时该条目在日志中的位置也从来不会改变。
第二条特性源于 AppendEntries 的一个简单的一致性检查。当发送一个 AppendEntries RPC 时，Leader会把新日志条目紧接着之前的条目的log index和term都包含在里面。如果Follower没有在它的日志中找到log index和term都相同的日志，它就会拒绝新的日志条目。"><meta name=author content="lu"><link rel=canonical href=https://ethereal-lu.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%9F%BA%E7%A1%80/raft%E7%AE%97%E6%B3%95/><link crossorigin=anonymous href=/assets/css/stylesheet.d72444526d7ecbdb0015438a7fa89054a658bf759d0542e2e5df81ce94b493ee.css integrity="sha256-1yREUm1+y9sAFUOKf6iQVKZYv3WdBULi5d+BzpS0k+4=" rel="preload stylesheet" as=style><link rel=icon href=https://ethereal-lu.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://ethereal-lu.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://ethereal-lu.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://ethereal-lu.github.io/apple-touch-icon.png><link rel=mask-icon href=https://ethereal-lu.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://ethereal-lu.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%9F%BA%E7%A1%80/raft%E7%AE%97%E6%B3%95/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://ethereal-lu.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%9F%BA%E7%A1%80/raft%E7%AE%97%E6%B3%95/"><meta property="og:site_name" content="lu"><meta property="og:title" content="Raft算法"><meta property="og:description" content="一、 概述 分布式一致性算法Raft将一致性分解为多个子问题：Leader选举、日志同步、安全性、日志压缩、成员变更等。
Raft将系统中的角色分为领导者（Leader）、跟从者（Follower）和候选人（Candidate）：
Leader：接受客户端请求，并向Follower同步请求日志，当日志同步到大多数节点上后告诉Follower提交日志。 Follower：接受并持久化Leader同步的日志，在Leader告之日志可以提交之后，提交日志。 Candidate：Leader选举过程中的临时角色。 Raft要求系统在任意时刻最多只有一个Leader，正常工作期间只有Leader和Followers。
只有 Leader 节点能够处理客户端的一切请求（如果客户端的请求发到了 Follower，Follower 将会把请求重定向到 Leader）。Raft算法将时间分为一个个的任期（term），每一个term的开始都是Leader选举。在成功选举Leader之后，Leader会在整个term内管理整个集群。如果Leader选举失败，该term就会因为没有Leader而结束。
二、Leader选举 Raft 使用心跳（heartbeat）触发Leader选举。Leader向所有Followers周期性发送heartbeat。如果Follower在超时时间内没有收到Leader的heartbeat（也许此时还没有选出Leader，大家都在等；也许Leader挂了；也许只是Leader与该Follower之间网络故障），就会随机睡眠一段时间后发起Leader选举。
当服务器启动时，初始化为Follower，此时可能是集群刚启动，那么所有节点全部等待leader的心跳，当某个或某些节点超时后变为Candidate发起选举；也可能是新节点加入集群，那它会直接收到leader的心跳。
不论外部环境如何，只要一个节点在超时时间内没有收到Leader的心跳，那它就会发起选举。也即选举时只有一个或几个节点会成为Candidate，并不是所有节点都成为Candidate。
Follower按如下规则投票：
每个 term 只能投一票 只能给 term 和 logindex 不低于自己的 Candidate 投票 注意：只有Candidate会给自己投票，Follower不能给自己投票，Follower按上方规则给自己收到的第一个投票请求投票。醒的最早的Candidate最有可能成为Leader。
Follower将其当前term加一然后转换为Candidate。它首先给自己投票并且给集群中的其他服务器发送 RequestVote RPC。结果有以下三种情况：
赢得了多数的选票，成功选举为Leader； 收到了Leader的消息，表示有其它服务器已经抢先当选了Leader； 没有服务器赢得多数的选票，Leader选举失败，等待选举时间超时后发起下一次选举。 选举出Leader后，Leader通过定期向所有Followers发送心跳信息维持其统治。若Follower一段时间未收到Leader的心跳则认为Leader可能已经挂了，再次发起Leader选举过程。
Raft保证选举出的Leader上一定具有最新的已提交的日志，这一点将在四、安全性中说明。
三、日志同步 Leader选出后，就开始接收客户端的请求。Leader把请求作为日志条目（Log entries）加入到它的日志中，然后并行的向其他服务器发起 AppendEntries RPC 复制日志条目。当这条日志被复制到大多数服务器上，Leader将这条日志应用到它的状态机并向客户端返回执行结果。
某些Followers可能没有成功的复制日志，Leader会无限的重试 AppendEntries RPC直到所有的Followers最终存储了所有的日志条目。
日志由有序编号（log index，索引）的日志条目组成。每个日志条目包含它被创建时的任期号（term），和用于状态机执行的命令。如果一个日志条目被复制到大多数服务器上，就被认为可以提交（commit）了。log index 与 term 无关，Leader 每生成一条日志条目都会消耗一个 log index ，log index 只会一直递增。
Raft日志同步保证如下两点：
如果不同日志中的两个条目有着相同的索引和任期号，则它们所存储的命令是相同的。 如果不同日志中的两个条目有着相同的索引和任期号，则它们之前的所有条目都是完全一样的。 第一条特性源于Leader在一个term内在给定的一个log index最多创建一条日志条目，同时该条目在日志中的位置也从来不会改变。
第二条特性源于 AppendEntries 的一个简单的一致性检查。当发送一个 AppendEntries RPC 时，Leader会把新日志条目紧接着之前的条目的log index和term都包含在里面。如果Follower没有在它的日志中找到log index和term都相同的日志，它就会拒绝新的日志条目。"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-08-11T13:42:15+00:00"><meta property="article:modified_time" content="2022-08-11T13:42:15+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Raft算法"><meta name=twitter:description content="一、 概述
分布式一致性算法Raft将一致性分解为多个子问题：Leader选举、日志同步、安全性、日志压缩、成员变更等。
Raft将系统中的角色分为领导者（Leader）、跟从者（Follower）和候选人（Candidate）：

Leader：接受客户端请求，并向Follower同步请求日志，当日志同步到大多数节点上后告诉Follower提交日志。
Follower：接受并持久化Leader同步的日志，在Leader告之日志可以提交之后，提交日志。
Candidate：Leader选举过程中的临时角色。

Raft要求系统在任意时刻最多只有一个Leader，正常工作期间只有Leader和Followers。
只有 Leader 节点能够处理客户端的一切请求（如果客户端的请求发到了 Follower，Follower 将会把请求重定向到 Leader）。Raft算法将时间分为一个个的任期（term），每一个term的开始都是Leader选举。在成功选举Leader之后，Leader会在整个term内管理整个集群。如果Leader选举失败，该term就会因为没有Leader而结束。

二、Leader选举
Raft 使用心跳（heartbeat）触发Leader选举。Leader向所有Followers周期性发送heartbeat。如果Follower在超时时间内没有收到Leader的heartbeat（也许此时还没有选出Leader，大家都在等；也许Leader挂了；也许只是Leader与该Follower之间网络故障），就会随机睡眠一段时间后发起Leader选举。
当服务器启动时，初始化为Follower，此时可能是集群刚启动，那么所有节点全部等待leader的心跳，当某个或某些节点超时后变为Candidate发起选举；也可能是新节点加入集群，那它会直接收到leader的心跳。
不论外部环境如何，只要一个节点在超时时间内没有收到Leader的心跳，那它就会发起选举。也即选举时只有一个或几个节点会成为Candidate，并不是所有节点都成为Candidate。
Follower按如下规则投票：

每个 term 只能投一票
只能给 term 和 logindex 不低于自己的 Candidate 投票

注意：只有Candidate会给自己投票，Follower不能给自己投票，Follower按上方规则给自己收到的第一个投票请求投票。醒的最早的Candidate最有可能成为Leader。
Follower将其当前term加一然后转换为Candidate。它首先给自己投票并且给集群中的其他服务器发送 RequestVote RPC。结果有以下三种情况：

赢得了多数的选票，成功选举为Leader；
收到了Leader的消息，表示有其它服务器已经抢先当选了Leader；
没有服务器赢得多数的选票，Leader选举失败，等待选举时间超时后发起下一次选举。

选举出Leader后，Leader通过定期向所有Followers发送心跳信息维持其统治。若Follower一段时间未收到Leader的心跳则认为Leader可能已经挂了，再次发起Leader选举过程。
Raft保证选举出的Leader上一定具有最新的已提交的日志，这一点将在四、安全性中说明。
三、日志同步
Leader选出后，就开始接收客户端的请求。Leader把请求作为日志条目（Log entries）加入到它的日志中，然后并行的向其他服务器发起 AppendEntries RPC 复制日志条目。当这条日志被复制到大多数服务器上，Leader将这条日志应用到它的状态机并向客户端返回执行结果。

某些Followers可能没有成功的复制日志，Leader会无限的重试 AppendEntries RPC直到所有的Followers最终存储了所有的日志条目。
日志由有序编号（log index，索引）的日志条目组成。每个日志条目包含它被创建时的任期号（term），和用于状态机执行的命令。如果一个日志条目被复制到大多数服务器上，就被认为可以提交（commit）了。log index 与 term 无关，Leader 每生成一条日志条目都会消耗一个 log index ，log index 只会一直递增。
Raft日志同步保证如下两点：

如果不同日志中的两个条目有着相同的索引和任期号，则它们所存储的命令是相同的。
如果不同日志中的两个条目有着相同的索引和任期号，则它们之前的所有条目都是完全一样的。

第一条特性源于Leader在一个term内在给定的一个log index最多创建一条日志条目，同时该条目在日志中的位置也从来不会改变。
第二条特性源于 AppendEntries 的一个简单的一致性检查。当发送一个 AppendEntries RPC 时，Leader会把新日志条目紧接着之前的条目的log index和term都包含在里面。如果Follower没有在它的日志中找到log index和term都相同的日志，它就会拒绝新的日志条目。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://ethereal-lu.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Raft算法","item":"https://ethereal-lu.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%9F%BA%E7%A1%80/raft%E7%AE%97%E6%B3%95/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Raft算法","name":"Raft算法","description":"一、 概述 分布式一致性算法Raft将一致性分解为多个子问题：Leader选举、日志同步、安全性、日志压缩、成员变更等。\nRaft将系统中的角色分为领导者（Leader）、跟从者（Follower）和候选人（Candidate）：\nLeader：接受客户端请求，并向Follower同步请求日志，当日志同步到大多数节点上后告诉Follower提交日志。 Follower：接受并持久化Leader同步的日志，在Leader告之日志可以提交之后，提交日志。 Candidate：Leader选举过程中的临时角色。 Raft要求系统在任意时刻最多只有一个Leader，正常工作期间只有Leader和Followers。\n只有 Leader 节点能够处理客户端的一切请求（如果客户端的请求发到了 Follower，Follower 将会把请求重定向到 Leader）。Raft算法将时间分为一个个的任期（term），每一个term的开始都是Leader选举。在成功选举Leader之后，Leader会在整个term内管理整个集群。如果Leader选举失败，该term就会因为没有Leader而结束。\n二、Leader选举 Raft 使用心跳（heartbeat）触发Leader选举。Leader向所有Followers周期性发送heartbeat。如果Follower在超时时间内没有收到Leader的heartbeat（也许此时还没有选出Leader，大家都在等；也许Leader挂了；也许只是Leader与该Follower之间网络故障），就会随机睡眠一段时间后发起Leader选举。\n当服务器启动时，初始化为Follower，此时可能是集群刚启动，那么所有节点全部等待leader的心跳，当某个或某些节点超时后变为Candidate发起选举；也可能是新节点加入集群，那它会直接收到leader的心跳。\n不论外部环境如何，只要一个节点在超时时间内没有收到Leader的心跳，那它就会发起选举。也即选举时只有一个或几个节点会成为Candidate，并不是所有节点都成为Candidate。\nFollower按如下规则投票：\n每个 term 只能投一票 只能给 term 和 logindex 不低于自己的 Candidate 投票 注意：只有Candidate会给自己投票，Follower不能给自己投票，Follower按上方规则给自己收到的第一个投票请求投票。醒的最早的Candidate最有可能成为Leader。\nFollower将其当前term加一然后转换为Candidate。它首先给自己投票并且给集群中的其他服务器发送 RequestVote RPC。结果有以下三种情况：\n赢得了多数的选票，成功选举为Leader； 收到了Leader的消息，表示有其它服务器已经抢先当选了Leader； 没有服务器赢得多数的选票，Leader选举失败，等待选举时间超时后发起下一次选举。 选举出Leader后，Leader通过定期向所有Followers发送心跳信息维持其统治。若Follower一段时间未收到Leader的心跳则认为Leader可能已经挂了，再次发起Leader选举过程。\nRaft保证选举出的Leader上一定具有最新的已提交的日志，这一点将在四、安全性中说明。\n三、日志同步 Leader选出后，就开始接收客户端的请求。Leader把请求作为日志条目（Log entries）加入到它的日志中，然后并行的向其他服务器发起 AppendEntries RPC 复制日志条目。当这条日志被复制到大多数服务器上，Leader将这条日志应用到它的状态机并向客户端返回执行结果。\n某些Followers可能没有成功的复制日志，Leader会无限的重试 AppendEntries RPC直到所有的Followers最终存储了所有的日志条目。\n日志由有序编号（log index，索引）的日志条目组成。每个日志条目包含它被创建时的任期号（term），和用于状态机执行的命令。如果一个日志条目被复制到大多数服务器上，就被认为可以提交（commit）了。log index 与 term 无关，Leader 每生成一条日志条目都会消耗一个 log index ，log index 只会一直递增。\nRaft日志同步保证如下两点：\n如果不同日志中的两个条目有着相同的索引和任期号，则它们所存储的命令是相同的。 如果不同日志中的两个条目有着相同的索引和任期号，则它们之前的所有条目都是完全一样的。 第一条特性源于Leader在一个term内在给定的一个log index最多创建一条日志条目，同时该条目在日志中的位置也从来不会改变。\n第二条特性源于 AppendEntries 的一个简单的一致性检查。当发送一个 AppendEntries RPC 时，Leader会把新日志条目紧接着之前的条目的log index和term都包含在里面。如果Follower没有在它的日志中找到log index和term都相同的日志，它就会拒绝新的日志条目。\n","keywords":[],"articleBody":"一、 概述 分布式一致性算法Raft将一致性分解为多个子问题：Leader选举、日志同步、安全性、日志压缩、成员变更等。\nRaft将系统中的角色分为领导者（Leader）、跟从者（Follower）和候选人（Candidate）：\nLeader：接受客户端请求，并向Follower同步请求日志，当日志同步到大多数节点上后告诉Follower提交日志。 Follower：接受并持久化Leader同步的日志，在Leader告之日志可以提交之后，提交日志。 Candidate：Leader选举过程中的临时角色。 Raft要求系统在任意时刻最多只有一个Leader，正常工作期间只有Leader和Followers。\n只有 Leader 节点能够处理客户端的一切请求（如果客户端的请求发到了 Follower，Follower 将会把请求重定向到 Leader）。Raft算法将时间分为一个个的任期（term），每一个term的开始都是Leader选举。在成功选举Leader之后，Leader会在整个term内管理整个集群。如果Leader选举失败，该term就会因为没有Leader而结束。\n二、Leader选举 Raft 使用心跳（heartbeat）触发Leader选举。Leader向所有Followers周期性发送heartbeat。如果Follower在超时时间内没有收到Leader的heartbeat（也许此时还没有选出Leader，大家都在等；也许Leader挂了；也许只是Leader与该Follower之间网络故障），就会随机睡眠一段时间后发起Leader选举。\n当服务器启动时，初始化为Follower，此时可能是集群刚启动，那么所有节点全部等待leader的心跳，当某个或某些节点超时后变为Candidate发起选举；也可能是新节点加入集群，那它会直接收到leader的心跳。\n不论外部环境如何，只要一个节点在超时时间内没有收到Leader的心跳，那它就会发起选举。也即选举时只有一个或几个节点会成为Candidate，并不是所有节点都成为Candidate。\nFollower按如下规则投票：\n每个 term 只能投一票 只能给 term 和 logindex 不低于自己的 Candidate 投票 注意：只有Candidate会给自己投票，Follower不能给自己投票，Follower按上方规则给自己收到的第一个投票请求投票。醒的最早的Candidate最有可能成为Leader。\nFollower将其当前term加一然后转换为Candidate。它首先给自己投票并且给集群中的其他服务器发送 RequestVote RPC。结果有以下三种情况：\n赢得了多数的选票，成功选举为Leader； 收到了Leader的消息，表示有其它服务器已经抢先当选了Leader； 没有服务器赢得多数的选票，Leader选举失败，等待选举时间超时后发起下一次选举。 选举出Leader后，Leader通过定期向所有Followers发送心跳信息维持其统治。若Follower一段时间未收到Leader的心跳则认为Leader可能已经挂了，再次发起Leader选举过程。\nRaft保证选举出的Leader上一定具有最新的已提交的日志，这一点将在四、安全性中说明。\n三、日志同步 Leader选出后，就开始接收客户端的请求。Leader把请求作为日志条目（Log entries）加入到它的日志中，然后并行的向其他服务器发起 AppendEntries RPC 复制日志条目。当这条日志被复制到大多数服务器上，Leader将这条日志应用到它的状态机并向客户端返回执行结果。\n某些Followers可能没有成功的复制日志，Leader会无限的重试 AppendEntries RPC直到所有的Followers最终存储了所有的日志条目。\n日志由有序编号（log index，索引）的日志条目组成。每个日志条目包含它被创建时的任期号（term），和用于状态机执行的命令。如果一个日志条目被复制到大多数服务器上，就被认为可以提交（commit）了。log index 与 term 无关，Leader 每生成一条日志条目都会消耗一个 log index ，log index 只会一直递增。\nRaft日志同步保证如下两点：\n如果不同日志中的两个条目有着相同的索引和任期号，则它们所存储的命令是相同的。 如果不同日志中的两个条目有着相同的索引和任期号，则它们之前的所有条目都是完全一样的。 第一条特性源于Leader在一个term内在给定的一个log index最多创建一条日志条目，同时该条目在日志中的位置也从来不会改变。\n第二条特性源于 AppendEntries 的一个简单的一致性检查。当发送一个 AppendEntries RPC 时，Leader会把新日志条目紧接着之前的条目的log index和term都包含在里面。如果Follower没有在它的日志中找到log index和term都相同的日志，它就会拒绝新的日志条目。\n一般情况下，Leader和Followers的日志保持一致，因此 AppendEntries 一致性检查通常不会失败。然而，Leader崩溃可能会导致日志不一致：旧的Leader可能没有完全复制完日志中的所有条目。\n上图阐述了一些Followers可能和新的Leader日志不同的情况。一个Follower可能会丢失掉Leader上的一些条目，也有可能包含一些Leader没有的条目，也有可能两者都会发生。丢失的或者多出来的条目可能会持续多个任期。\nLeader通过强制Followers复制它的日志来处理日志的不一致，Followers上的不一致的日志会被Leader的日志覆盖。\nLeader为了使Followers的日志同自己的一致，Leader需要找到Followers同它的日志一致的地方，然后覆盖Followers在该位置之后的条目。\nLeader会从后往前试，每次AppendEntries失败后尝试前一个日志条目，直到成功找到每个Follower的日志一致位点，然后向后逐条覆盖Followers在该位置之后的条目。\n四、安全性 Raft增加了如下两条限制以保证安全性：\n拥有最新的已提交的log entry的Follower才有资格成为Leader。 这个保证是在RequestVote RPC中做的，Candidate在发送RequestVote RPC时，要带上自己的最后一条日志的term和log index，其他节点收到消息时，如果发现自己的日志比请求中携带的更新，则拒绝投票。日志比较的原则是，如果本地的最后一条log entry的term更大，则term大的更新，如果term一样大，则log index更大的更新。注：上方所有比较都是基于已提交到日志进行比较。\nLeader只能推进commit index来提交当前term的已经复制到大多数服务器上的日志，旧term日志的提交要等到提交当前term的日志来间接提交（log index 小于 commit index的日志被间接提交）。 之所以要这样，是因为可能会出现已提交的日志又被覆盖的情况：\n在阶段a，term为2，S1是Leader，且S1写入日志（term, index）为(2, 2)，并且日志被同步写入了S2；\n在阶段b，S1离线，触发一次新的选主，此时S5被选为新的Leader，此时系统term为3，且写入了日志（term, index）为（3， 2）;\nS5尚未将日志推送到Followers就离线了，进而触发了一次新的选主，而之前离线的S1经过重新上线后被选中变成Leader，此时系统term为4，此时S1会将自己的日志同步到Followers，按照上图就是将日志（2， 2）同步到了S3，而此时由于该日志已经被同步到了多数节点（S1, S2, S3），因此，此时日志（2，2）可以被提交了。；\n在阶段d，S1又下线了，触发一次选主，而S5有可能被选为新的Leader（这是因为S5可以满足作为主的一切条件：1. term = 5 \u003e 4，2. 最新的日志为（3，2），比大多数节点（如S2/S3/S4的日志都新），然后S5会将自己的日志更新到Followers，于是S2、S3中已经被提交的日志（2，2）被截断了。\n增加上述限制后，即使日志（2，2）已经被大多数节点（S1、S2、S3）确认了，但是它不能被提交，因为它是来自之前term（2）的日志，直到S1在当前term（4）产生的日志（4， 4）被大多数Followers确认，S1方可提交日志（4，4）这条日志，当然，根据Raft定义，（4，4）之前的所有日志也会被提交。此时即使S1再下线，重新选主时S5不可能成为Leader，因为它没有包含大多数节点已经拥有的日志（4，4）。\n五、系统快照 Raft 采用系统快照来解决日志无限增长的问题。每个节点独立的对自己的系统状态进行snapshot，并且只能对已经提交的日志记录进行snapshot。快照之前的日志全部丢弃。快照中包括最后一条已提交的 log entry的 log index和term，这两个值在snapshot之后的第一条log entry的AppendEntries RPC的完整性检查的时候会被用上。\n当集群新增一台机器或Follower的日志落后Leader太多时，会通过快照同步日志。生成快照通过fork子进程进行。\n六、成员变更 Raft 不允许一次新增多个节点，会产生脑裂问题，如下：\n原本集群中有 5 个节点，其中 1 个 Leader 4 个 Follower，现同时新增 7 个节点。此时 Leader 需要将旧配置（共 5 个节点）更换为新配置（共 12 个节点），由于各节点提交日志的时间可能不同，若 7 个新增节点全部将更新日志提交，但是原有的 4 个 Follower 还未提交（已达到过半节点提交的条件），此时若 Leader 宕机，且 4 个 Follower 和 7 个新增节点断开连接，那么两个部分都具备选取主节点的条件，因此会发生脑裂。\nRaft 每次只允许增加或删除一个成员，可从数学上严格证明，Cold与Cnew不可能形成两个不相交的多数派。\n成员变更限制每次只能增加或删除一个成员（如果要变更多个成员，连续变更多次）。 成员变更由Leader发起，Cnew得到多数派确认后，返回客户端成员变更成功。 一次成员变更成功前不允许开始下一次成员变更，因此新任Leader在开始提供服务前要将自己本地保存的最新成员配置重新投票形成多数派确认。 Leader只要开始同步新成员配置，即可开始使用新的成员配置进行日志同步。 七、脑裂问题 raft保证一个任期内最多只有一个leader，但在网络分割的情况下，可能会出现两个leader，但两个leader所处的任期是不同的。\n系统有5个节点ABCDE组成，在term1，Node B是leader，但Node A、B和Node C、D、E之间出现了网络分割，因此Node C、D、E无法收到来自leader（Node B）的消息，在election time之后，Node C、D、E会分期选举，由于满足majority条件，Node E成为了term 2的leader。因此，在系统中貌似出现了两个leader：term 1的Node B， term 2的Node E, Node B的term更旧，但由于无法与Majority节点通信，NodeB仍然会认为自己是leader。\n产生脑裂后Node E可以正常读写，但是Node B对于写请求会因为无法复制到半数以上节点而不会产生问题，对于读请求会返回就旧数据。\nraft的论文中leader转换成follower的条件是收到来自更高term的消息，如果网络分割一直持续，那么旧 leader就会一直存在。而在raft的一些实现中，leader如果检测不到半数以上的节点就会自行转换到follower状态。\n","wordCount":"190","inLanguage":"en","datePublished":"2022-08-11T13:42:15Z","dateModified":"2022-08-11T13:42:15Z","author":{"@type":"Person","name":"lu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://ethereal-lu.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%9F%BA%E7%A1%80/raft%E7%AE%97%E6%B3%95/"},"publisher":{"@type":"Organization","name":"lu","logo":{"@type":"ImageObject","url":"https://ethereal-lu.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://ethereal-lu.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://ethereal-lu.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://ethereal-lu.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://ethereal-lu.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://ethereal-lu.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://ethereal-lu.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Raft算法</h1><div class=post-meta><span title='2022-08-11 13:42:15 +0000 UTC'>2022-08-11</span>&nbsp;·&nbsp;190 words&nbsp;·&nbsp;lu</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#一-概述>一、 概述</a></li><li><a href=#二leader选举>二、Leader选举</a></li><li><a href=#三日志同步>三、日志同步</a></li><li><a href=#四安全性>四、安全性</a></li><li><a href=#五系统快照>五、系统快照</a></li><li><a href=#六成员变更>六、成员变更</a></li><li><a href=#七脑裂问题>七、脑裂问题</a></li></ul></nav></div></details></div><div class=post-content><h2 id=一-概述>一、 概述<a hidden class=anchor aria-hidden=true href=#一-概述>#</a></h2><p>分布式一致性算法Raft将一致性分解为多个子问题：Leader选举、日志同步、安全性、日志压缩、成员变更等。</p><p>Raft将系统中的角色分为领导者（Leader）、跟从者（Follower）和候选人（Candidate）：</p><ul><li><strong>Leader</strong>：接受客户端请求，并向Follower同步请求日志，当日志同步到大多数节点上后告诉Follower提交日志。</li><li><strong>Follower</strong>：接受并持久化Leader同步的日志，在Leader告之日志可以提交之后，提交日志。</li><li><strong>Candidate</strong>：Leader选举过程中的临时角色。</li></ul><p>Raft要求系统在任意时刻最多只有一个Leader，正常工作期间只有Leader和Followers。</p><p>只有 Leader 节点能够处理客户端的一切请求（如果客户端的请求发到了 Follower，Follower 将会把请求重定向到 Leader）。Raft算法将时间分为一个个的任期（term），每一个term的开始都是Leader选举。在成功选举Leader之后，Leader会在整个term内管理整个集群。如果Leader选举失败，该term就会因为没有Leader而结束。</p><p><img alt=term loading=lazy src=/posts/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%9F%BA%E7%A1%80/raft%E7%AE%97%E6%B3%95/term.png></p><h2 id=二leader选举>二、Leader选举<a hidden class=anchor aria-hidden=true href=#二leader选举>#</a></h2><p>Raft 使用心跳（heartbeat）触发Leader选举。Leader向所有Followers周期性发送heartbeat。如果Follower在超时时间内没有收到Leader的heartbeat（也许此时还没有选出Leader，大家都在等；也许Leader挂了；也许只是Leader与该Follower之间网络故障），就会随机睡眠一段时间后发起Leader选举。</p><p>当服务器启动时，初始化为Follower，此时可能是集群刚启动，那么所有节点全部等待leader的心跳，当某个或某些节点超时后变为Candidate发起选举；也可能是新节点加入集群，那它会直接收到leader的心跳。</p><p>不论外部环境如何，只要一个节点在超时时间内没有收到Leader的心跳，那它就会发起选举。也即选举时只有一个或几个节点会成为Candidate，并不是所有节点都成为Candidate。</p><p>Follower按如下规则投票：</p><ol><li>每个 term 只能投一票</li><li>只能给 term 和 logindex 不低于自己的 Candidate 投票</li></ol><p>注意：只有Candidate会给自己投票，Follower不能给自己投票，Follower按上方规则给自己收到的第一个投票请求投票。醒的最早的Candidate最有可能成为Leader。</p><p>Follower将其当前term加一然后转换为Candidate。它首先给自己投票并且给集群中的其他服务器发送 RequestVote RPC。结果有以下三种情况：</p><ul><li>赢得了多数的选票，成功选举为Leader；</li><li>收到了Leader的消息，表示有其它服务器已经抢先当选了Leader；</li><li>没有服务器赢得多数的选票，Leader选举失败，等待选举时间超时后发起下一次选举。</li></ul><p>选举出Leader后，Leader通过定期向所有Followers发送心跳信息维持其统治。若Follower一段时间未收到Leader的心跳则认为Leader可能已经挂了，再次发起Leader选举过程。</p><p>Raft保证选举出的Leader上一定具有最新的已提交的日志，这一点将在四、安全性中说明。</p><h2 id=三日志同步>三、日志同步<a hidden class=anchor aria-hidden=true href=#三日志同步>#</a></h2><p>Leader选出后，就开始接收客户端的请求。Leader把请求作为日志条目（Log entries）加入到它的日志中，然后并行的向其他服务器发起 AppendEntries RPC 复制日志条目。当这条日志被复制到大多数服务器上，Leader将这条日志应用到它的状态机并向客户端返回执行结果。</p><p><img alt=日志同步 loading=lazy src=/posts/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%9F%BA%E7%A1%80/raft%E7%AE%97%E6%B3%95/%E6%97%A5%E5%BF%97%E5%90%8C%E6%AD%A5.jpeg></p><p>某些Followers可能没有成功的复制日志，Leader会无限的重试 AppendEntries RPC直到所有的Followers最终存储了所有的日志条目。</p><p>日志由有序编号（log index，索引）的日志条目组成。每个日志条目包含它被创建时的任期号（term），和用于状态机执行的命令。如果一个日志条目被复制到大多数服务器上，就被认为可以提交（commit）了。log index 与 term 无关，Leader 每生成一条日志条目都会消耗一个 log index ，log index 只会一直递增。</p><p>Raft日志同步保证如下两点：</p><ul><li>如果不同日志中的两个条目有着相同的索引和任期号，则它们所存储的命令是相同的。</li><li>如果不同日志中的两个条目有着相同的索引和任期号，则它们之前的所有条目都是完全一样的。</li></ul><p>第一条特性源于Leader在一个term内在给定的一个log index最多创建一条日志条目，同时该条目在日志中的位置也从来不会改变。</p><p>第二条特性源于 AppendEntries 的一个简单的一致性检查。当发送一个 AppendEntries RPC 时，Leader会把新日志条目紧接着之前的条目的log index和term都包含在里面。如果Follower没有在它的日志中找到log index和term都相同的日志，它就会拒绝新的日志条目。</p><p>一般情况下，Leader和Followers的日志保持一致，因此 AppendEntries 一致性检查通常不会失败。然而，Leader崩溃可能会导致日志不一致：旧的Leader可能没有完全复制完日志中的所有条目。</p><p><img alt=日志不一致.jpeg loading=lazy src=/posts/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%9F%BA%E7%A1%80/raft%E7%AE%97%E6%B3%95/%E6%97%A5%E5%BF%97%E4%B8%8D%E4%B8%80%E8%87%B4.jpeg></p><p>上图阐述了一些Followers可能和新的Leader日志不同的情况。一个Follower可能会丢失掉Leader上的一些条目，也有可能包含一些Leader没有的条目，也有可能两者都会发生。丢失的或者多出来的条目可能会持续多个任期。</p><p>Leader通过强制Followers复制它的日志来处理日志的不一致，Followers上的不一致的日志会被Leader的日志覆盖。</p><p>Leader为了使Followers的日志同自己的一致，Leader需要找到Followers同它的日志一致的地方，然后覆盖Followers在该位置之后的条目。</p><p>Leader会从后往前试，每次AppendEntries失败后尝试前一个日志条目，直到成功找到每个Follower的日志一致位点，然后向后逐条覆盖Followers在该位置之后的条目。</p><h2 id=四安全性>四、安全性<a hidden class=anchor aria-hidden=true href=#四安全性>#</a></h2><p>Raft增加了如下两条限制以保证安全性：</p><ul><li>拥有最新的<strong>已提交</strong>的log entry的Follower才有资格成为Leader。</li></ul><p>这个保证是在RequestVote RPC中做的，Candidate在发送RequestVote RPC时，要带上自己的最后一条日志的term和log index，其他节点收到消息时，如果发现自己的日志比请求中携带的更新，则拒绝投票。日志比较的原则是，如果本地的最后一条log entry的term更大，则term大的更新，如果term一样大，则log index更大的更新。注：上方所有比较都是基于已提交到日志进行比较。</p><ul><li>Leader只能推进commit index来提交当前term的已经复制到大多数服务器上的日志，旧term日志的提交要等到提交当前term的日志来间接提交（log index 小于 commit index的日志被间接提交）。</li></ul><p>之所以要这样，是因为可能会出现已提交的日志又被覆盖的情况：</p><p><img alt=已提交的日志被覆盖 loading=lazy src=%E5%B7%B2%E6%8F%90%E4%BA%A4%E7%9A%84%E6%97%A5%E5%BF%97%E8%A2%AB%E8%A6%86%E7%9B%96.jpeg></p><p>在阶段a，term为2，S1是Leader，且S1写入日志（term, index）为(2, 2)，并且日志被同步写入了S2；</p><p>在阶段b，S1离线，触发一次新的选主，此时S5被选为新的Leader，此时系统term为3，且写入了日志（term, index）为（3， 2）;</p><p>S5尚未将日志推送到Followers就离线了，进而触发了一次新的选主，而之前离线的S1经过重新上线后被选中变成Leader，此时系统term为4，此时S1会将自己的日志同步到Followers，按照上图就是将日志（2， 2）同步到了S3，而此时由于该日志已经被同步到了多数节点（S1, S2, S3），因此，此时日志（2，2）可以被提交了。；</p><p>在阶段d，S1又下线了，触发一次选主，而S5有可能被选为新的Leader（这是因为S5可以满足作为主的一切条件：1. term = 5 > 4，2. 最新的日志为（3，2），比大多数节点（如S2/S3/S4的日志都新），然后S5会将自己的日志更新到Followers，于是S2、S3中已经被提交的日志（2，2）被截断了。</p><p>增加上述限制后，即使日志（2，2）已经被大多数节点（S1、S2、S3）确认了，但是它不能被提交，因为它是来自之前term（2）的日志，直到S1在当前term（4）产生的日志（4， 4）被大多数Followers确认，S1方可提交日志（4，4）这条日志，当然，根据Raft定义，（4，4）之前的所有日志也会被提交。此时即使S1再下线，重新选主时S5不可能成为Leader，因为它没有包含大多数节点已经拥有的日志（4，4）。</p><h2 id=五系统快照>五、系统快照<a hidden class=anchor aria-hidden=true href=#五系统快照>#</a></h2><p>Raft 采用系统快照来解决日志无限增长的问题。每个节点独立的对自己的系统状态进行snapshot，并且只能对已经提交的日志记录进行snapshot。快照之前的日志全部丢弃。快照中包括最后一条已提交的 log entry的 log index和term，这两个值在snapshot之后的第一条log entry的AppendEntries RPC的完整性检查的时候会被用上。</p><p>当集群新增一台机器或Follower的日志落后Leader太多时，会通过快照同步日志。生成快照通过fork子进程进行。</p><h2 id=六成员变更>六、成员变更<a hidden class=anchor aria-hidden=true href=#六成员变更>#</a></h2><p>Raft 不允许一次新增多个节点，会产生脑裂问题，如下：</p><p>原本集群中有 5 个节点，其中 1 个 Leader 4 个 Follower，现同时新增 7 个节点。此时 Leader 需要将旧配置（共 5 个节点）更换为新配置（共 12 个节点），由于各节点提交日志的时间可能不同，若 7 个新增节点全部将更新日志提交，但是原有的 4 个 Follower 还未提交（已达到过半节点提交的条件），此时若 Leader 宕机，且 4 个 Follower 和 7 个新增节点断开连接，那么两个部分都具备选取主节点的条件，因此会发生脑裂。</p><p>Raft 每次只允许增加或删除一个成员，可从数学上严格证明，Cold与Cnew不可能形成两个不相交的多数派。</p><ul><li>成员变更限制每次只能增加或删除一个成员（如果要变更多个成员，连续变更多次）。</li><li>成员变更由Leader发起，Cnew得到多数派确认后，返回客户端成员变更成功。</li><li>一次成员变更成功前不允许开始下一次成员变更，因此新任Leader在开始提供服务前要将自己本地保存的最新成员配置重新投票形成多数派确认。</li><li>Leader只要开始同步新成员配置，即可开始使用新的成员配置进行日志同步。</li></ul><h2 id=七脑裂问题>七、脑裂问题<a hidden class=anchor aria-hidden=true href=#七脑裂问题>#</a></h2><p>raft保证一个任期内最多只有一个leader，但在网络分割的情况下，<strong>可能会出现两个leader，但两个leader所处的任期是不同的</strong>。</p><p>系统有5个节点ABCDE组成，在term1，Node B是leader，但Node A、B和Node C、D、E之间出现了网络分割，因此Node C、D、E无法收到来自leader（Node B）的消息，在election time之后，Node C、D、E会分期选举，由于满足majority条件，Node E成为了term 2的leader。因此，在系统中貌似出现了两个leader：term 1的Node B， term 2的Node E, Node B的term更旧，但由于无法与Majority节点通信，NodeB仍然会认为自己是leader。</p><p>产生脑裂后Node E可以正常读写，但是Node B对于写请求会因为无法复制到半数以上节点而不会产生问题，对于读请求会返回就旧数据。</p><p>raft的论文中leader转换成follower的条件是收到来自更高term的消息，如果网络分割一直持续，那么旧 leader就会一直存在。而在raft的一些实现中，leader如果检测不到半数以上的节点就会自行转换到follower状态。</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://ethereal-lu.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%BE%AE%E6%9C%8D%E5%8A%A1/dubbo/><span class=title>« Prev</span><br><span>Dubbo</span>
</a><a class=next href=https://ethereal-lu.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/elasticsearch/elasticsearch%E9%9B%86%E7%BE%A4/><span class=title>Next »</span><br><span>ElasticSearch集群</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://ethereal-lu.github.io/>lu</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>