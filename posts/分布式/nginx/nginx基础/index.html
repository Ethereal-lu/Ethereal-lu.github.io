<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Nginx基础 | lu</title>
<meta name=keywords content><meta name=description content="Tomcat 稳定但不支持高并发，因此支持高并发的 Nginx 诞生了。Nginx使用基于事件驱动架构，使其可以支持数以百万级别的TCP连接。
1、Nginx 应用场景
Nginx是一款高性能的HTTP服务器和反向代理服务器。Nginx 最常用的应用场景就是这两个。
1.1、反向代理
正向代理，&ldquo;它代理的是客户端，代客户端发出请求&rdquo;，是一个位于客户端和原始服务器之间的中间服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。
反向代理，&ldquo;它代理的是服务端，代服务端接收请求&rdquo;，主要用于服务器集群分布式部署的情况下，反向代理隐藏了服务器的信息。Nginx 作为服务端暴露的地址，所有客户端的请求都会进入 Nginx 服务器，然后由 Nginx 按照一定的规则将请求分发给具体的业务处理服务器，客户端并不知道是哪台服务器为自己服务，这里Nginx 扮演的就是反向代理服务器。
反向代理的作用：

保证内网的安全，通常将反向代理作为公网访问地址，Web服务器是内网
负载均衡，通过反向代理服务器来优化网站的负载

负载均衡
上方提到的请求分发就是依据这里的负载均衡策略分发的。
负载均衡分为硬件负载均衡和软件负载均衡两种，硬件如F5负载均衡，相对造价昂贵成本较高，但是数据的稳定性安全性高；除了移动联通等运营商使用的都是软件负载均衡，软件负载均衡是利用现有的技术结合主机硬件实现的一种消息队列分发机制。
Nginx支持的负载均衡调度算法如下：重点掌握权重轮询即可，其余的基本不用。但作为面试还是要能说出来。

权重轮询(默认）：接收到的请求按照权重分配到不同的后端服务器，可以根据服务器的硬件性能配置不同的权重，权重越大被分配到请求的几率越大。
ip_hash：每个请求按照发起客户端的ip的hash结果进行匹配，对于一个固定ip地址的客户端总会访问到同一个后端服务器，这也在一定程度上解决了集群部署环境下session共享的问题。但是移动端的ip可能一直变化，所以较为鸡肋。
fair：智能调整调度算法，动态的根据后端服务器的响应时长进行均衡分配，响应时间短处理效率高的服务器分配到请求的概率高。Nginx默认不支持fair算法，需要安装upstream_fair模块。可能造成流量倾斜，大量请求进入响应时长短的服务器导致崩溃。
url_hash：按照访问的url的hash结果分配请求，每个请求的url会指向后端固定的某个服务器，可以在Nginx作为静态服务器的情况下提高缓存效率。同样要注意Nginx默认不支持这种调度算法，要使用的话需要安装Nginx的hash软件包。

1.2、web 服务器
可以先通过动态/静态内容分离，而后为静态内容（html/css/js/图片等）提供HTTP访问功能；而动态内容可以整合代理模块，代理给上游服务器，来支持对外部程序的直接调用或者解析。
2、Nginx 基本架构

一个master进程生成多个worker子进程（每个进程只有一个线程），一个worker进程可以响应多个用户请求；
非阻塞、IO复用、事件驱动：select，poll， epoll， kqueue，/dev/poll；
支持sendfile，sendfile64；
支持文件AIO（异步I/O）；
支持mmap；
灵活的文件配置；
占用内存小：10,000个非活动HTTP保持连接占用大约2.5M内存。

3、Nginx 并发模型
一个master进程生成多个worker子进程（每个进程只有一个线程），一个worker响应多个用户请求。如果单进程启动：仅有一个进程，既充当master进程的角色，也充当worker进程的角色。
3.1、master进程
充当整个进程组与用户的交互接口（接收来自外界的信号，向各worker进程发送信号），同时监控worker进程的运行状态。
它不需要处理网络事件，不负责业务的执行，只会通过管理worker进程来实现重启服务、平滑升级、更换日志文件、配置文件实时生效等功能。
3.2、worker进程
主要任务是处理基本的网络事件，完成具体的任务逻辑。多个worker进程之间是对等的，互相独立的。
worker进程主要关注点是与客户端或后端服务器（此时nginx作为中间代理）之间的数据可读/可写等I/O交互事件，所以工作进程的阻塞点是在像select()、epoll_wait()等这样的I/O多路复用函数调用处，以等待发生数据可读/写事件。当然也可能被新收到的进程信号中断。
worker进程个数：

如果负载以CPU密集型应用为主，一般会设置与机器cpu核数一致或少一个（用来处理用户等其他任务）；
如果负载以IO密集型为主，如响应大量内容给客户端，则worker数应该为CPU个数的1.5或2倍。

因为更多的worker数，只会导致进程来竞争cpu资源了，从而带来不必要的上下文切换。而且，nginx为了更好的利用多核特性，具有cpu绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效。
3.3、并发处理

在master进程里面，先创建socket，并bind、listen在80端口（所以master进程需要root权限）；
然后再fork出多个worker进程，这样每个worker进程都可以去accept这个socket（会产生惊群问题）， 或者使用锁机制，让抢到锁的一个worker进程去accept这个socket，注意这里一般使用select/poll/epoll机制来解决accept阻塞问题；
当一个新连接进来后，而只有抢到锁的一个进程可以accept这个连接进行处理（也是放入epoll中）；
抢到锁的worker进程accept到新连接后，会立即释放锁；然后所有worker进程再次参与抢锁，这样就回到了第二步，进行循环处理并发连接；

3.4、惊群问题
产生原因：像上面第二步，多个worker进程等待同一个socket的连接事件，当这个事件发生时，这些进程被同时唤醒，就是惊群。
注意，在linux2.6内核上，accept系统调用已经不存在惊群，但用epoll机制来解决accept阻塞问题，epoll_wait会有惊群问题（新增 EPOLLEXCLUSIVE 选项解决了）。
导致后果：许多worker进程被内核重新调度唤醒，只有一个进程可以accept这个连接进行处理，其他余者皆失败，导致性能浪费。
nginx解决方案：使用锁机制，让抢到锁的一个worker进程去accept（epoll_wait）这个socket；如果操作系统支持原子整型，才会使用共享内存实现原子上锁，否则使用文件上锁。
4、Nginx 配置
4.1、默认配置文件
/etc/nginx/nginx.conf"><meta name=author content="lu"><link rel=canonical href=https://ethereal-lu.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F/nginx/nginx%E5%9F%BA%E7%A1%80/><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=https://ethereal-lu.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://ethereal-lu.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://ethereal-lu.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://ethereal-lu.github.io/apple-touch-icon.png><link rel=mask-icon href=https://ethereal-lu.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://ethereal-lu.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F/nginx/nginx%E5%9F%BA%E7%A1%80/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://ethereal-lu.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F/nginx/nginx%E5%9F%BA%E7%A1%80/"><meta property="og:site_name" content="lu"><meta property="og:title" content="Nginx基础"><meta property="og:description" content="Tomcat 稳定但不支持高并发，因此支持高并发的 Nginx 诞生了。Nginx使用基于事件驱动架构，使其可以支持数以百万级别的TCP连接。
1、Nginx 应用场景 Nginx是一款高性能的HTTP服务器和反向代理服务器。Nginx 最常用的应用场景就是这两个。
1.1、反向代理 正向代理，“它代理的是客户端，代客户端发出请求”，是一个位于客户端和原始服务器之间的中间服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。
反向代理，“它代理的是服务端，代服务端接收请求”，主要用于服务器集群分布式部署的情况下，反向代理隐藏了服务器的信息。Nginx 作为服务端暴露的地址，所有客户端的请求都会进入 Nginx 服务器，然后由 Nginx 按照一定的规则将请求分发给具体的业务处理服务器，客户端并不知道是哪台服务器为自己服务，这里Nginx 扮演的就是反向代理服务器。
反向代理的作用：
保证内网的安全，通常将反向代理作为公网访问地址，Web服务器是内网 负载均衡，通过反向代理服务器来优化网站的负载 负载均衡
上方提到的请求分发就是依据这里的负载均衡策略分发的。
负载均衡分为硬件负载均衡和软件负载均衡两种，硬件如F5负载均衡，相对造价昂贵成本较高，但是数据的稳定性安全性高；除了移动联通等运营商使用的都是软件负载均衡，软件负载均衡是利用现有的技术结合主机硬件实现的一种消息队列分发机制。
Nginx支持的负载均衡调度算法如下：重点掌握权重轮询即可，其余的基本不用。但作为面试还是要能说出来。
权重轮询(默认）：接收到的请求按照权重分配到不同的后端服务器，可以根据服务器的硬件性能配置不同的权重，权重越大被分配到请求的几率越大。 ip_hash：每个请求按照发起客户端的ip的hash结果进行匹配，对于一个固定ip地址的客户端总会访问到同一个后端服务器，这也在一定程度上解决了集群部署环境下session共享的问题。但是移动端的ip可能一直变化，所以较为鸡肋。 fair：智能调整调度算法，动态的根据后端服务器的响应时长进行均衡分配，响应时间短处理效率高的服务器分配到请求的概率高。Nginx默认不支持fair算法，需要安装upstream_fair模块。可能造成流量倾斜，大量请求进入响应时长短的服务器导致崩溃。 url_hash：按照访问的url的hash结果分配请求，每个请求的url会指向后端固定的某个服务器，可以在Nginx作为静态服务器的情况下提高缓存效率。同样要注意Nginx默认不支持这种调度算法，要使用的话需要安装Nginx的hash软件包。 1.2、web 服务器 可以先通过动态/静态内容分离，而后为静态内容（html/css/js/图片等）提供HTTP访问功能；而动态内容可以整合代理模块，代理给上游服务器，来支持对外部程序的直接调用或者解析。
2、Nginx 基本架构 一个master进程生成多个worker子进程（每个进程只有一个线程），一个worker进程可以响应多个用户请求； 非阻塞、IO复用、事件驱动：select，poll， epoll， kqueue，/dev/poll； 支持sendfile，sendfile64； 支持文件AIO（异步I/O）； 支持mmap； 灵活的文件配置； 占用内存小：10,000个非活动HTTP保持连接占用大约2.5M内存。 3、Nginx 并发模型 一个master进程生成多个worker子进程（每个进程只有一个线程），一个worker响应多个用户请求。如果单进程启动：仅有一个进程，既充当master进程的角色，也充当worker进程的角色。
3.1、master进程 充当整个进程组与用户的交互接口（接收来自外界的信号，向各worker进程发送信号），同时监控worker进程的运行状态。
它不需要处理网络事件，不负责业务的执行，只会通过管理worker进程来实现重启服务、平滑升级、更换日志文件、配置文件实时生效等功能。
3.2、worker进程 主要任务是处理基本的网络事件，完成具体的任务逻辑。多个worker进程之间是对等的，互相独立的。
worker进程主要关注点是与客户端或后端服务器（此时nginx作为中间代理）之间的数据可读/可写等I/O交互事件，所以工作进程的阻塞点是在像select()、epoll_wait()等这样的I/O多路复用函数调用处，以等待发生数据可读/写事件。当然也可能被新收到的进程信号中断。
worker进程个数：
如果负载以CPU密集型应用为主，一般会设置与机器cpu核数一致或少一个（用来处理用户等其他任务）； 如果负载以IO密集型为主，如响应大量内容给客户端，则worker数应该为CPU个数的1.5或2倍。 因为更多的worker数，只会导致进程来竞争cpu资源了，从而带来不必要的上下文切换。而且，nginx为了更好的利用多核特性，具有cpu绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效。
3.3、并发处理 在master进程里面，先创建socket，并bind、listen在80端口（所以master进程需要root权限）； 然后再fork出多个worker进程，这样每个worker进程都可以去accept这个socket（会产生惊群问题）， 或者使用锁机制，让抢到锁的一个worker进程去accept这个socket，注意这里一般使用select/poll/epoll机制来解决accept阻塞问题； 当一个新连接进来后，而只有抢到锁的一个进程可以accept这个连接进行处理（也是放入epoll中）； 抢到锁的worker进程accept到新连接后，会立即释放锁；然后所有worker进程再次参与抢锁，这样就回到了第二步，进行循环处理并发连接； 3.4、惊群问题 产生原因：像上面第二步，多个worker进程等待同一个socket的连接事件，当这个事件发生时，这些进程被同时唤醒，就是惊群。
注意，在linux2.6内核上，accept系统调用已经不存在惊群，但用epoll机制来解决accept阻塞问题，epoll_wait会有惊群问题（新增 EPOLLEXCLUSIVE 选项解决了）。
导致后果：许多worker进程被内核重新调度唤醒，只有一个进程可以accept这个连接进行处理，其他余者皆失败，导致性能浪费。
nginx解决方案：使用锁机制，让抢到锁的一个worker进程去accept（epoll_wait）这个socket；如果操作系统支持原子整型，才会使用共享内存实现原子上锁，否则使用文件上锁。
4、Nginx 配置 4.1、默认配置文件 /etc/nginx/nginx.conf"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-05-30T22:42:15+00:00"><meta property="article:modified_time" content="2022-05-30T22:42:15+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Nginx基础"><meta name=twitter:description content="Tomcat 稳定但不支持高并发，因此支持高并发的 Nginx 诞生了。Nginx使用基于事件驱动架构，使其可以支持数以百万级别的TCP连接。
1、Nginx 应用场景
Nginx是一款高性能的HTTP服务器和反向代理服务器。Nginx 最常用的应用场景就是这两个。
1.1、反向代理
正向代理，&ldquo;它代理的是客户端，代客户端发出请求&rdquo;，是一个位于客户端和原始服务器之间的中间服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。
反向代理，&ldquo;它代理的是服务端，代服务端接收请求&rdquo;，主要用于服务器集群分布式部署的情况下，反向代理隐藏了服务器的信息。Nginx 作为服务端暴露的地址，所有客户端的请求都会进入 Nginx 服务器，然后由 Nginx 按照一定的规则将请求分发给具体的业务处理服务器，客户端并不知道是哪台服务器为自己服务，这里Nginx 扮演的就是反向代理服务器。
反向代理的作用：

保证内网的安全，通常将反向代理作为公网访问地址，Web服务器是内网
负载均衡，通过反向代理服务器来优化网站的负载

负载均衡
上方提到的请求分发就是依据这里的负载均衡策略分发的。
负载均衡分为硬件负载均衡和软件负载均衡两种，硬件如F5负载均衡，相对造价昂贵成本较高，但是数据的稳定性安全性高；除了移动联通等运营商使用的都是软件负载均衡，软件负载均衡是利用现有的技术结合主机硬件实现的一种消息队列分发机制。
Nginx支持的负载均衡调度算法如下：重点掌握权重轮询即可，其余的基本不用。但作为面试还是要能说出来。

权重轮询(默认）：接收到的请求按照权重分配到不同的后端服务器，可以根据服务器的硬件性能配置不同的权重，权重越大被分配到请求的几率越大。
ip_hash：每个请求按照发起客户端的ip的hash结果进行匹配，对于一个固定ip地址的客户端总会访问到同一个后端服务器，这也在一定程度上解决了集群部署环境下session共享的问题。但是移动端的ip可能一直变化，所以较为鸡肋。
fair：智能调整调度算法，动态的根据后端服务器的响应时长进行均衡分配，响应时间短处理效率高的服务器分配到请求的概率高。Nginx默认不支持fair算法，需要安装upstream_fair模块。可能造成流量倾斜，大量请求进入响应时长短的服务器导致崩溃。
url_hash：按照访问的url的hash结果分配请求，每个请求的url会指向后端固定的某个服务器，可以在Nginx作为静态服务器的情况下提高缓存效率。同样要注意Nginx默认不支持这种调度算法，要使用的话需要安装Nginx的hash软件包。

1.2、web 服务器
可以先通过动态/静态内容分离，而后为静态内容（html/css/js/图片等）提供HTTP访问功能；而动态内容可以整合代理模块，代理给上游服务器，来支持对外部程序的直接调用或者解析。
2、Nginx 基本架构

一个master进程生成多个worker子进程（每个进程只有一个线程），一个worker进程可以响应多个用户请求；
非阻塞、IO复用、事件驱动：select，poll， epoll， kqueue，/dev/poll；
支持sendfile，sendfile64；
支持文件AIO（异步I/O）；
支持mmap；
灵活的文件配置；
占用内存小：10,000个非活动HTTP保持连接占用大约2.5M内存。

3、Nginx 并发模型
一个master进程生成多个worker子进程（每个进程只有一个线程），一个worker响应多个用户请求。如果单进程启动：仅有一个进程，既充当master进程的角色，也充当worker进程的角色。
3.1、master进程
充当整个进程组与用户的交互接口（接收来自外界的信号，向各worker进程发送信号），同时监控worker进程的运行状态。
它不需要处理网络事件，不负责业务的执行，只会通过管理worker进程来实现重启服务、平滑升级、更换日志文件、配置文件实时生效等功能。
3.2、worker进程
主要任务是处理基本的网络事件，完成具体的任务逻辑。多个worker进程之间是对等的，互相独立的。
worker进程主要关注点是与客户端或后端服务器（此时nginx作为中间代理）之间的数据可读/可写等I/O交互事件，所以工作进程的阻塞点是在像select()、epoll_wait()等这样的I/O多路复用函数调用处，以等待发生数据可读/写事件。当然也可能被新收到的进程信号中断。
worker进程个数：

如果负载以CPU密集型应用为主，一般会设置与机器cpu核数一致或少一个（用来处理用户等其他任务）；
如果负载以IO密集型为主，如响应大量内容给客户端，则worker数应该为CPU个数的1.5或2倍。

因为更多的worker数，只会导致进程来竞争cpu资源了，从而带来不必要的上下文切换。而且，nginx为了更好的利用多核特性，具有cpu绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效。
3.3、并发处理

在master进程里面，先创建socket，并bind、listen在80端口（所以master进程需要root权限）；
然后再fork出多个worker进程，这样每个worker进程都可以去accept这个socket（会产生惊群问题）， 或者使用锁机制，让抢到锁的一个worker进程去accept这个socket，注意这里一般使用select/poll/epoll机制来解决accept阻塞问题；
当一个新连接进来后，而只有抢到锁的一个进程可以accept这个连接进行处理（也是放入epoll中）；
抢到锁的worker进程accept到新连接后，会立即释放锁；然后所有worker进程再次参与抢锁，这样就回到了第二步，进行循环处理并发连接；

3.4、惊群问题
产生原因：像上面第二步，多个worker进程等待同一个socket的连接事件，当这个事件发生时，这些进程被同时唤醒，就是惊群。
注意，在linux2.6内核上，accept系统调用已经不存在惊群，但用epoll机制来解决accept阻塞问题，epoll_wait会有惊群问题（新增 EPOLLEXCLUSIVE 选项解决了）。
导致后果：许多worker进程被内核重新调度唤醒，只有一个进程可以accept这个连接进行处理，其他余者皆失败，导致性能浪费。
nginx解决方案：使用锁机制，让抢到锁的一个worker进程去accept（epoll_wait）这个socket；如果操作系统支持原子整型，才会使用共享内存实现原子上锁，否则使用文件上锁。
4、Nginx 配置
4.1、默认配置文件
/etc/nginx/nginx.conf"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://ethereal-lu.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Nginx基础","item":"https://ethereal-lu.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F/nginx/nginx%E5%9F%BA%E7%A1%80/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Nginx基础","name":"Nginx基础","description":"Tomcat 稳定但不支持高并发，因此支持高并发的 Nginx 诞生了。Nginx使用基于事件驱动架构，使其可以支持数以百万级别的TCP连接。\n1、Nginx 应用场景 Nginx是一款高性能的HTTP服务器和反向代理服务器。Nginx 最常用的应用场景就是这两个。\n1.1、反向代理 正向代理，\u0026ldquo;它代理的是客户端，代客户端发出请求\u0026rdquo;，是一个位于客户端和原始服务器之间的中间服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。\n反向代理，\u0026ldquo;它代理的是服务端，代服务端接收请求\u0026rdquo;，主要用于服务器集群分布式部署的情况下，反向代理隐藏了服务器的信息。Nginx 作为服务端暴露的地址，所有客户端的请求都会进入 Nginx 服务器，然后由 Nginx 按照一定的规则将请求分发给具体的业务处理服务器，客户端并不知道是哪台服务器为自己服务，这里Nginx 扮演的就是反向代理服务器。\n反向代理的作用：\n保证内网的安全，通常将反向代理作为公网访问地址，Web服务器是内网 负载均衡，通过反向代理服务器来优化网站的负载 负载均衡\n上方提到的请求分发就是依据这里的负载均衡策略分发的。\n负载均衡分为硬件负载均衡和软件负载均衡两种，硬件如F5负载均衡，相对造价昂贵成本较高，但是数据的稳定性安全性高；除了移动联通等运营商使用的都是软件负载均衡，软件负载均衡是利用现有的技术结合主机硬件实现的一种消息队列分发机制。\nNginx支持的负载均衡调度算法如下：重点掌握权重轮询即可，其余的基本不用。但作为面试还是要能说出来。\n权重轮询(默认）：接收到的请求按照权重分配到不同的后端服务器，可以根据服务器的硬件性能配置不同的权重，权重越大被分配到请求的几率越大。 ip_hash：每个请求按照发起客户端的ip的hash结果进行匹配，对于一个固定ip地址的客户端总会访问到同一个后端服务器，这也在一定程度上解决了集群部署环境下session共享的问题。但是移动端的ip可能一直变化，所以较为鸡肋。 fair：智能调整调度算法，动态的根据后端服务器的响应时长进行均衡分配，响应时间短处理效率高的服务器分配到请求的概率高。Nginx默认不支持fair算法，需要安装upstream_fair模块。可能造成流量倾斜，大量请求进入响应时长短的服务器导致崩溃。 url_hash：按照访问的url的hash结果分配请求，每个请求的url会指向后端固定的某个服务器，可以在Nginx作为静态服务器的情况下提高缓存效率。同样要注意Nginx默认不支持这种调度算法，要使用的话需要安装Nginx的hash软件包。 1.2、web 服务器 可以先通过动态/静态内容分离，而后为静态内容（html/css/js/图片等）提供HTTP访问功能；而动态内容可以整合代理模块，代理给上游服务器，来支持对外部程序的直接调用或者解析。\n2、Nginx 基本架构 一个master进程生成多个worker子进程（每个进程只有一个线程），一个worker进程可以响应多个用户请求； 非阻塞、IO复用、事件驱动：select，poll， epoll， kqueue，/dev/poll； 支持sendfile，sendfile64； 支持文件AIO（异步I/O）； 支持mmap； 灵活的文件配置； 占用内存小：10,000个非活动HTTP保持连接占用大约2.5M内存。 3、Nginx 并发模型 一个master进程生成多个worker子进程（每个进程只有一个线程），一个worker响应多个用户请求。如果单进程启动：仅有一个进程，既充当master进程的角色，也充当worker进程的角色。\n3.1、master进程 充当整个进程组与用户的交互接口（接收来自外界的信号，向各worker进程发送信号），同时监控worker进程的运行状态。\n它不需要处理网络事件，不负责业务的执行，只会通过管理worker进程来实现重启服务、平滑升级、更换日志文件、配置文件实时生效等功能。\n3.2、worker进程 主要任务是处理基本的网络事件，完成具体的任务逻辑。多个worker进程之间是对等的，互相独立的。\nworker进程主要关注点是与客户端或后端服务器（此时nginx作为中间代理）之间的数据可读/可写等I/O交互事件，所以工作进程的阻塞点是在像select()、epoll_wait()等这样的I/O多路复用函数调用处，以等待发生数据可读/写事件。当然也可能被新收到的进程信号中断。\nworker进程个数：\n如果负载以CPU密集型应用为主，一般会设置与机器cpu核数一致或少一个（用来处理用户等其他任务）； 如果负载以IO密集型为主，如响应大量内容给客户端，则worker数应该为CPU个数的1.5或2倍。 因为更多的worker数，只会导致进程来竞争cpu资源了，从而带来不必要的上下文切换。而且，nginx为了更好的利用多核特性，具有cpu绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效。\n3.3、并发处理 在master进程里面，先创建socket，并bind、listen在80端口（所以master进程需要root权限）； 然后再fork出多个worker进程，这样每个worker进程都可以去accept这个socket（会产生惊群问题）， 或者使用锁机制，让抢到锁的一个worker进程去accept这个socket，注意这里一般使用select/poll/epoll机制来解决accept阻塞问题； 当一个新连接进来后，而只有抢到锁的一个进程可以accept这个连接进行处理（也是放入epoll中）； 抢到锁的worker进程accept到新连接后，会立即释放锁；然后所有worker进程再次参与抢锁，这样就回到了第二步，进行循环处理并发连接； 3.4、惊群问题 产生原因：像上面第二步，多个worker进程等待同一个socket的连接事件，当这个事件发生时，这些进程被同时唤醒，就是惊群。\n注意，在linux2.6内核上，accept系统调用已经不存在惊群，但用epoll机制来解决accept阻塞问题，epoll_wait会有惊群问题（新增 EPOLLEXCLUSIVE 选项解决了）。\n导致后果：许多worker进程被内核重新调度唤醒，只有一个进程可以accept这个连接进行处理，其他余者皆失败，导致性能浪费。\nnginx解决方案：使用锁机制，让抢到锁的一个worker进程去accept（epoll_wait）这个socket；如果操作系统支持原子整型，才会使用共享内存实现原子上锁，否则使用文件上锁。\n4、Nginx 配置 4.1、默认配置文件 /etc/nginx/nginx.conf\n","keywords":[],"articleBody":"Tomcat 稳定但不支持高并发，因此支持高并发的 Nginx 诞生了。Nginx使用基于事件驱动架构，使其可以支持数以百万级别的TCP连接。\n1、Nginx 应用场景 Nginx是一款高性能的HTTP服务器和反向代理服务器。Nginx 最常用的应用场景就是这两个。\n1.1、反向代理 正向代理，“它代理的是客户端，代客户端发出请求”，是一个位于客户端和原始服务器之间的中间服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。\n反向代理，“它代理的是服务端，代服务端接收请求”，主要用于服务器集群分布式部署的情况下，反向代理隐藏了服务器的信息。Nginx 作为服务端暴露的地址，所有客户端的请求都会进入 Nginx 服务器，然后由 Nginx 按照一定的规则将请求分发给具体的业务处理服务器，客户端并不知道是哪台服务器为自己服务，这里Nginx 扮演的就是反向代理服务器。\n反向代理的作用：\n保证内网的安全，通常将反向代理作为公网访问地址，Web服务器是内网 负载均衡，通过反向代理服务器来优化网站的负载 负载均衡\n上方提到的请求分发就是依据这里的负载均衡策略分发的。\n负载均衡分为硬件负载均衡和软件负载均衡两种，硬件如F5负载均衡，相对造价昂贵成本较高，但是数据的稳定性安全性高；除了移动联通等运营商使用的都是软件负载均衡，软件负载均衡是利用现有的技术结合主机硬件实现的一种消息队列分发机制。\nNginx支持的负载均衡调度算法如下：重点掌握权重轮询即可，其余的基本不用。但作为面试还是要能说出来。\n权重轮询(默认）：接收到的请求按照权重分配到不同的后端服务器，可以根据服务器的硬件性能配置不同的权重，权重越大被分配到请求的几率越大。 ip_hash：每个请求按照发起客户端的ip的hash结果进行匹配，对于一个固定ip地址的客户端总会访问到同一个后端服务器，这也在一定程度上解决了集群部署环境下session共享的问题。但是移动端的ip可能一直变化，所以较为鸡肋。 fair：智能调整调度算法，动态的根据后端服务器的响应时长进行均衡分配，响应时间短处理效率高的服务器分配到请求的概率高。Nginx默认不支持fair算法，需要安装upstream_fair模块。可能造成流量倾斜，大量请求进入响应时长短的服务器导致崩溃。 url_hash：按照访问的url的hash结果分配请求，每个请求的url会指向后端固定的某个服务器，可以在Nginx作为静态服务器的情况下提高缓存效率。同样要注意Nginx默认不支持这种调度算法，要使用的话需要安装Nginx的hash软件包。 1.2、web 服务器 可以先通过动态/静态内容分离，而后为静态内容（html/css/js/图片等）提供HTTP访问功能；而动态内容可以整合代理模块，代理给上游服务器，来支持对外部程序的直接调用或者解析。\n2、Nginx 基本架构 一个master进程生成多个worker子进程（每个进程只有一个线程），一个worker进程可以响应多个用户请求； 非阻塞、IO复用、事件驱动：select，poll， epoll， kqueue，/dev/poll； 支持sendfile，sendfile64； 支持文件AIO（异步I/O）； 支持mmap； 灵活的文件配置； 占用内存小：10,000个非活动HTTP保持连接占用大约2.5M内存。 3、Nginx 并发模型 一个master进程生成多个worker子进程（每个进程只有一个线程），一个worker响应多个用户请求。如果单进程启动：仅有一个进程，既充当master进程的角色，也充当worker进程的角色。\n3.1、master进程 充当整个进程组与用户的交互接口（接收来自外界的信号，向各worker进程发送信号），同时监控worker进程的运行状态。\n它不需要处理网络事件，不负责业务的执行，只会通过管理worker进程来实现重启服务、平滑升级、更换日志文件、配置文件实时生效等功能。\n3.2、worker进程 主要任务是处理基本的网络事件，完成具体的任务逻辑。多个worker进程之间是对等的，互相独立的。\nworker进程主要关注点是与客户端或后端服务器（此时nginx作为中间代理）之间的数据可读/可写等I/O交互事件，所以工作进程的阻塞点是在像select()、epoll_wait()等这样的I/O多路复用函数调用处，以等待发生数据可读/写事件。当然也可能被新收到的进程信号中断。\nworker进程个数：\n如果负载以CPU密集型应用为主，一般会设置与机器cpu核数一致或少一个（用来处理用户等其他任务）； 如果负载以IO密集型为主，如响应大量内容给客户端，则worker数应该为CPU个数的1.5或2倍。 因为更多的worker数，只会导致进程来竞争cpu资源了，从而带来不必要的上下文切换。而且，nginx为了更好的利用多核特性，具有cpu绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效。\n3.3、并发处理 在master进程里面，先创建socket，并bind、listen在80端口（所以master进程需要root权限）； 然后再fork出多个worker进程，这样每个worker进程都可以去accept这个socket（会产生惊群问题）， 或者使用锁机制，让抢到锁的一个worker进程去accept这个socket，注意这里一般使用select/poll/epoll机制来解决accept阻塞问题； 当一个新连接进来后，而只有抢到锁的一个进程可以accept这个连接进行处理（也是放入epoll中）； 抢到锁的worker进程accept到新连接后，会立即释放锁；然后所有worker进程再次参与抢锁，这样就回到了第二步，进行循环处理并发连接； 3.4、惊群问题 产生原因：像上面第二步，多个worker进程等待同一个socket的连接事件，当这个事件发生时，这些进程被同时唤醒，就是惊群。\n注意，在linux2.6内核上，accept系统调用已经不存在惊群，但用epoll机制来解决accept阻塞问题，epoll_wait会有惊群问题（新增 EPOLLEXCLUSIVE 选项解决了）。\n导致后果：许多worker进程被内核重新调度唤醒，只有一个进程可以accept这个连接进行处理，其他余者皆失败，导致性能浪费。\nnginx解决方案：使用锁机制，让抢到锁的一个worker进程去accept（epoll_wait）这个socket；如果操作系统支持原子整型，才会使用共享内存实现原子上锁，否则使用文件上锁。\n4、Nginx 配置 4.1、默认配置文件 /etc/nginx/nginx.conf\nhttp { include /etc/nginx/mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; # 一个 server 就是一个服务，通过下方的服务名和端口二元组唯一区别。 # 若有多个服务，请求过来后，从上往下匹配服务名和端口，第一次匹配到便停止，不会继续匹配。 server { listen 80; listen [::]:80; server_name localhost; # 可以是IP地址或域名，可以有多个域名，域名可以使用通配符。 # 此处和下方的错误页码路径全部是指向静态页面。 location / { root /usr/share/nginx/html; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } } } 4.2、反向代理 http { include /etc/nginx/mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server { listen 80; listen [::]:80; server_name localhost; location / { # 此处就是将请求转发给后边的地址，得到响应后再返回给用户。将地址改为需要反向代理的服务器IP即可。 proxy_pass https://ethereal-lu.github.io/; # root /usr/share/nginx/html; # index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } } } 4.3、负载均衡 http { include /etc/nginx/mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; # 将服务器列表放在这里，默认为权重轮询，如果都不设置weight，就是挨个轮询 upstream servers { server 192.168.36.128:80 weight=5; server 192.168.36.129:80 weight=8; # down 和 backup 只供学习，实际用处不大。因为每改一次配置需要重启nginx服务器，有这时间不如重启一台机器。 server 192.168.36.130:80 weight=2 down; # down 表示下线，不接受请求 server 192.168.36.130:80 weight=1 backup; # backup 表示备用，除非所有机器都不能用才用它，一般不会用它 } server { listen 80; listen [::]:80; server_name localhost; location / { # 代理多台服务器，这里名字 servers 必须和上方 upstream 后边的名字一致 proxy_pass servers; # root /usr/share/nginx/html; # index index.html index.htm; } error_page 500 502 503 504 /50x.html; # 错误码 500 502 503 504 会被转到 /50x.html 页面 location = /50x.html { root /usr/share/nginx/html; } } } 4.4、动静分离 适合中小型网站。因为静态资源需要放在 nginx 服务器中，大型网站的静态资源太多，就不适合只是放在 nginx 中了。\n在 浏览器、Nginx、Tomcat 结构中，浏览器先通过Nginx 的代理向Tomcat请求一个 html 页面，然后再根据页面中需要的资源通过Nginx向Tomcat请求大量的图片、js、css等静态资源。每个请求都必须经过Nginx到达Tomcat，为了减少不必要的请求，可以将静态资源放在Nginx服务器中，由于Nginx 本身的并发能力就高于 Tomcat，同时又减少了网络开销，所以能很大程度地提高性能。这就是动静分离。\n值得注意的是：tomcat 性能确实没 nginx 高，但是由于其使用了长连接和io多路复用，使得两者之间的差距没有达到指数级别。\n# 同一个 server 中可以有多个 location，每个 location 对应一个静态资源地址。 # 请求到达后会根据路径中的 uri 与这里的资源路径匹配，这里的匹配遵循精确匹配优先。 # 路径由 root 和 location 拼接而成，此处表示 /usr/share/nginx/html/ 下的所有资源。 location / { root /usr/share/nginx/html; index index.html index.htm; } # 支持正则表达式来表示路径， 开头的 ~ 表示后续的路径使用了正则表达式。 location ~ /(js|img|css) { root /usr/share/nginx/html; index index.html index.htm; } 4.5、URLRewrite 伪静态 可以通过 rewrite 关键字实现动态资源路径的隐藏。\nupstream servers { server 192.168.36.128:80 weight=5; server 192.168.36.129:80 weight=8; } server { listen 80; listen [::]:80; server_name localhost; location / { # 当请求的路径匹配到A时会自动访问到B，而url显示的还是A，这样就隐藏了动态路径B rewrite 正则表达式A 动态资源路径B break; proxy_pass servers; } } 4.6、防盗链 网站资源都有域的概念，浏览器加载一个站点时，首先加载这个站点的首页，一般是index.html，页面中包含文本、图片、样式等资源。这些静态资源以 src 的方式既可以拉取自本地也可以用一个完整的 url 拉取自其他的域。浏览器在页面呈现的过程，拉取非本站的资源，这就称“盗链”。\n从index.html请求图片等资源时，http 和浏览器会在这些请求的头部添加一个 Referer 的字段，该字段表明发起这些个请求的站点是谁。Nginx 可以获取到这些盗链的站点并进行拦截。\nserver { listen 80; listen [::]:80; server_name localhost; # 防盗链设置可以在任何需要的 location 中配置。 location ~ /(js|img|css) { # 此处配置信任的站点，一般就是自己的域；多个域名用空格隔开，可以使用 none 表示不携带 Referer 字段也可以请求 valid_referers localhost; if ($invalid_referer) { # 如果 Referer 字段中的域名不在上方的配置中，就直接返回 403。 return 403; # 此处还可以通过 rewrite 重定向到一个图片或网页 } root /usr/share/nginx/html; index index.html index.htm; } } 4.7、高可用配置 如果单点 Nginx 出现故障，则整个服务就不可用了。因此引入备份 Nginx ，当主 Nginx 出现故障就切换到备份 Nginx 继续服务。\n在Nginx高可用架构中，从局域网分配一个 IP 作为虚拟 IP(即图中的VIP)，所有的请求都通过虚拟IP到达主 Nginx 中，当主 Nginx 挂掉后，由 Keepalived 的心跳机制检测到并根据优先级重新选举 Master，然后 Master 通过 ARP 协议声明虚拟 IP 对应的 MAC 主机就是自己，之后到达虚拟 IP 的请求就会由新 Master 处理，这样就完成了主备切换。\nkeepalived 的工作原理\nNginx 服务器是否可用以及 IP 漂移都由 Keepalived负责。Keepalived是一个软件，它的核心原理是VRRP协议（虚拟路由器冗余协议）VRRP虚拟路由器由多个路由器组成，其工作过程为：\n虚拟路由器中的路由器根据优先级（在配置文件中手动配置）选举出Master。Master路由器通过发送ARP报文，声明自己为虚拟 IP 的占有者，从而承担报文转发任务。 Master路由器周期性发送VRRP报文（心跳），以公布其配置信息（优先级等）和工作状况 如果Master路由器出现故障，虚拟路由器中的Backup路由器收不到心跳信息，就会根据优先级重新选举新的Master 新的Master路由器同样通过发送ARP报文，声明自己为虚拟 IP 的占有者。网络中的主机感知不到Master路由器已经切换为另外一台设备 keepalived 进程和 Nginx 进程是两个独立的进程，只有当主机出现故障才能正常主备切换；而主机正常 Nginx 进程出错时，keepalived 不起作用，所以可以另外写一个脚本，周期检测 Nginx 进程是否正常，如果异常就杀掉 keepalived 进程，使其进行主备切换。\nkeepalived 不仅可以用于 Nginx ，其他任何分布式集群的检测都可以使用 keepalived ，工作模式和上述一致。\n","wordCount":"485","inLanguage":"en","datePublished":"2022-05-30T22:42:15Z","dateModified":"2022-05-30T22:42:15Z","author":{"@type":"Person","name":"lu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://ethereal-lu.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F/nginx/nginx%E5%9F%BA%E7%A1%80/"},"publisher":{"@type":"Organization","name":"lu","logo":{"@type":"ImageObject","url":"https://ethereal-lu.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://ethereal-lu.github.io/ accesskey=h title="lu (Alt + H)">lu</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://ethereal-lu.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://ethereal-lu.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://ethereal-lu.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://ethereal-lu.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Nginx基础</h1><div class=post-meta><span title='2022-05-30 22:42:15 +0000 UTC'>2022-05-30</span>&nbsp;·&nbsp;485 words&nbsp;·&nbsp;lu</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#1nginx-应用场景>1、Nginx 应用场景</a><ul><li><a href=#11反向代理>1.1、反向代理</a></li><li><a href=#12web-服务器>1.2、web 服务器</a></li></ul></li><li><a href=#2nginx-基本架构>2、Nginx 基本架构</a></li><li><a href=#3nginx-并发模型>3、Nginx 并发模型</a><ul><li><a href=#31master进程>3.1、master进程</a></li><li><a href=#32worker进程>3.2、worker进程</a></li><li><a href=#33并发处理>3.3、并发处理</a></li><li><a href=#34惊群问题>3.4、惊群问题</a></li></ul></li><li><a href=#4nginx-配置>4、Nginx 配置</a><ul><li><a href=#41默认配置文件>4.1、默认配置文件</a></li><li><a href=#42反向代理>4.2、反向代理</a></li><li><a href=#43负载均衡>4.3、负载均衡</a></li><li><a href=#44动静分离>4.4、动静分离</a></li><li><a href=#45urlrewrite-伪静态>4.5、URLRewrite 伪静态</a></li><li><a href=#46防盗链>4.6、防盗链</a></li><li><a href=#47高可用配置>4.7、高可用配置</a></li></ul></li></ul></nav></div></details></div><div class=post-content><p>Tomcat 稳定但不支持高并发，因此支持高并发的 Nginx 诞生了。Nginx使用基于事件驱动架构，使其可以支持数以百万级别的TCP连接。</p><h2 id=1nginx-应用场景>1、Nginx 应用场景<a hidden class=anchor aria-hidden=true href=#1nginx-应用场景>#</a></h2><p>Nginx是一款高性能的HTTP服务器和反向代理服务器。Nginx 最常用的应用场景就是这两个。</p><h3 id=11反向代理>1.1、反向代理<a hidden class=anchor aria-hidden=true href=#11反向代理>#</a></h3><p><strong>正向代理</strong>，&ldquo;它代理的是客户端，代客户端发出请求&rdquo;，是一个位于客户端和原始服务器之间的中间服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。</p><p><strong>反向代理</strong>，&ldquo;它代理的是服务端，代服务端接收请求&rdquo;，主要用于服务器集群分布式部署的情况下，反向代理隐藏了服务器的信息。Nginx 作为服务端暴露的地址，所有客户端的请求都会进入 Nginx 服务器，然后由 Nginx 按照一定的规则将请求分发给具体的业务处理服务器，客户端并不知道是哪台服务器为自己服务，这里Nginx 扮演的就是反向代理服务器。</p><p>反向代理的作用：</p><ul><li>保证内网的安全，通常将反向代理作为公网访问地址，Web服务器是内网</li><li>负载均衡，通过反向代理服务器来优化网站的负载</li></ul><p><strong>负载均衡</strong></p><p>上方提到的请求分发就是依据这里的负载均衡策略分发的。</p><p>负载均衡分为硬件负载均衡和软件负载均衡两种，硬件如F5负载均衡，相对造价昂贵成本较高，但是数据的稳定性安全性高；除了移动联通等运营商使用的都是软件负载均衡，软件负载均衡是利用现有的技术结合主机硬件实现的一种消息队列分发机制。</p><p>Nginx支持的负载均衡调度算法如下：<strong>重点掌握权重轮询即可，其余的基本不用。但作为面试还是要能说出来。</strong></p><ul><li>权重轮询(默认）：接收到的请求按照权重分配到不同的后端服务器，可以根据服务器的硬件性能配置不同的权重，权重越大被分配到请求的几率越大。</li><li>ip_hash：每个请求按照发起客户端的ip的hash结果进行匹配，对于一个固定ip地址的客户端总会访问到同一个后端服务器，这也在一定程度上解决了集群部署环境下session共享的问题。但是移动端的ip可能一直变化，所以较为鸡肋。</li><li>fair：智能调整调度算法，动态的根据后端服务器的响应时长进行均衡分配，响应时间短处理效率高的服务器分配到请求的概率高。Nginx默认不支持fair算法，需要安装upstream_fair模块。可能造成流量倾斜，大量请求进入响应时长短的服务器导致崩溃。</li><li>url_hash：按照访问的url的hash结果分配请求，每个请求的url会指向后端固定的某个服务器，可以在Nginx作为静态服务器的情况下提高缓存效率。同样要注意Nginx默认不支持这种调度算法，要使用的话需要安装Nginx的hash软件包。</li></ul><h3 id=12web-服务器>1.2、web 服务器<a hidden class=anchor aria-hidden=true href=#12web-服务器>#</a></h3><p>可以先通过动态/静态内容分离，而后为静态内容（html/css/js/图片等）提供HTTP访问功能；而动态内容可以整合代理模块，代理给上游服务器，来支持对外部程序的直接调用或者解析。</p><h2 id=2nginx-基本架构>2、Nginx 基本架构<a hidden class=anchor aria-hidden=true href=#2nginx-基本架构>#</a></h2><ul><li>一个master进程生成多个worker子进程（每个进程只有一个线程），一个worker进程可以响应多个用户请求；</li><li>非阻塞、IO复用、事件驱动：select，poll， epoll， kqueue，/dev/poll；</li><li>支持sendfile，sendfile64；</li><li>支持文件AIO（异步I/O）；</li><li>支持mmap；</li><li>灵活的文件配置；</li><li>占用内存小：10,000个非活动HTTP保持连接占用大约2.5M内存。</li></ul><h2 id=3nginx-并发模型>3、Nginx 并发模型<a hidden class=anchor aria-hidden=true href=#3nginx-并发模型>#</a></h2><p>一个master进程生成多个worker子进程（每个进程只有一个线程），一个worker响应多个用户请求。如果单进程启动：仅有一个进程，既充当master进程的角色，也充当worker进程的角色。</p><h3 id=31master进程>3.1、master进程<a hidden class=anchor aria-hidden=true href=#31master进程>#</a></h3><p>充当整个进程组与用户的交互接口（接收来自外界的信号，向各worker进程发送信号），同时监控worker进程的运行状态。</p><p>它不需要处理网络事件，不负责业务的执行，只会通过管理worker进程来实现重启服务、平滑升级、更换日志文件、配置文件实时生效等功能。</p><h3 id=32worker进程>3.2、worker进程<a hidden class=anchor aria-hidden=true href=#32worker进程>#</a></h3><p>主要任务是处理基本的网络事件，完成具体的任务逻辑。多个worker进程之间是对等的，互相独立的。</p><p>worker进程主要关注点是与客户端或后端服务器（此时nginx作为中间代理）之间的数据可读/可写等I/O交互事件，所以工作进程的阻塞点是在像select()、epoll_wait()等这样的I/O多路复用函数调用处，以等待发生数据可读/写事件。当然也可能被新收到的进程信号中断。</p><p>worker进程个数：</p><ul><li>如果负载以CPU密集型应用为主，一般会设置与机器cpu核数一致或少一个（用来处理用户等其他任务）；</li><li>如果负载以IO密集型为主，如响应大量内容给客户端，则worker数应该为CPU个数的1.5或2倍。</li></ul><p>因为更多的worker数，只会导致进程来竞争cpu资源了，从而带来不必要的上下文切换。而且，nginx为了更好的利用多核特性，具有cpu绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效。</p><h3 id=33并发处理>3.3、并发处理<a hidden class=anchor aria-hidden=true href=#33并发处理>#</a></h3><ol><li>在master进程里面，先创建socket，并bind、listen在80端口（所以master进程需要root权限）；</li><li>然后再fork出多个worker进程，这样每个worker进程都可以去accept这个socket（会产生惊群问题）， 或者使用锁机制，让抢到锁的一个worker进程去accept这个socket，注意这里一般使用select/poll/epoll机制来解决accept阻塞问题；</li><li>当一个新连接进来后，而只有抢到锁的一个进程可以accept这个连接进行处理（也是放入epoll中）；</li><li>抢到锁的worker进程accept到新连接后，会立即释放锁；然后所有worker进程再次参与抢锁，这样就回到了第二步，进行循环处理并发连接；</li></ol><h3 id=34惊群问题>3.4、惊群问题<a hidden class=anchor aria-hidden=true href=#34惊群问题>#</a></h3><p>产生原因：像上面第二步，多个worker进程等待同一个socket的连接事件，当这个事件发生时，这些进程被同时唤醒，就是惊群。</p><p>注意，在linux2.6内核上，accept系统调用已经不存在惊群，但用epoll机制来解决accept阻塞问题，epoll_wait会有惊群问题（新增 EPOLLEXCLUSIVE 选项解决了）。</p><p>导致后果：许多worker进程被内核重新调度唤醒，只有一个进程可以accept这个连接进行处理，其他余者皆失败，导致性能浪费。</p><p>nginx解决方案：使用锁机制，让抢到锁的一个worker进程去accept（epoll_wait）这个socket；如果操作系统支持原子整型，才会使用共享内存实现原子上锁，否则使用文件上锁。</p><h2 id=4nginx-配置>4、Nginx 配置<a hidden class=anchor aria-hidden=true href=#4nginx-配置>#</a></h2><h3 id=41默认配置文件>4.1、默认配置文件<a hidden class=anchor aria-hidden=true href=#41默认配置文件>#</a></h3><p><code>/etc/nginx/nginx.conf</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#ae81ff>http {</span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>include       /etc/nginx/mime.types;</span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>default_type  application/octet-stream;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>sendfile        on;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>keepalive_timeout  65;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>	<span style=color:#75715e># 一个 server 就是一个服务，通过下方的服务名和端口二元组唯一区别。</span>
</span></span><span style=display:flex><span>	<span style=color:#75715e># 若有多个服务，请求过来后，从上往下匹配服务名和端口，第一次匹配到便停止，不会继续匹配。</span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>server {</span>
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>listen       80;</span>
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>listen  [::]:80;</span>
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>server_name  localhost;  </span> <span style=color:#75715e># 可以是IP地址或域名，可以有多个域名，域名可以使用通配符。</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>		<span style=color:#75715e># 此处和下方的错误页码路径全部是指向静态页面。</span>
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>location / {</span>
</span></span><span style=display:flex><span>            <span style=color:#ae81ff>root   /usr/share/nginx/html;</span>
</span></span><span style=display:flex><span>            <span style=color:#ae81ff>index  index.html index.htm;</span>
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>error_page   500 502 503 504  /50x.html;</span>
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>location = /50x.html {</span>
</span></span><span style=display:flex><span>            <span style=color:#ae81ff>root   /usr/share/nginx/html;</span>
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=42反向代理>4.2、反向代理<a hidden class=anchor aria-hidden=true href=#42反向代理>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#ae81ff>http {</span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>include       /etc/nginx/mime.types;</span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>default_type  application/octet-stream;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>sendfile        on;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>keepalive_timeout  65;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>server {</span>
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>listen       80;</span>
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>listen  [::]:80;</span>
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>server_name  localhost;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>location / {</span>
</span></span><span style=display:flex><span>        	<span style=color:#75715e># 此处就是将请求转发给后边的地址，得到响应后再返回给用户。将地址改为需要反向代理的服务器IP即可。</span>
</span></span><span style=display:flex><span>        	<span style=color:#ae81ff>proxy_pass https://ethereal-lu.github.io/;    </span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># root   /usr/share/nginx/html;</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># index  index.html index.htm;</span>
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>error_page   500 502 503 504  /50x.html;</span>
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>location = /50x.html {</span>
</span></span><span style=display:flex><span>            <span style=color:#ae81ff>root   /usr/share/nginx/html;</span>
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=43负载均衡>4.3、负载均衡<a hidden class=anchor aria-hidden=true href=#43负载均衡>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#ae81ff>http {</span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>include       /etc/nginx/mime.types;</span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>default_type  application/octet-stream;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>sendfile        on;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>keepalive_timeout  65;</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 将服务器列表放在这里，默认为权重轮询，如果都不设置weight，就是挨个轮询</span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>upstream servers {</span>
</span></span><span style=display:flex><span>    	<span style=color:#ae81ff>server 192.168.36.128:80 weight=5;</span>
</span></span><span style=display:flex><span>    	<span style=color:#ae81ff>server 192.168.36.129:80 weight=8;</span>
</span></span><span style=display:flex><span>    	<span style=color:#75715e># down 和 backup 只供学习，实际用处不大。因为每改一次配置需要重启nginx服务器，有这时间不如重启一台机器。</span>
</span></span><span style=display:flex><span>    	<span style=color:#ae81ff>server 192.168.36.130:80 weight=2 down;      </span> <span style=color:#75715e># down 表示下线，不接受请求</span>
</span></span><span style=display:flex><span>    	<span style=color:#ae81ff>server 192.168.36.130:80 weight=1 backup;    </span> <span style=color:#75715e># backup 表示备用，除非所有机器都不能用才用它，一般不会用它</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>server {</span>
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>listen       80;</span>
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>listen  [::]:80;</span>
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>server_name  localhost;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>location / {</span>
</span></span><span style=display:flex><span>        	<span style=color:#75715e># 代理多台服务器，这里名字 servers 必须和上方 upstream 后边的名字一致</span>
</span></span><span style=display:flex><span>        	<span style=color:#ae81ff>proxy_pass servers;    </span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># root   /usr/share/nginx/html;</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># index  index.html index.htm;</span>
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>error_page   500 502 503 504  /50x.html;  </span> <span style=color:#75715e># 错误码 500 502 503 504 会被转到 /50x.html 页面</span>
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>location = /50x.html {</span>
</span></span><span style=display:flex><span>            <span style=color:#ae81ff>root   /usr/share/nginx/html;</span>
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=44动静分离>4.4、动静分离<a hidden class=anchor aria-hidden=true href=#44动静分离>#</a></h3><p>适合中小型网站。因为静态资源需要放在 nginx 服务器中，大型网站的静态资源太多，就不适合只是放在 nginx 中了。</p><p>在 浏览器、Nginx、Tomcat 结构中，浏览器先通过Nginx 的代理向Tomcat请求一个 html 页面，然后再根据页面中需要的资源通过Nginx向Tomcat请求大量的图片、js、css等静态资源。每个请求都必须经过Nginx到达Tomcat，为了减少不必要的请求，可以将静态资源放在Nginx服务器中，由于Nginx 本身的并发能力就高于 Tomcat，同时又减少了网络开销，所以能很大程度地提高性能。这就是动静分离。</p><p>值得注意的是：tomcat 性能确实没 nginx 高，但是由于其使用了长连接和io多路复用，使得两者之间的差距没有达到指数级别。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#75715e># 同一个 server 中可以有多个 location，每个 location 对应一个静态资源地址。</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 请求到达后会根据路径中的 uri 与这里的资源路径匹配，这里的匹配遵循精确匹配优先。</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 路径由 root 和 location 拼接而成，此处表示 /usr/share/nginx/html/ 下的所有资源。</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>location / { </span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>root   /usr/share/nginx/html;</span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>index  index.html index.htm;</span>
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 支持正则表达式来表示路径， 开头的 ~ 表示后续的路径使用了正则表达式。</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>location ~ /(js|img|css) { </span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>root   /usr/share/nginx/html;</span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>index  index.html index.htm;</span>
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=45urlrewrite-伪静态>4.5、URLRewrite 伪静态<a hidden class=anchor aria-hidden=true href=#45urlrewrite-伪静态>#</a></h3><p>可以通过 rewrite 关键字实现动态资源路径的隐藏。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#ae81ff>upstream servers {</span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>server 192.168.36.128:80 weight=5;</span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>server 192.168.36.129:80 weight=8;</span>
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>server {</span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>listen       80;</span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>listen  [::]:80;</span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>server_name  localhost;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>location / {</span>
</span></span><span style=display:flex><span>    	<span style=color:#75715e># 当请求的路径匹配到A时会自动访问到B，而url显示的还是A，这样就隐藏了动态路径B</span>
</span></span><span style=display:flex><span>    	<span style=color:#ae81ff>rewrite 正则表达式A  动态资源路径B  break;</span>
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>proxy_pass servers;    </span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=46防盗链>4.6、防盗链<a hidden class=anchor aria-hidden=true href=#46防盗链>#</a></h3><p>网站资源都有域的概念，浏览器加载一个站点时，首先加载这个站点的首页，一般是index.html，页面中包含文本、图片、样式等资源。这些静态资源以 src 的方式既可以拉取自本地也可以用一个完整的 url 拉取自其他的域。浏览器在页面呈现的过程，拉取非本站的资源，这就称“<strong>盗链</strong>”。</p><p>从index.html请求图片等资源时，http 和浏览器会在这些请求的头部添加一个 Referer 的字段，该字段表明发起这些个请求的站点是谁。Nginx 可以获取到这些盗链的站点并进行拦截。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#ae81ff>server {</span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>listen       80;</span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>listen  [::]:80;</span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>server_name  localhost;</span>
</span></span><span style=display:flex><span>	
</span></span><span style=display:flex><span>	<span style=color:#75715e># 防盗链设置可以在任何需要的 location 中配置。</span>
</span></span><span style=display:flex><span>    <span style=color:#ae81ff>location ~ /(js|img|css) { </span>
</span></span><span style=display:flex><span>    	<span style=color:#75715e># 此处配置信任的站点，一般就是自己的域；多个域名用空格隔开，可以使用 none 表示不携带 Referer 字段也可以请求</span>
</span></span><span style=display:flex><span>    	<span style=color:#ae81ff>valid_referers localhost;</span>
</span></span><span style=display:flex><span>    	<span style=color:#ae81ff>if ($invalid_referer) {  </span> <span style=color:#75715e># 如果 Referer 字段中的域名不在上方的配置中，就直接返回 403。</span>
</span></span><span style=display:flex><span>    		<span style=color:#ae81ff>return 403;          </span> <span style=color:#75715e># 此处还可以通过 rewrite 重定向到一个图片或网页</span>
</span></span><span style=display:flex><span>    	}
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>root   /usr/share/nginx/html;</span>
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>index  index.html index.htm;</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=47高可用配置>4.7、高可用配置<a hidden class=anchor aria-hidden=true href=#47高可用配置>#</a></h3><p><img alt=Nginx高可用架构 loading=lazy src=/posts/%E5%88%86%E5%B8%83%E5%BC%8F/nginx/nginx%E5%9F%BA%E7%A1%80/Nginx%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84.jpg></p><p>如果单点 Nginx 出现故障，则整个服务就不可用了。因此引入备份 Nginx ，当主 Nginx 出现故障就切换到备份 Nginx 继续服务。</p><p>在Nginx高可用架构中，从局域网分配一个 IP 作为虚拟 IP(即图中的VIP)，所有的请求都通过虚拟IP到达主 Nginx 中，当主 Nginx 挂掉后，由 Keepalived 的心跳机制检测到并根据优先级重新选举 Master，然后 Master 通过 ARP 协议声明虚拟 IP 对应的 MAC 主机就是自己，之后到达虚拟 IP 的请求就会由新 Master 处理，这样就完成了主备切换。</p><p><strong>keepalived 的工作原理</strong></p><p>Nginx 服务器是否可用以及 IP 漂移都由 Keepalived负责。Keepalived是一个软件，它的核心原理是VRRP协议（虚拟路由器冗余协议）VRRP虚拟路由器由多个路由器组成，其工作过程为：</p><ol><li>虚拟路由器中的路由器根据优先级（在配置文件中手动配置）选举出Master。Master路由器通过发送ARP报文，声明自己为虚拟 IP 的占有者，从而承担报文转发任务。</li><li>Master路由器周期性发送VRRP报文（心跳），以公布其配置信息（优先级等）和工作状况</li><li>如果Master路由器出现故障，虚拟路由器中的Backup路由器收不到心跳信息，就会根据优先级重新选举新的Master</li><li>新的Master路由器同样通过发送ARP报文，声明自己为虚拟 IP 的占有者。网络中的主机感知不到Master路由器已经切换为另外一台设备</li></ol><p>keepalived 进程和 Nginx 进程是两个独立的进程，只有当主机出现故障才能正常主备切换；而主机正常 Nginx 进程出错时，keepalived 不起作用，所以可以另外写一个脚本，周期检测 Nginx 进程是否正常，如果异常就杀掉 keepalived 进程，使其进行主备切换。</p><p>keepalived 不仅可以用于 Nginx ，其他任何分布式集群的检测都可以使用 keepalived ，工作模式和上述一致。</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://ethereal-lu.github.io/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/http/><span class=title>« Prev</span><br><span>HTTP</span>
</a><a class=next href=https://ethereal-lu.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%9F%BA%E7%A1%80/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/><span class=title>Next »</span><br><span>分布式锁</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://ethereal-lu.github.io/>lu</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>