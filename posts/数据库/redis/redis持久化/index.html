<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Redis持久化 | lu</title>
<meta name=keywords content><meta name=description content="1、Redis 核心主流程
AOF 和 RDB 的持久化过程中，有不少操作是在时间事件 serverCron 中被触发的。所以，这边有必要先了解下 Redis 中的事件核心流程。
Redis 的服务器进程就是一个事件循环，最重要的有两个事件：文件事件和时间事件。Redis 在服务器初始化后，会无限循环，处理产生的文件事件和时间事件。
文件事件常见的有：接受连接（accept）、读取（read）、写入（write）、关闭连接（close）等。使用 IO 多路复用处理。
时间事件中常见的就是 serverCron，redis 核心流程中通常也只有这个时间事件。serverCron 默认配置下每100ms会被触发一次，在该时间事件中，会执行很多操作：清理过期键、AOF 后台重写、RDB 的 save point 的检查、将 aof_buf 内容写到磁盘上（flushAppendOnlyFile 函数）等等。
2、Redis持久化
Redis是内存数据库，若不持久化到磁盘中，则redis进程一旦退出，数据就会丢失，因此需要持久化。
Redis 的持久化机制有以下三种：

RDB
AOF
混合持久化（redis4.0引入）

2.1、RDB(Redis DataBase)
描述：类似于快照。在某个时间点，将 Redis 在内存中的数据保存到磁盘里面。RDB 持久化功能生成的 RDB 文件是经过压缩的二进制文件。恢复时将快照文件直接读入内存。
rdb保存的文件是dump.rdb。同样可以在redis.conf中修改
在redis.conf中对自动保存的间隔进行设置
# save 3600 1        After 3600 seconds (an hour) if at least 1 key changed
# save 300 100       After 300 seconds (5 minutes) if at least 100 keys changed
# save 60 10000      After 60 seconds if at least 10000 keys changed
2.1.1、触发条件
自动触发（全部是BGSAVE）"><meta name=author content="lu"><link rel=canonical href=https://ethereal-lu.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=https://ethereal-lu.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://ethereal-lu.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://ethereal-lu.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://ethereal-lu.github.io/apple-touch-icon.png><link rel=mask-icon href=https://ethereal-lu.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://ethereal-lu.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://ethereal-lu.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/"><meta property="og:site_name" content="lu"><meta property="og:title" content="Redis持久化"><meta property="og:description" content="1、Redis 核心主流程 AOF 和 RDB 的持久化过程中，有不少操作是在时间事件 serverCron 中被触发的。所以，这边有必要先了解下 Redis 中的事件核心流程。
Redis 的服务器进程就是一个事件循环，最重要的有两个事件：文件事件和时间事件。Redis 在服务器初始化后，会无限循环，处理产生的文件事件和时间事件。
文件事件常见的有：接受连接（accept）、读取（read）、写入（write）、关闭连接（close）等。使用 IO 多路复用处理。
时间事件中常见的就是 serverCron，redis 核心流程中通常也只有这个时间事件。serverCron 默认配置下每100ms会被触发一次，在该时间事件中，会执行很多操作：清理过期键、AOF 后台重写、RDB 的 save point 的检查、将 aof_buf 内容写到磁盘上（flushAppendOnlyFile 函数）等等。
2、Redis持久化 Redis是内存数据库，若不持久化到磁盘中，则redis进程一旦退出，数据就会丢失，因此需要持久化。
Redis 的持久化机制有以下三种：
RDB AOF 混合持久化（redis4.0引入） 2.1、RDB(Redis DataBase) 描述：类似于快照。在某个时间点，将 Redis 在内存中的数据保存到磁盘里面。RDB 持久化功能生成的 RDB 文件是经过压缩的二进制文件。恢复时将快照文件直接读入内存。
rdb保存的文件是dump.rdb。同样可以在redis.conf中修改
在redis.conf中对自动保存的间隔进行设置 # save 3600 1 After 3600 seconds (an hour) if at least 1 key changed # save 300 100 After 300 seconds (5 minutes) if at least 100 keys changed # save 60 10000 After 60 seconds if at least 10000 keys changed 2.1.1、触发条件 自动触发（全部是BGSAVE）"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-04-09T23:39:41+00:00"><meta property="article:modified_time" content="2022-04-09T23:39:41+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Redis持久化"><meta name=twitter:description content="1、Redis 核心主流程
AOF 和 RDB 的持久化过程中，有不少操作是在时间事件 serverCron 中被触发的。所以，这边有必要先了解下 Redis 中的事件核心流程。
Redis 的服务器进程就是一个事件循环，最重要的有两个事件：文件事件和时间事件。Redis 在服务器初始化后，会无限循环，处理产生的文件事件和时间事件。
文件事件常见的有：接受连接（accept）、读取（read）、写入（write）、关闭连接（close）等。使用 IO 多路复用处理。
时间事件中常见的就是 serverCron，redis 核心流程中通常也只有这个时间事件。serverCron 默认配置下每100ms会被触发一次，在该时间事件中，会执行很多操作：清理过期键、AOF 后台重写、RDB 的 save point 的检查、将 aof_buf 内容写到磁盘上（flushAppendOnlyFile 函数）等等。
2、Redis持久化
Redis是内存数据库，若不持久化到磁盘中，则redis进程一旦退出，数据就会丢失，因此需要持久化。
Redis 的持久化机制有以下三种：

RDB
AOF
混合持久化（redis4.0引入）

2.1、RDB(Redis DataBase)
描述：类似于快照。在某个时间点，将 Redis 在内存中的数据保存到磁盘里面。RDB 持久化功能生成的 RDB 文件是经过压缩的二进制文件。恢复时将快照文件直接读入内存。
rdb保存的文件是dump.rdb。同样可以在redis.conf中修改
在redis.conf中对自动保存的间隔进行设置
# save 3600 1        After 3600 seconds (an hour) if at least 1 key changed
# save 300 100       After 300 seconds (5 minutes) if at least 100 keys changed
# save 60 10000      After 60 seconds if at least 10000 keys changed
2.1.1、触发条件
自动触发（全部是BGSAVE）"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://ethereal-lu.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Redis持久化","item":"https://ethereal-lu.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Redis持久化","name":"Redis持久化","description":"1、Redis 核心主流程 AOF 和 RDB 的持久化过程中，有不少操作是在时间事件 serverCron 中被触发的。所以，这边有必要先了解下 Redis 中的事件核心流程。\nRedis 的服务器进程就是一个事件循环，最重要的有两个事件：文件事件和时间事件。Redis 在服务器初始化后，会无限循环，处理产生的文件事件和时间事件。\n文件事件常见的有：接受连接（accept）、读取（read）、写入（write）、关闭连接（close）等。使用 IO 多路复用处理。\n时间事件中常见的就是 serverCron，redis 核心流程中通常也只有这个时间事件。serverCron 默认配置下每100ms会被触发一次，在该时间事件中，会执行很多操作：清理过期键、AOF 后台重写、RDB 的 save point 的检查、将 aof_buf 内容写到磁盘上（flushAppendOnlyFile 函数）等等。\n2、Redis持久化 Redis是内存数据库，若不持久化到磁盘中，则redis进程一旦退出，数据就会丢失，因此需要持久化。\nRedis 的持久化机制有以下三种：\nRDB AOF 混合持久化（redis4.0引入） 2.1、RDB(Redis DataBase) 描述：类似于快照。在某个时间点，将 Redis 在内存中的数据保存到磁盘里面。RDB 持久化功能生成的 RDB 文件是经过压缩的二进制文件。恢复时将快照文件直接读入内存。\nrdb保存的文件是dump.rdb。同样可以在redis.conf中修改\n在redis.conf中对自动保存的间隔进行设置 # save 3600 1 After 3600 seconds (an hour) if at least 1 key changed # save 300 100 After 300 seconds (5 minutes) if at least 100 keys changed # save 60 10000 After 60 seconds if at least 10000 keys changed 2.1.1、触发条件 自动触发（全部是BGSAVE）\n","keywords":[],"articleBody":"1、Redis 核心主流程 AOF 和 RDB 的持久化过程中，有不少操作是在时间事件 serverCron 中被触发的。所以，这边有必要先了解下 Redis 中的事件核心流程。\nRedis 的服务器进程就是一个事件循环，最重要的有两个事件：文件事件和时间事件。Redis 在服务器初始化后，会无限循环，处理产生的文件事件和时间事件。\n文件事件常见的有：接受连接（accept）、读取（read）、写入（write）、关闭连接（close）等。使用 IO 多路复用处理。\n时间事件中常见的就是 serverCron，redis 核心流程中通常也只有这个时间事件。serverCron 默认配置下每100ms会被触发一次，在该时间事件中，会执行很多操作：清理过期键、AOF 后台重写、RDB 的 save point 的检查、将 aof_buf 内容写到磁盘上（flushAppendOnlyFile 函数）等等。\n2、Redis持久化 Redis是内存数据库，若不持久化到磁盘中，则redis进程一旦退出，数据就会丢失，因此需要持久化。\nRedis 的持久化机制有以下三种：\nRDB AOF 混合持久化（redis4.0引入） 2.1、RDB(Redis DataBase) 描述：类似于快照。在某个时间点，将 Redis 在内存中的数据保存到磁盘里面。RDB 持久化功能生成的 RDB 文件是经过压缩的二进制文件。恢复时将快照文件直接读入内存。\nrdb保存的文件是dump.rdb。同样可以在redis.conf中修改\n在redis.conf中对自动保存的间隔进行设置 # save 3600 1 After 3600 seconds (an hour) if at least 1 key changed # save 300 100 After 300 seconds (5 minutes) if at least 100 keys changed # save 60 10000 After 60 seconds if at least 10000 keys changed 2.1.1、触发条件 自动触发（全部是BGSAVE）\n满足上方save的规则\n执行flushall，生成的 dump.rdb 为空。\n退出reids\n手动触发\nSAVE：生成 RDB 快照文件，但是会阻塞主进程，服务器将无法处理客户端发来的命令请求，所以通常不会直接使用该命令。 BGSAVE：fork 子进程来生成 RDB 快照文件，阻塞只会发生在 fork 子进程的时候，之后主进程可以正常处理请求。会先将数据保存进一个临时文件中，待持久化过程结束了，再将这个临时文件替换上次持久化的文件。 2.1.2、恢复rdb文件 # 若rdb文件在下方目录下，则启动时会自动回复其中的数据 127.0.0.1:6379\u003e CONFIG GET dir 1) \"dir\" 2) \"/usr/local/bin\" 2.1.3、RDB 的优缺点 RDB 的优点：\nRDB 文件是是经过压缩的二进制文件，占用空间很小，它保存了 Redis 某个时间点的数据集，很适合用于做备份。 RDB 非常适用于灾难恢复：它只有一个文件，并且内容都非常紧凑，可以（在加密后）将它传送到别的数据中心。 RDB 可以最大化 redis 的性能。父进程在保存 RDB 文件时唯一要做的就是 fork 出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘 I/O 操作。 RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。 RDB 的缺点：\nRDB 在服务器故障时容易造成数据的丢失。RDB 允许我们通过修改 save point 配置来控制持久化的频率。但是，因为 RDB 文件需要保存整个数据集的状态， 所以它是一个比较重的操作，如果频率太频繁，可能会对 Redis 性能产生影响。所以通常可能设置至少5分钟才保存一次快照，这时如果 Redis 出现宕机等情况，则意味着最多可能丢失5分钟数据。\nRDB 保存时使用 fork 子进程进行数据的持久化，如果数据比较大的话，fork 可能会非常耗时，造成 Redis 停止处理服务N毫秒。如果数据集很大且 CPU 比较繁忙的时候，停止服务的时间甚至会到一秒。\nLinux fork 子进程采用的是 copy-on-write 的方式。在 Redis 执行 RDB 持久化期间，如果 client 写入数据很频繁，那么将增加 Redis 占用的内存，最坏情况下，内存的占用将达到原先的2倍。刚 fork 时，主进程和子进程共享内存，但是随着主进程需要处理写操作，主进程需要将修改的页面拷贝一份出来，然后进行修改。极端情况下，如果所有的页面都被修改，则此时的内存占用是原先的2倍。\n2.2、AOF(Append Only File) 将所有写命令都记录到文件中，恢复时把该文件再执行一遍，只允许追加该记录文件，不允许修改。该记录文件的名字为appendonly.aof。该功能默认不开启，可以通过配置：appendonly yes 开启， appendonly no 关闭。\n2.2.1、AOF的实现 AOF 持久化功能的实现可以分为三个步骤：命令追加、文件写入、文件同步。\n命令追加：当 AOF 持久化功能打开时，服务器在执行完一个写命令之后，会将被执行的写命令追加到服务器状态的 aof 缓冲区（aof_buf）的末尾。\n文件写入：将 aof_buf 的内容写到页缓存\n文件同步：将页缓存刷盘到硬盘\nserverCron 时间事件中会触发 flushAppendOnlyFile 函数，该函数会根据服务器配置的 appendfsync 参数值，来决定是否将 aof_buf 缓冲区的内容写入和保存到 AOF 文件。\nappendfsync 参数有三个选项：\nalways：每个命令都刷盘。\neverysec：每秒刷盘1次，这个操作是异步的，由一个后台线程专门负责执行。\nno：不执行刷盘，让操作系统自己执行刷盘。\n2.2.2、AOF 的优缺点 AOF 的优点\nAOF 比 RDB可靠。可以设置不同的 fsync 策略：no、everysec 和 always。默认是 everysec，在这种配置下，redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据。\nAOF文件是一个纯追加的日志文件。即使日志因为某些原因而包含了未写入完整的命令（比如写入时磁盘已满，写入中途停机等等）， 我们也可以使用 redis-check-aof 工具也可以轻易地修复这种问题。\n当 AOF文件太大时，Redis 会自动在后台进行重写：重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。整个重写是绝对安全，因为重写是在一个新的文件上进行，同时 Redis 会继续往旧的文件追加数据。当新文件重写完毕，Redis 会把新旧文件进行切换，然后开始把数据写到新文件上。\n易读\nAOF 的缺点\n对于相同的数据集，AOF 文件的大小一般会比 RDB 文件大。\n根据所使用的 fsync 策略，AOF 的速度可能会比 RDB 慢。通常 fsync 设置为每秒一次就能获得比较高的性能，而关闭 fsync 可以让 AOF 的速度和 RDB 一样快。\nAOF 在过去曾经发生过这样的 bug ：因为个别命令的原因，导致 AOF 文件在重新载入时，无法将数据集恢复成保存时的原样。（举个例子，阻塞命令 BRPOPLPUSH 就曾经引起过这样的 bug ） 。\n2.3、混合持久化 混合持久化只发生于 AOF 重写过程。使用了混合持久化，重写后的新 AOF 文件前半段是 RDB 格式的全量数据，后半段是 AOF 格式的增量数据。\n混合持久化本质是通过 AOF 后台重写（bgrewriteaof 命令）完成的，不同的是当开启混合持久化时，fork 出的子进程先将当前全量数据以 RDB 方式写入新的 AOF 文件，然后再将 AOF 重写缓冲区（aof_rewrite_buf_blocks）的增量命令以 AOF 方式写入到文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。\n优点：结合 RDB 和 AOF 的优点, 更快的重写和恢复。\n缺点：AOF 文件里面的 RDB 部分不再是 AOF 格式，可读性差。\n3、AOF重写 3.1、为什么需要 AOF 重写 AOF 持久化是通过保存被执行的写命令来记录数据库状态的，随着写入命令的不断增加，AOF 文件中的内容会越来越多，文件的体积也会越来越大。\n如果不加以控制，体积过大的 AOF 文件可能会对 Redis 服务器、甚至整个宿主机造成影响，并且 AOF 文件的体积越大，使用 AOF 文件来进行数据还原所需的时间就越多。\n3.2、AOF 重写 Redis 生成新的 AOF 文件来代替旧 AOF 文件，这个新的 AOF 文件包含重建当前数据集所需的最少命令。具体过程是遍历所有数据库的所有键，从数据库读取键现在的值，然后用一条命令去记录键值对，代替之前记录这个键值对的多条命令。\n3.3、AOF 后台重写一致性问题 AOF 后台重写使用子进程进行从写，解决了主进程阻塞的问题，但是仍然存在另一个问题：子进程在进行 AOF 重写期间，服务器主进程还需要继续处理命令请求，新的命令可能会对现有的数据库状态进行修改，从而使得当前的数据库状态和重写后的 AOF 文件保存的数据库状态不一致。\n为了解决上述问题，Redis 引入了 AOF 重写缓冲区（aof_rewrite_buf_blocks），这个缓冲区在服务器创建子进程之后开始使用，当 Redis 服务器执行完一个写命令之后，它会同时将这个写命令追加到 AOF 缓冲区和 AOF 重写缓冲区。\n这样，当子进程完成 AOF 重写工作后，父进程会在 serverCron 中检测到子进程已经重写结束，则会执行以下工作：\n1、将 AOF 重写缓冲区中的所有内容写入到新 AOF 文件中，这时新 AOF 文件所保存的数据库状态将和服务器当前的数据库状态一致。\n2、对新的 AOF 文件进行改名，原子的覆盖现有的 AOF 文件，完成新旧两个 AOF 文件的替换。\n3.4、AOF 重写缓冲区内容过多 将 AOF 重写缓冲区的内容追加到新 AOF 文件的工作是由主进程完成的，所以这一过程会导致主进程无法处理请求，如果内容过多，可能会使得阻塞时间过长，显然是无法接受的。\nRedis 中已经针对这种情况进行了优化：\n1、在进行 AOF 后台重写时，Redis 会创建一组用于父子进程间通信的管道，同时会新增一个文件事件，该文件事件会将写入 AOF 重写缓冲区的内容通过该管道发送到子进程。\n2、在重写结束后，子进程会通过该管道尽量从父进程读取更多的数据，每次等待可读取事件1ms，如果一直能读取到数据，则这个过程最多执行1000次，也就是1秒。如果连续20次没有读取到数据，则结束这个过程。\n通过这些优化，Redis 尽量让 AOF 重写缓冲区的内容更少，以减少主进程阻塞的时间。\n本文摘自面试必问的 Redis：RDB、AOF、混合持久化 - 知乎 (zhihu.com)\n","wordCount":"403","inLanguage":"en","datePublished":"2022-04-09T23:39:41Z","dateModified":"2022-04-09T23:39:41Z","author":{"@type":"Person","name":"lu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://ethereal-lu.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/"},"publisher":{"@type":"Organization","name":"lu","logo":{"@type":"ImageObject","url":"https://ethereal-lu.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://ethereal-lu.github.io/ accesskey=h title="lu (Alt + H)">lu</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://ethereal-lu.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://ethereal-lu.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://ethereal-lu.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://ethereal-lu.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Redis持久化</h1><div class=post-meta><span title='2022-04-09 23:39:41 +0000 UTC'>2022-04-09</span>&nbsp;·&nbsp;403 words&nbsp;·&nbsp;lu</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#1redis-核心主流程>1、Redis 核心主流程</a></li><li><a href=#2redis持久化>2、Redis持久化</a><ul><li><a href=#21rdbredis-database>2.1、RDB(Redis DataBase)</a></li><li><a href=#22aofappend-only-file>2.2、AOF(Append Only File)</a></li><li><a href=#23混合持久化>2.3、混合持久化</a></li></ul></li><li><a href=#3aof重写>3、AOF重写</a><ul><li><a href=#31为什么需要-aof-重写>3.1、为什么需要 AOF 重写</a></li><li><a href=#32aof-重写>3.2、AOF 重写</a></li><li><a href=#33aof-后台重写一致性问题>3.3、AOF 后台重写一致性问题</a></li><li><a href=#34aof-重写缓冲区内容过多>3.4、AOF 重写缓冲区内容过多</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h2 id=1redis-核心主流程>1、Redis 核心主流程<a hidden class=anchor aria-hidden=true href=#1redis-核心主流程>#</a></h2><p>AOF 和 RDB 的持久化过程中，有不少操作是在时间事件 serverCron 中被触发的。所以，这边有必要先了解下 Redis 中的事件核心流程。</p><p>Redis 的服务器进程就是一个事件循环，最重要的有两个事件：文件事件和时间事件。Redis 在服务器初始化后，会无限循环，处理产生的文件事件和时间事件。</p><p>文件事件常见的有：接受连接（accept）、读取（read）、写入（write）、关闭连接（close）等。使用 IO 多路复用处理。</p><p>时间事件中常见的就是 serverCron，redis 核心流程中通常也只有这个时间事件。serverCron 默认配置下每100ms会被触发一次，在该时间事件中，会执行很多操作：清理过期键、AOF 后台重写、RDB 的 save point 的检查、将 aof_buf 内容写到磁盘上（flushAppendOnlyFile 函数）等等。</p><h2 id=2redis持久化>2、Redis持久化<a hidden class=anchor aria-hidden=true href=#2redis持久化>#</a></h2><p>Redis是内存数据库，若不持久化到磁盘中，则redis进程一旦退出，数据就会丢失，因此需要持久化。</p><p>Redis 的持久化机制有以下三种：</p><ul><li>RDB</li><li>AOF</li><li>混合持久化（redis4.0引入）</li></ul><h3 id=21rdbredis-database>2.1、RDB(Redis DataBase)<a hidden class=anchor aria-hidden=true href=#21rdbredis-database>#</a></h3><p>描述：类似于快照。在某个时间点，将 Redis 在内存中的数据保存到磁盘里面。RDB 持久化功能生成的 RDB 文件是经过压缩的二进制文件。恢复时将快照文件直接读入内存。</p><p>rdb保存的文件是dump.rdb。同样可以在redis.conf中修改</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>在redis.conf中对自动保存的间隔进行设置
</span></span><span style=display:flex><span><span style=color:#75715e># save 3600 1        After 3600 seconds (an hour) if at least 1 key changed</span>
</span></span><span style=display:flex><span><span style=color:#75715e># save 300 100       After 300 seconds (5 minutes) if at least 100 keys changed</span>
</span></span><span style=display:flex><span><span style=color:#75715e># save 60 10000      After 60 seconds if at least 10000 keys changed</span>
</span></span></code></pre></div><h4 id=211触发条件>2.1.1、触发条件<a hidden class=anchor aria-hidden=true href=#211触发条件>#</a></h4><p><strong>自动触发</strong>（全部是BGSAVE）</p><ul><li><p>满足上方save的规则</p></li><li><p>执行flushall，生成的 dump.rdb 为空。</p></li><li><p>退出reids</p></li></ul><p><strong>手动触发</strong></p><ul><li>SAVE：生成 RDB 快照文件，但是会阻塞主进程，服务器将无法处理客户端发来的命令请求，所以通常不会直接使用该命令。</li><li>BGSAVE：fork 子进程来生成 RDB 快照文件，阻塞只会发生在 fork 子进程的时候，之后主进程可以正常处理请求。会先将数据保存进一个临时文件中，待持久化过程结束了，再将这个临时文件替换上次持久化的文件。</li></ul><h4 id=212恢复rdb文件>2.1.2、恢复rdb文件<a hidden class=anchor aria-hidden=true href=#212恢复rdb文件>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 若rdb文件在下方目录下，则启动时会自动回复其中的数据</span>
</span></span><span style=display:flex><span>127.0.0.1:6379&gt; CONFIG GET dir
</span></span><span style=display:flex><span>1<span style=color:#f92672>)</span> <span style=color:#e6db74>&#34;dir&#34;</span>
</span></span><span style=display:flex><span>2<span style=color:#f92672>)</span> <span style=color:#e6db74>&#34;/usr/local/bin&#34;</span>
</span></span></code></pre></div><h4 id=213rdb-的优缺点>2.1.3、RDB 的优缺点<a hidden class=anchor aria-hidden=true href=#213rdb-的优缺点>#</a></h4><p><strong>RDB 的优点：</strong></p><ul><li>RDB 文件是是经过压缩的二进制文件，占用空间很小，它保存了 Redis 某个时间点的数据集，很适合用于做备份。</li><li>RDB 非常适用于灾难恢复：它只有一个文件，并且内容都非常紧凑，可以（在加密后）将它传送到别的数据中心。</li><li>RDB 可以最大化 redis 的性能。父进程在保存 RDB 文件时唯一要做的就是 fork 出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘 I/O 操作。</li><li>RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。</li></ul><p><strong>RDB 的缺点：</strong></p><ul><li><p>RDB 在服务器故障时容易造成数据的丢失。RDB 允许我们通过修改 save point 配置来控制持久化的频率。但是，因为 RDB 文件需要保存整个数据集的状态， 所以它是一个比较重的操作，如果频率太频繁，可能会对 Redis 性能产生影响。所以通常可能设置至少5分钟才保存一次快照，这时如果 Redis 出现宕机等情况，则意味着最多可能丢失5分钟数据。</p></li><li><p>RDB 保存时使用 fork 子进程进行数据的持久化，如果数据比较大的话，fork 可能会非常耗时，造成 Redis 停止处理服务N毫秒。如果数据集很大且 CPU 比较繁忙的时候，停止服务的时间甚至会到一秒。</p></li><li><p>Linux fork 子进程采用的是 copy-on-write 的方式。在 Redis 执行 RDB 持久化期间，如果 client 写入数据很频繁，那么将增加 Redis 占用的内存，最坏情况下，内存的占用将达到原先的2倍。刚 fork 时，主进程和子进程共享内存，但是随着主进程需要处理写操作，主进程需要将修改的页面拷贝一份出来，然后进行修改。极端情况下，如果所有的页面都被修改，则此时的内存占用是原先的2倍。</p></li></ul><h3 id=22aofappend-only-file>2.2、AOF(Append Only File)<a hidden class=anchor aria-hidden=true href=#22aofappend-only-file>#</a></h3><p>将所有写命令都记录到文件中，恢复时把该文件再执行一遍，只允许追加该记录文件，不允许修改。该记录文件的名字为<code>appendonly.aof</code>。该功能默认不开启，可以通过配置：appendonly yes 开启， appendonly no 关闭。</p><h4 id=221aof的实现>2.2.1、AOF的实现<a hidden class=anchor aria-hidden=true href=#221aof的实现>#</a></h4><p>AOF 持久化功能的实现可以分为三个步骤：命令追加、文件写入、文件同步。</p><p>命令追加：当 AOF 持久化功能打开时，服务器在执行完一个写命令之后，会将被执行的写命令追加到服务器状态的 aof 缓冲区（aof_buf）的末尾。</p><p>文件写入：将 aof_buf 的内容写到页缓存</p><p>文件同步：将页缓存刷盘到硬盘</p><p>serverCron 时间事件中会触发 flushAppendOnlyFile 函数，该函数会根据服务器配置的 appendfsync 参数值，来决定是否将 aof_buf 缓冲区的内容写入和保存到 AOF 文件。</p><p><strong>appendfsync 参数有三个选项：</strong></p><ul><li><p>always：每个命令都刷盘。</p></li><li><p>everysec：每秒刷盘1次，这个操作是异步的，由一个后台线程专门负责执行。</p></li><li><p>no：不执行刷盘，让操作系统自己执行刷盘。</p></li></ul><h4 id=222aof-的优缺点>2.2.2、AOF 的优缺点<a hidden class=anchor aria-hidden=true href=#222aof-的优缺点>#</a></h4><p><strong>AOF 的优点</strong></p><ul><li><p>AOF 比 RDB可靠。可以设置不同的 fsync 策略：no、everysec 和 always。默认是 everysec，在这种配置下，redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据。</p></li><li><p>AOF文件是一个纯追加的日志文件。即使日志因为某些原因而包含了未写入完整的命令（比如写入时磁盘已满，写入中途停机等等）， 我们也可以使用 redis-check-aof 工具也可以轻易地修复这种问题。</p></li><li><p>当 AOF文件太大时，Redis 会自动在后台进行重写：重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。整个重写是绝对安全，因为重写是在一个新的文件上进行，同时 Redis 会继续往旧的文件追加数据。当新文件重写完毕，Redis 会把新旧文件进行切换，然后开始把数据写到新文件上。</p></li><li><p>易读</p></li></ul><p><strong>AOF 的缺点</strong></p><ul><li><p>对于相同的数据集，AOF 文件的大小一般会比 RDB 文件大。</p></li><li><p>根据所使用的 fsync 策略，AOF 的速度可能会比 RDB 慢。通常 fsync 设置为每秒一次就能获得比较高的性能，而关闭 fsync 可以让 AOF 的速度和 RDB 一样快。</p></li><li><p>AOF 在过去曾经发生过这样的 bug ：因为个别命令的原因，导致 AOF 文件在重新载入时，无法将数据集恢复成保存时的原样。（举个例子，阻塞命令 BRPOPLPUSH 就曾经引起过这样的 bug ） 。</p></li></ul><h3 id=23混合持久化>2.3、混合持久化<a hidden class=anchor aria-hidden=true href=#23混合持久化>#</a></h3><p>混合持久化只发生于 AOF 重写过程。使用了混合持久化，重写后的新 AOF 文件前半段是 RDB 格式的全量数据，后半段是 AOF 格式的增量数据。</p><p>混合持久化本质是通过 AOF 后台重写（bgrewriteaof 命令）完成的，不同的是当开启混合持久化时，fork 出的子进程先将当前全量数据以 RDB 方式写入新的 AOF 文件，然后再将 AOF 重写缓冲区（aof_rewrite_buf_blocks）的增量命令以 AOF 方式写入到文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。</p><p>优点：结合 RDB 和 AOF 的优点, 更快的重写和恢复。</p><p>缺点：AOF 文件里面的 RDB 部分不再是 AOF 格式，可读性差。</p><h2 id=3aof重写>3、AOF重写<a hidden class=anchor aria-hidden=true href=#3aof重写>#</a></h2><h3 id=31为什么需要-aof-重写>3.1、为什么需要 AOF 重写<a hidden class=anchor aria-hidden=true href=#31为什么需要-aof-重写>#</a></h3><p>AOF 持久化是通过保存被执行的写命令来记录数据库状态的，随着写入命令的不断增加，AOF 文件中的内容会越来越多，文件的体积也会越来越大。</p><p>如果不加以控制，体积过大的 AOF 文件可能会对 Redis 服务器、甚至整个宿主机造成影响，并且 AOF 文件的体积越大，使用 AOF 文件来进行数据还原所需的时间就越多。</p><h3 id=32aof-重写>3.2、AOF 重写<a hidden class=anchor aria-hidden=true href=#32aof-重写>#</a></h3><p>Redis 生成新的 AOF 文件来代替旧 AOF 文件，这个新的 AOF 文件包含重建当前数据集所需的最少命令。具体过程是遍历所有数据库的所有键，从数据库读取键现在的值，然后用一条命令去记录键值对，代替之前记录这个键值对的多条命令。</p><h3 id=33aof-后台重写一致性问题>3.3、AOF 后台重写一致性问题<a hidden class=anchor aria-hidden=true href=#33aof-后台重写一致性问题>#</a></h3><p>AOF 后台重写使用子进程进行从写，解决了主进程阻塞的问题，但是仍然存在另一个问题：子进程在进行 AOF 重写期间，服务器主进程还需要继续处理命令请求，新的命令可能会对现有的数据库状态进行修改，从而使得当前的数据库状态和重写后的 AOF 文件保存的数据库状态不一致。</p><p>为了解决上述问题，Redis 引入了 AOF 重写缓冲区（aof_rewrite_buf_blocks），这个缓冲区在服务器创建子进程之后开始使用，当 Redis 服务器执行完一个写命令之后，它会同时将这个写命令追加到 AOF 缓冲区和 AOF 重写缓冲区。</p><p>这样，当子进程完成 AOF 重写工作后，父进程会在 serverCron 中检测到子进程已经重写结束，则会执行以下工作：</p><p>1、将 AOF 重写缓冲区中的所有内容写入到新 AOF 文件中，这时新 AOF 文件所保存的数据库状态将和服务器当前的数据库状态一致。</p><p>2、对新的 AOF 文件进行改名，原子的覆盖现有的 AOF 文件，完成新旧两个 AOF 文件的替换。</p><h3 id=34aof-重写缓冲区内容过多>3.4、AOF 重写缓冲区内容过多<a hidden class=anchor aria-hidden=true href=#34aof-重写缓冲区内容过多>#</a></h3><p>将 AOF 重写缓冲区的内容追加到新 AOF 文件的工作是由主进程完成的，所以这一过程会导致主进程无法处理请求，如果内容过多，可能会使得阻塞时间过长，显然是无法接受的。</p><p>Redis 中已经针对这种情况进行了优化：</p><p>1、在进行 AOF 后台重写时，Redis 会创建一组用于父子进程间通信的管道，同时会新增一个文件事件，该文件事件会将写入 AOF 重写缓冲区的内容通过该管道发送到子进程。</p><p>2、在重写结束后，子进程会通过该管道尽量从父进程读取更多的数据，每次等待可读取事件1ms，如果一直能读取到数据，则这个过程最多执行1000次，也就是1秒。如果连续20次没有读取到数据，则结束这个过程。</p><p>通过这些优化，Redis 尽量让 AOF 重写缓冲区的内容更少，以减少主进程阻塞的时间。</p><p>本文摘自<a href=https://zhuanlan.zhihu.com/p/340082703>面试必问的 Redis：RDB、AOF、混合持久化 - 知乎 (zhihu.com)</a></p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://ethereal-lu.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/><span class=title>« Prev</span><br><span>Redis分布式锁</span>
</a><a class=next href=https://ethereal-lu.github.io/posts/linux/io/><span class=title>Next »</span><br><span>IO 多路复用</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://ethereal-lu.github.io/>lu</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>