<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Redis | lu</title>
<meta name=keywords content><meta name=description content><meta name=author content="lu"><link rel=canonical href=https://ethereal-lu.github.io/categories/redis/><link crossorigin=anonymous href=/assets/css/stylesheet.d72444526d7ecbdb0015438a7fa89054a658bf759d0542e2e5df81ce94b493ee.css integrity="sha256-1yREUm1+y9sAFUOKf6iQVKZYv3WdBULi5d+BzpS0k+4=" rel="preload stylesheet" as=style><link rel=icon href=https://ethereal-lu.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://ethereal-lu.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://ethereal-lu.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://ethereal-lu.github.io/apple-touch-icon.png><link rel=mask-icon href=https://ethereal-lu.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://ethereal-lu.github.io/categories/redis/index.xml><link rel=alternate hreflang=en href=https://ethereal-lu.github.io/categories/redis/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://ethereal-lu.github.io/categories/redis/"><meta property="og:site_name" content="lu"><meta property="og:title" content="Redis"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Redis"><meta name=twitter:description content></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://ethereal-lu.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://ethereal-lu.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://ethereal-lu.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://ethereal-lu.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://ethereal-lu.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://ethereal-lu.github.io/categories/>Categories</a></div><h1>Redis
<a href=/categories/redis/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Redis集群</h2></header><div class=entry-content><p>主从复制和哨兵机制保障了高可用，就读写分离而言虽然slave节点扩展了主从的读并发能力，但是写能力和存储能力是无法进行扩展，就只能是master节点能够承载的上限。如果面对海量数据那么必然需要构建master之间的集群，同时必然需要吸收高可用（主从复制和哨兵机制）能力，即每个master分片节点还需要有slave节点。这就是为社么要使用Redis集群。
1、概述 Redis集群可以理解为n个主从架构组合在一起对外服务。Redis Cluster要求至少需要3个master才能组成一个集群，同时每个master至少需要有一个slave节点。
如此，Redis集群的写能力和存储能力就是所有master之和了。
虽然每个master下都挂载了一个slave节点，但是在Redis Cluster中的读、写请求其实都是在master上完成的。slave节点只是充当了一个数据备份的角色，当master发生了宕机，就会将对应的slave节点提拔为master，来重新对外提供服务。
2、 主要模块介绍 2.1、 哈希槽(Hash Slot) Redis-cluster没有使用一致性hash，而是引入了哈希槽的概念。Redis-cluster中有16384(即2的14次方）个哈希槽，每个key通过CRC16校验后对16383取模来决定放置哪个槽。Cluster中的每个节点负责一部分hash槽（hash slot）。
一个键的对应的哈希槽通过计算键的CRC16 哈希值，然后对16384进行取模得到：HASH_SLOT=CRC16(key) modulo 16383。读写操作都是先计算出键的哈希槽，再在负责该哈希槽的 master 上进行相应操作。
2.2、Cluster总线 每个Redis Cluster节点有一个额外的TCP端口用来接受其他节点的连接。这个端口为普通 client 端口 + 10000。如普通 client 端口为6379，则总线端口为 16379。节点到节点的通讯只使用集群总线。
2.3、集群拓扑 Redis Cluster是一张全网拓扑，节点与其他每个节点之间都保持着TCP连接。
2.4、节点握手 节点认定其他节点是当前集群的一部分有两种方式：
如果一个节点出现在了一条MEET消息中。meet消息会强制接收者接受一个节点作为集群的一部分。
从某个已信任的节点处获知某节点是集群的一部分，则当前节点也会将该节点当成集群的一部分。
3、状态检测及维护 在集群模式下，所有的publish命令都会向所有节点（包括从节点）进行广播，加重了带宽负担，对于在有大量节点的集群中频繁使用pub，会严重消耗带宽，不建议使用。
3.1、Gossip协议 gossip 协议是基于流行病传播方式的节点或者进程之间信息交换的协议。Gossip协议的最大的好处是，即使集群节点的数量增加，每个节点的负载也不会增加很多，几乎是恒定的。
Gossip的特点：在一个有界网络中，每个节点都随机地与其他节点通信，经过一番杂乱无章的通信，最终所有节点的状态都会达成一致。每个节点可能知道所有其他节点，也可能仅知道几个邻居节点，只要这些节可以通过网络连通，最终他们的状态都是一致的。即Gossip协议是最终一致性，不是强一致性。
3.2、基于Gossip协议的故障检测 集群中的每个节点都会不定时地向集群中的其他节点发送PING消息，以此交换各个节点状态信息。
当节点 1 向节点 3 发送PING消息后未在规定时间内收到节点 3 的PONG响应，则节点 1 认为节点 3 PFAIL（主观下线）。当节点1标记节点3为PFAIL后，节点1会通过Gossip消息把这个信息发送给其他节点，接收到信息的节点会进行节点3客观下线状态判定。当节点2接收到来自节点1关于节点3的状态判定信息之后，节点2首先会把节点1加入到节点3的下线报告列表(Fail Report)中。每个节点都会维护一个下线报告列表，主要维护一个节点被哪些节点报告处于下线状态。
只有同样认为节点3处于PFAIL状态的节点才会去做客观下线状态判定，即只有节点2也曾向节点3发送ping且没有得到响应，节点2才会去做客观下线状态判定：如果自己维护的节点3的下线报告列表中包含一半以上的主节点（即超过半数的主节点认为节点3主观下线），则认为节点3 FAIL（客观下线）。
一旦节点2认为节点3客观下线，就向集群广播节点3的FAIL消息，所有收到FAIL消息的节点都会立即将节点3的状态标记为已下线。
疑问：节点2是否可以是从节点？即从节点是否参与故障检测，是否拥有下线报告列表，是否做客观下线判断，是否能发广播？
4、 故障恢复（Failover） 当slave发现自己的master变为FAIL状态时，便尝试进行Failover，以期成为新的master。由于挂掉的master可能会有多个slave。Failover的过程需要经过类Raft协议的过程在整个集群内达到一致， 其过程如下：
slave发现自己的master变为FAIL 长时间不与主节点通信的从节点不具备竞选资格 所有竞选者随即休眠，唤醒后立即通过广播向所有节点拉票 其他节点收到拉票请求，只有master响应，若本轮竞选中自己没投过票就投，否则不投票，即每个主节点只有一次投票机会 从节点发现超过半数的主节点为自己投票就变成新Master：接替旧master 的slot，并让旧master与其他从节点成为自己的从节点 广播Pong通知其他集群节点自己成为新的主节点 易知，休眠时间最短的节点容易获得大部分投票。
...</p></div><footer class=entry-footer><span title='2022-05-02 21:39:41 +0000 UTC'>2022-05-02</span>&nbsp;·&nbsp;88 words&nbsp;·&nbsp;lu</footer><a class=entry-link aria-label="post link to Redis集群" href=https://ethereal-lu.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/redis%E9%9B%86%E7%BE%A4/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Redis主从复制</h2></header><div class=entry-content><p>1、概述 主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。主从节点建立连接后会保持心跳检测。
主从复制的作用主要包括：
数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务。尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。 高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。 主从库之间采用的是读写分离的方式。
读操作：主库、从库都可以接收； 写操作：首先到主库执行，然后，主库将写操作同步给从库。 由于 Redis 的主从复制是通过异步实现的，在主从复制期间任然可以对外提供服务，因此属于 AP 模型，实现的是最终一致性。
2、原理 全量（同步）复制：主库的全部数据同步给从库 增量（同步）复制：只会把主从库网络断连期间主库收到的命令，同步给从库 2.1、全量复制 当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof（Redis 5.0 之前使用 slaveof）命令形成主库和从库的关系。
replicaof 172.16.19.3 6379 // 当前实例作为 172.16.19.3 6379 的从库 全量复制的三个阶段
第一阶段是主从库间建立连接、协商同步的过程：
// 从库发出如下命令请求数据同步 psync ？ -1 // 第一个参数为 runID ,唯一标识一个实例。由于第一次请求不知道主库的 runID ，故使用 ？ // 第二个参数为数据同步的偏移量 offset ，-1 表示从头开始同步。 主库收到请求后返回自己的 runID 和当前同步进度 offset，从库记录下来用于后续同步操作。
第二阶段，主库将所有数据同步给从库：主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。数据同步的过程中主库新接收的写操作记录在 replication buffer 中。
第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库：主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。
...</p></div><footer class=entry-footer><span title='2022-05-02 15:39:41 +0000 UTC'>2022-05-02</span>&nbsp;·&nbsp;144 words&nbsp;·&nbsp;lu</footer><a class=entry-link aria-label="post link to Redis主从复制" href=https://ethereal-lu.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Redis哨兵机制</h2></header><div class=entry-content><p>由于主从模式是读写分离的，如果主节点故障，那么将没有主节点来执行写操作，也没有主节点给从节点进行数据同步了。若是每次主节点故障都需要人工切换主从节点太繁琐，于是哨兵机制出现了。哨兵的核心功能是主节点的自动故障转移。
1、哨兵集群的组建 哨兵实例之间可以相互发现，要归功于 Redis 提供的发布 / 订阅机制。
首先主节点的信息配置在哨兵(Sentinel)的配置文件中 哨兵节点会和配置的主节点建立起连接 哨兵每10秒会向主节点发送info命令，主节点会返回自己的run_id和自己的从节点信息。 哨兵会对这些从节点也建立连接。之后每10秒会向主节点和从节点都发送info命令以获取最新的拓扑结构。 每个哨兵都订阅主节点的_sentinel:hello频道，且每2秒向该频道发布自己的信息，各哨兵由此与其他哨兵建立连接。 每隔1秒每个哨兵会向主节点、从节点、其他哨兵发送ping命令，做心跳检测。 上述 6 点中，加粗部分为每个哨兵的三个定时任务。
2、主库下线的判定 主观下线：哨兵节点每隔1秒向各节点发送PING命令，如果在规定时间内没有收到有效响应，哨兵就会将该节点标记为主观下线。 客观下线：当某个哨兵判断主库主观下线后，就会给其他哨兵发起询问，其他哨兵会根据自己和主库的连接情况，做出赞成或反对的响应。如果赞成票数大于等于哨兵配置文件中的配置项 quorum 的值, 则判定主库客观下线。quorum 的值一般为哨兵个数 / 2 + 1。 3、新主库选取 根据以下规则选取新主库：
过滤掉网络状态不好的：redis 有一个参数用于表示主从节点的通信超时时间，如果从节点的超时次数超过10次，说明这个从节点的网络状况不好，不适合作为新主节点。 选择从节点优先级最高的（redis.conf 中有一个配置项salve-priority表示从节点优先级） 优先级相同时选择复制偏移量最大的 若优先级和偏移量都相同，则选择 id 号小的 4、选举Leader哨兵 新主库选取选举之后需要进行故障转移，但是哨兵节点有多个，需要选举一个 leader 哨兵来负责进行主从切换。
选举算法Raft选举算法：哪个哨兵节点判断主节点为「客观下线」，这个哨兵节点就是候选者。候选者会向其他哨兵发送命令，表明希望成为 Leader 来执行主从切换，并让所有其他哨兵对它进行投票。每个哨兵只有一次投票机会，如果用完后就不能参与投票了，可以投给自己或投给别人，但是只有候选者才能把票投给自己。若只有一个候选者，则其他哨兵会将票投给它，若有多个候选者，即多个哨兵同时判断主节点为「客观下线」，此时其他非候选者哨兵会对它收到的第一个拉票候选者投票，对后续收到的其他拉票请求给予拒绝。
一个候选者若能成为 Leader ，那它获得的赞成票必须既大于哨兵节点的一半又大于quorum的值。如果所有候选者都不满足，则发起下一轮选举。
若有超过一半的哨兵宕机，则无法完成Leader哨兵的选举。
5、故障转移 通过 slave of no one 命令将 4 中选举的从节点变为主节点。 通过replicaof命令将其他从节点和旧的主节点都成为新主节点的从节点。</p></div><footer class=entry-footer><span title='2022-05-02 15:39:41 +0000 UTC'>2022-05-02</span>&nbsp;·&nbsp;58 words&nbsp;·&nbsp;lu</footer><a class=entry-link aria-label="post link to Redis哨兵机制" href=https://ethereal-lu.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/redis%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Redis底层数据结构</h2></header><div class=entry-content><p>1、压缩列表 - ZipList Redis是基于内存的nosql，有些场景下为了节省内存redis会用“时间”换“空间”。ziplist就是很典型的例子。
1.1、整体布局 ziplist是为了节省内存空间而设计的由一系列特殊编码的连续内存块组成的顺序存储结构，类似于数组，ziplist在内存中是连续存储的，但是不同于数组，为了节省内存 ziplist的每个元素所占的内存大小可以不同（数组中叫元素，ziplist叫节点entry），每个节点可以用来存储一个整数或者一个字符串。存储整数时是采用整数的二进制而不是字符串形式存储。
zlbytes: ziplist的长度（单位: 字节)，是一个32位无符号整数 zltail: ziplist最后一个节点的偏移量，反向遍历ziplist或者pop尾部节点的时候有用。 zllen: ziplist的节点（entry）个数 entry: 节点 zlend: 值为0xFF，用于标记ziplist的结尾 1.2、节点的布局(entry) 每个节点由三部分组成：prevlength、encoding、data
prevlengh: 记录上一个节点的长度，为了方便反向遍历ziplist encoding: 当前节点的编码规则 data: 当前节点的值，可以是数字或字符串 为了节省内存，根据上一个节点的长度prevlength 可以将ziplist节点分为两类：
entry的前8位小于254，则这8位就表示上一个节点的长度 entry的前8位等于254，则意味着上一个节点的长度无法用8位表示，后面32位才是真实的prevlength。用254 不用255(11111111)作为分界是因为255是zlend的值，它用于判断ziplist是否到达尾部。 根据当前节点存储的数据类型及长度，可以将ziplist节点分为9类：
当 encoding 的高两位为 11 时表明是整数节点，否则表明是字符串节点。其中整数节点共有 6 中类型（int16、int32、int64等），字符串节点共有3中类型（3种类型的字符串长度不同）。
1.3、复杂度 新建 ZipList：O(1) 查找：O(n) 插入：O(n) 删除：O(n) 1.4、总结 ziplist是为节省内存空间而生的。让每个元素按照实际的内容大小存储，不浪费空间。 ziplist是一个为Redis专门提供的底层数据结构之一，本身可以有序也可以无序。当作为list和hash的底层实现时，节点之间没有顺序；当作为zset的底层实现时，节点之间会按照大小顺序排列。 2、快表 - QuickList 在Redis的早期版本中，存储list列表结构时，如果元素少则使用压缩列表ziplist，否则使用双向链表linkedlist。
但是考虑到链表的每个节点都要有两个指针，prev 和 next 指针要占去 16 个字节 (64bit 系统的指针是 8 个字节)。因此Redis3.2版本开始使用 quicklist 代替了 ziplist 和 linkedlist。
quicklist 实际上是 zipList 和 linkedList 的混合体，它将 linkedList 中的多个节点并为一个 quicklistNode，使用 zipList 来紧凑存储，多个 zipList 之间使用双向指针串接起来。
...</p></div><footer class=entry-footer><span title='2022-05-01 17:39:41 +0000 UTC'>2022-05-01</span>&nbsp;·&nbsp;427 words&nbsp;·&nbsp;lu</footer><a class=entry-link aria-label="post link to Redis底层数据结构" href=https://ethereal-lu.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/redis%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Redis缓存一致性</h2></header><div class=entry-content><p>1、先更新缓存再更新DB 缓存更新后 DB 更新失败回滚，此时缓存与 DB 数据不一致。因此不推荐
2、先删除缓存再更新DB 删除缓存后立即来一条线程查询，此时 DB 可能还未更新完成，读取到了旧值，这相当于白删了，做了无用功。不推荐。
因此最好先操作 DB 再操作缓存
3、先更新DB再更新缓存 更新操作远多于查询操作时，对于缓存的更新完全是没必要的，浪费。 并发修改问题：若线程A、B同时修改数据，A先修改DB，释放锁后B再修改；但是有可能 B 先于 A 修改缓存（STW），此时 A 覆盖了缓存中 B 的修改，导致不一致问题。 因此最好删除缓存而不是更新缓存
4、先更新DB再删除缓存 延迟双删：更新期间读取的是旧值；第一次删除后，读取线程可能因操作缓慢将读到旧值写回缓存中，为了避免缓存中一直是旧值，需要在一定时间后再次删除缓存，保证之后的读取线程写回缓存的值为更新后的值。这段时间应该大于线程读数据 + 写缓存的时间。
public void putValue(key, value){ putToDB(key, value); deleteFromRedis(key); // 5秒之后再次进行删除 deleteFromRedisDelay(key, 5second); } 5、其他策略 如果对于一致性要求不高，可以将缓存中数据的过期时间设置的短一些（如 5 秒），这样每过 5 秒，缓存就会从 DB 中取一次最新值。</p></div><footer class=entry-footer><span title='2022-04-25 22:39:41 +0000 UTC'>2022-04-25</span>&nbsp;·&nbsp;49 words&nbsp;·&nbsp;lu</footer><a class=entry-link aria-label="post link to Redis缓存一致性" href=https://ethereal-lu.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/redis%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>缓存穿透、击穿、雪崩</h2></header><div class=entry-content><p>1、缓存穿透 1.1、问题描述 如果在请求数据时，在缓存层和数据库层都没有命中，这种情况就叫作缓存穿透。
造成缓存穿透的主要原因就是：查询某个 Key 对应的数据，Redis 缓存中没有相应的数据，则直接到数据库中查询。数据库中也不存在要查询的数据，则数据库会返回空，而 Redis 也不会缓存这个空结果。这就造成每次通过这样的 Key 去查询数据都会直接到数据库中查询，Redis 不会缓存空结果。这就造成了缓存穿透的问题。
1.2、解决办法 将空对象也缓存起来。即如果某个 key 在缓存和数据库都没有命中，就将该 key 的值置为空对象缓存到 redis。 布隆过滤器。将所有的 key 都存放在足够大的布隆过滤器中，每次查询先由其对 key 过滤，若布隆过滤器命中，则该 key 有可能存在，若布隆过滤器未命中，则该 key 一定不存在。 1.3、布隆过滤器 布隆过滤器由一个 bit 数组和若干哈希函数组成。
初始时将 bit 数组所有位置置 0。
对任意一个 key，通过哈希函数得到哈希值，将该哈希值对 bit 数组的长度取余就得到一个确定的位置，将该位置置为 1。对所有的哈希函数都执行上述操作，则一个 key 会对应多个位置。
查询时，对 key 进行同样的操作，若得到的所有位置都为 1，则该 key 有很大的可能存在；若有任意一个位置不为 1，则该值一定不存在。
之所以命中时是很有可能存在，根本问题是哈希的碰撞，可能其他一个或多个值的哈希映射与该值的所有映射碰撞，则无法判断该值是否存在。
布隆过滤器无法删除元素，一是无法精确判断该值是否存在，二是删除后会使得其他值在该点的碰撞映射删除导致误判。
应用场景：
redis 缓存穿透 爬虫或其他业务中判断是否访问过某 url web 拦截器，拦截重复请求，防止重复攻击 2、缓存击穿 2.1、问题描述 缓存数据都设置有过期时间，当高峰期对于某个热点数据有大量访问，若此时该数据正好过期，则大量的访问就直接落到数据库中，导致数据库崩溃。
2.2、解决办法 对于热点数据不设置过期时间 使用分布式锁。只有第一个到达的访问获取锁去数据库读取数据并写回缓存，其他的访问竞争锁失败陷入等待并循环查询缓存。 3、缓存雪崩 3.1、问题描述 若缓存服务器突然故障宕机，则大量请求就会直接淹没数据库，此时若不采取其他措施就直接重启数据库，它又会立刻被淹没，这就是缓存雪崩。
3.2、解决办法 redis 集群，保证高可用 限流，通过分布式锁限制访问数据库的线程数量 数据预热 ，可能产生大量访问之前，手动将数据加载到缓存，对数据设置不同的过期时间，使其均匀过期。（感觉像是缓存击穿的解决方法呢？）</p></div><footer class=entry-footer><span title='2022-04-16 22:39:41 +0000 UTC'>2022-04-16</span>&nbsp;·&nbsp;74 words&nbsp;·&nbsp;lu</footer><a class=entry-link aria-label="post link to 缓存穿透、击穿、雪崩" href=https://ethereal-lu.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E5%87%BB%E7%A9%BF%E9%9B%AA%E5%B4%A9/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Redis分布式锁</h2></header><div class=entry-content><p>1、什么是分布式锁 分布式锁，顾名思义，就是分布式项目开发中用到的锁，可以用来控制分布式系统之间同步访问共享资源，一般来说，分布式锁需要满足的特性有这么几点：
1、互斥性：在任何时刻，对于同一条数据，只有一台应用可以获取到分布式锁；
2、高可用性：在分布式场景下，一小部分服务器宕机不影响正常使用，这种情况就需要将提供分布式锁的服务以集群的方式部署；
3、防止锁超时：如果客户端没有主动释放锁，服务器会在一段时间之后自动释放锁，防止客户端宕机或者网络不可达时产生死锁；
4、独占性：加锁解锁必须由同一台服务器进行，也就是锁的持有者才可以释放锁，不能出现你加的锁，别人给你解锁了；
2、实现分布式锁 Redis分布式锁主要是通过SETNX和SETEX这两个命令实现的。这两个命令都是原子操作。
核心思想就是每次想要获取锁的时候，就对一个固定的 key 值以 SETNX的方式存放，如果成功，就说明获取锁成功，否则以自旋的方式持续获取锁，直到超时获取失败。
解锁通过 LUA 代码实现，LUA是原子性的。
注：下方代码只体现实现锁的思想，不能实际使用。实际开发中使用 Redisson 。
3、分布式锁的缺陷 一、客户端长时间阻塞导致锁失效问题
客户端1得到了锁，因为网络问题或者GC等原因导致长时间阻塞，然后业务程序还没执行完锁就过期了，这时候客户端2也能正常拿到锁，可能会导致线程安全的问题。
二、redis服务器时钟漂移问题
如果redis服务器的机器时钟发生了向前跳跃，就会导致这个key过早超时失效，比如说客户端1拿到锁后，key的过期时间是12:02分，但redis服务器本身的时钟比客户端快了2分钟，导致key在12:00的时候就失效了，这时候，如果客户端1还没有释放锁的话，就可能导致多个客户端同时持有同一把锁的问题。
三、单点实例安全问题
如果redis是单master模式的，当这台机宕机的时候，那么所有的客户端都获取不到锁了，为了提高可用性，可能就会给这个master加一个slave，但是因为redis的主从同步是异步进行的，可能会出现客户端1设置完锁后，master挂掉，但此时数据还没有同步给slave 节点，当slave提升为master后，客户端1设置的锁丢失了，这时候客户端2设置锁也能够成功，导致客户端1和客户端2同时拥有锁。因此 reids 实现的分布式锁是 AP 模型。
4、RedLock 针对上述问题，官方推出了 RedLock 算法，RedLock 算法用于解决 Redis 集群中向一个 master 节点设置锁后该节点挂了，这时向其他 master 节点设置锁一定成功的问题。获取锁时在超过半数的实例中设置了锁就认为获取到了锁，解锁时将所有实例解锁。
RedLock 不足：
宕机重启之后，2个客户端拿到同一把锁：假设5个节点是A, B, C, D, E，客户端1在A, B, C上面拿到锁，D, E没有拿到锁，客户端1拿锁成功。 此时，C挂了重启，C上面锁的数据丢失（假设机器断电，数据还没来得及刷盘；或者C上面的主节点挂了，从节点未同步）。客户端2去取锁，从C, D, E 3个节点拿到锁，A, B没有拿到（还被客户端1持有），客户端2也超过多数派，也会拿到锁。 多个客户端同时竞争同一把锁，全部失败：比如有节点1、2、3、4、5，A、B、C同时竞争锁，A获得1、2,B获得3、4,C获得5,最后ABC都没有成功获得锁，没有获得半数以上的锁。需要强调，当客户端从大多数Redis实例获取锁失败时，应该尽快地释放（部分）已经成功取到的锁，方便别的客户端去获取锁，假如释放锁失败了，就只能等待锁超时释放了 效率低：需要顺序向所有 master 节点设置锁，master 节点越多，效率越低 5、Redisson Redisson 分布式锁通过 hash 实现，hash 名作为锁，hash 中的键为 线程ID，值为 重入次数。
加锁时设置了过期时间
...</p></div><footer class=entry-footer><span title='2022-04-12 22:39:41 +0000 UTC'>2022-04-12</span>&nbsp;·&nbsp;95 words&nbsp;·&nbsp;lu</footer><a class=entry-link aria-label="post link to Redis分布式锁" href=https://ethereal-lu.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Redis持久化</h2></header><div class=entry-content><p>1、Redis 核心主流程 AOF 和 RDB 的持久化过程中，有不少操作是在时间事件 serverCron 中被触发的。所以，这边有必要先了解下 Redis 中的事件核心流程。
Redis 的服务器进程就是一个事件循环，最重要的有两个事件：文件事件和时间事件。Redis 在服务器初始化后，会无限循环，处理产生的文件事件和时间事件。
文件事件常见的有：接受连接（accept）、读取（read）、写入（write）、关闭连接（close）等。使用 IO 多路复用处理。
时间事件中常见的就是 serverCron，redis 核心流程中通常也只有这个时间事件。serverCron 默认配置下每100ms会被触发一次，在该时间事件中，会执行很多操作：清理过期键、AOF 后台重写、RDB 的 save point 的检查、将 aof_buf 内容写到磁盘上（flushAppendOnlyFile 函数）等等。
2、Redis持久化 Redis是内存数据库，若不持久化到磁盘中，则redis进程一旦退出，数据就会丢失，因此需要持久化。
Redis 的持久化机制有以下三种：
RDB AOF 混合持久化（redis4.0引入） 2.1、RDB(Redis DataBase) 描述：类似于快照。在某个时间点，将 Redis 在内存中的数据保存到磁盘里面。RDB 持久化功能生成的 RDB 文件是经过压缩的二进制文件。恢复时将快照文件直接读入内存。
rdb保存的文件是dump.rdb。同样可以在redis.conf中修改
在redis.conf中对自动保存的间隔进行设置 # save 3600 1 After 3600 seconds (an hour) if at least 1 key changed # save 300 100 After 300 seconds (5 minutes) if at least 100 keys changed # save 60 10000 After 60 seconds if at least 10000 keys changed 2.1.1、触发条件 自动触发（全部是BGSAVE）
...</p></div><footer class=entry-footer><span title='2022-04-09 23:39:41 +0000 UTC'>2022-04-09</span>&nbsp;·&nbsp;403 words&nbsp;·&nbsp;lu</footer><a class=entry-link aria-label="post link to Redis持久化" href=https://ethereal-lu.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Redis基础</h2></header><div class=entry-content><p>概述 Redis是什么？
Redis（Remote Dictionary Server )，即远程字典服务！
Redis能干吗？ —》 数据库、缓存、中间件
内存存储、持久化（rdb、aof） 效率高，可用于缓存 发布订阅系统 地图信息分析 计时器、计数器 。。。 Redis 通过“Redis序列化协议”（简称“RESP”），实现客户端与服务端之间的连接通信，其底层是通过TCP来完成的。
Linux安装配置redis 下载并解压redis后，将解压好的包移动到/usr/local/redis中，然后cd /usr/local/redis，依次在该目录下执行make，make test（也可以不执行）和make install。之后将该目录下的redis.conf备份，再vim redis.conf，将daemonize的值从no改为yes。cd /usr/local/bin，执行redis-server ../redis/redis.conf。配置完成。
redis 是单线程 对Redis来说，执行get、set以及eval等API，都是一个一个的任务，这些任务都会由Redis的线程（单线程）去负责执行，任务要么执行成功，要么执行失败，这就是Redis的命令是原子性的原因。
redis 6 引入了多线程 redis 5 及之前的版本一直使用的是单线程，多线程是 Redis6.0 推出的一个新特性。 Redis 的核心线程负责网络 IO ，命令处理以及写数据到缓冲，而随着网络硬件的性能提升，单个主线程处理⽹络请求的速度跟不上底层⽹络硬件的速度，导致网络 IO 的处理成为了 Redis 的性能瓶颈。
而 Redis6.0 就是从单线程处理网络请求到多线程处理，通过多个 IO 线程并⾏处理网络操作提升实例的整体处理性能。需要注意的是对于读写命令，Redis 仍然使⽤单线程来处理，这是因为继续使⽤单线程执行命令操作，就不⽤为了保证 Lua 脚本、事务的原⼦性，额外开发多线程互斥机制了。
redis 将所有的数据都放在内存中。单线程避免切换上下文，所以快。
多线程开发中并发访问控制是⼀个难点，需要精细的设计才能处理。如果只是简单地处理，比如简单地采⽤⼀个粗粒度互斥锁，只会出现不理想的结果。即便增加了线程，系统吞吐率也不会随着线程的增加而增加，因为大部分线程还在等待获取访问共享资源的互斥锁。而且，大部分采用多线程开发引入的同步原语保护共享资源的并发访问，也会降低系统代码的易调试性和可维护性。而正是以上这些问题，才让 Redis 采⽤了单线程模式。
官方解释：因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦)。
基础知识 redis所有命令不区分大小写
数据库基本命令 redis默认有16个数据库（0~15），默认使用第0个数据库。数据库之间数据相互隔离
127.0.0.1:6379> SELECT 3 # 切换数据库 OK 127.0.0.1:6379[3]> DBSIZE # 查看当前数据库大小 (integer) 0 127.0.0.1:6379> FLUSHDB # 清空当前数据库 OK 127.0.0.1:6379> FLUSHALL # 清空所有数据库 OK 127.0.0.1:6379> SHUTDOWN # 关闭redis服务 Redis-key基本命令 127.0.0.1:6379> set age 18 # 添加键值对 OK 127.0.0.1:6379> get name # 通过key获取value "xunlu" 127.0.0.1:6379> KEYS * # KEYS + 正则表达式。返回所有符合正则表达式的键 1) "age" 2) "name" 127.0.0.1:6379> EXISTS name # 判断是否存在指定的key (integer) 1 # 返回1则存在，0则不存在 127.0.0.1:6379> EXPIRE name 10 # 设置键name的有效期为10秒 (integer) 1 127.0.0.1:6379> ttl name # 查看键name的有效时间还剩下多少 (integer) 4 127.0.0.1:6379> MOVE name 1 # 将键值对移动到指定的数据库中 (integer) 1 127.0.0.1:6379> DEL name # 删除键值对 (integer) 1 127.0.0.1:6379> TYPE age # 获取当前键对应值的类型 string 数据类型 五种基本数据类型 String —> 应用：计数器（如访问量，点赞数等） 127.0.0.1:6379> set name xunlu OK 127.0.0.1:6379> APPEND name feilu # 追加字符串，类似StringBuilder的append (integer) 10 # 若追加的键不存在，则新建键值对 127.0.0.1:6379> get name "xunlufeilu" ----------------------------------------------- 127.0.0.1:6379> STRLEN name # 返回值的长度 (integer) 10 ----------------------------------------------- 127.0.0.1:6379> set views 0 OK 127.0.0.1:6379> INCR views # 每执行一次，值就会加1.（只能作用于integer类型） (integer) 1 127.0.0.1:6379> INCR views (integer) 2 127.0.0.1:6379> DECR views # 每执行一次，值就会减1.（只能作用于integer类型） (integer) 1 127.0.0.1:6379> INCRBY views 10 # 指定增加的步长 (integer) 11 127.0.0.1:6379> DECRBY views 10 # 指定减少的步长 (integer) 1 ----------------------------------------------- 127.0.0.1:6379> set name xunlu OK 127.0.0.1:6379> GETRANGE name 0 2 # 截取部分值（start和end都包括在内） "xun" 127.0.0.1:6379> GETRANGE name 0 -1 # == get name "xunlu" 127.0.0.1:6379> SETRANGE name 0 gao # 替换部分字符，起始替换位置 + 替换的值 (integer) 5 127.0.0.1:6379> get name "gaolu" ----------------------------------------------- # setex(set with expire) 【原子性操作】 # setnx(set if not exist) 【原子性操作】 127.0.0.1:6379> setex name 30 xunlu # 新建键值对，并设置有效期为30秒 OK # 等同于 set name xunlu ex 30 127.0.0.1:6379> setnx gender male # nx表示键不存在时才能正确执行，即只能新建 OK # 等同于 set gender male nx # 常用于分布式锁 127.0.0.1:6379> get gender "male" 127.0.0.1:6379> set gender female nx # 此时键gender已经存在，执行失败 (nil) ----------------------------------------------- 127.0.0.1:6379> MSET k1 v1 k2 v1 k3 v1 # 批量创建键值对 OK 127.0.0.1:6379> KEYS * 1) "k1" # msetnx 【原子性操作】 2) "k3" 3) "k2" 127.0.0.1:6379> MGET k1 k2 k3 # 批量获取 1) "v1" 2) "v1" 3) "v1" ------------------------------------------------ 127.0.0.1:6379> set user {id:1,name:xunlu,age:3} # 可以将值设为json字符串，然后通过json解析 OK 127.0.0.1:6379> mset user:name xunlu user:age 18 # redis支持键中存在`:`冒号，亦可用于解析 OK ------------------------------------------------ 127.0.0.1:6379> getset db redis # 先get再set。没有返回nil，再设新值 (nil) 127.0.0.1:6379> getset db redis # 有则返回旧值，再设新值 "redis" List（双向链表） 绝大部分的list命令都以l开头，list的名字也可作为key，故有些redis-key的命令也可用 应用：消息队列、栈 # 添加、范围读取 LPUSH key element [element ...] # key为列表的名字，添加到列表的头部 RPUSH key element [element ...] # 添加到列表的尾部 127.0.0.1:6379> LPUSH list mid # 列表名为list，head、mid、tail为元素 (integer) 1 127.0.0.1:6379> LPUSH list head (integer) 2 127.0.0.1:6379> RPUSH list tail (integer) 3 127.0.0.1:6379> LRANGE list 0 -1 1) "head" 2) "mid" 3) "tail" 127.0.0.1:6379> LRANGE list 0 1 # 从头向尾读，没有RRANGE这个命令 1) "head" 2) "mid" -------------------------------------------------- # 删除、改变list LPOP key [count] # 从头部弹出元素 RPOP key [count] # 从尾部弹出元素 LREM key count element # 根据值移除元素，count表示从多个相同的值中移除的个数 LTRIM key start stop # 将列表截断，只保留[start ~ stop]的值 -------------------------------------------------- # 按下标索引 127.0.0.1:6379> LINDEX list 0 # 获取list的第i个值 "head" 127.0.0.1:6379> LINDEX list 1 "mid" -------------------------------------------------- # 长度 127.0.0.1:6379> LLEN list # 获取list的长度 (integer) 3 -------------------------------------------------- # 组合命令 RPOPLPUSH source destination # 从容器source的尾部弹出并添加到容器destination的头部 "tail" # source和destination自然可以是同一个列表 ------------------------------------------------- # 修改列表中的值 LSET key index element # 修改列表指定下标处的值 127.0.0.1:6379> LSET list 0 prehead OK ------------------------------------------------- # 插值 LINSERT key BEFORE|AFTER pivot element # pivot为列表中已有的元素，往列表中元素的前或后插入元素 Set（无序不重复）（命令都以s打头） # 添加、查看 SADD key member [member ...] # 添加元素（可以批量） 127.0.0.1:6379> SADD set first second third (integer) 3 127.0.0.1:6379> SMEMBERS set # 查看所有元素 1) "second" 2) "third" 3) "first" 127.0.0.1:6379> SISMEMBER set first # 判断是否包含指定元素 (integer) 1 127.0.0.1:6379> SISMEMBER set fifth (integer) 0 127.0.0.1:6379> SCARD set # 集合的长度 (integer) 3 ------------------------------------------------- # 移除 SREM key member [member ...] # 删除指定元素（可以批量） SPOP key [count] # 随机删除元素（可以指定个数） SMOVE source destination member # 将指定元素从集合source移动到集合destination ------------------------------------------------- SRANDMEMBER key [count] # 随机返回元素（可以指定个数） ------------------------------------------------- # 集合计算 # 差集 SDIFF set1 set2 # 集合set1中有但set2中没有的元素 # 交集 SINTER set1 set2 # 交 # 并集 SUNION set1 set2 # 并 Hash（命令都以h打头） 相当于map，则变为key-(key-value)，故（更适合对象的存储） # 添加 HSET key field value [field value ...] # 存值，key为hash容器的名字 HMSET key field value [field value ...] # 批量存值 127.0.0.1:6379> HSET hash name xunlu (integer) 1 127.0.0.1:6379> HSET hash age 18 (integer) 1 ------------------------------------------------- # 查看 HGET key field # 指定字段的取值 HMGET key field [field ...] # 批量取值 127.0.0.1:6379> HGET hash name "xunlu" 127.0.0.1:6379> HGETALL hash # 查看全部内容 1) "name" 2) "xunlu" 3) "age" 4) "18" ------------------------------------------------- # 删除 HDEL key field [field ...] # 删除指定元素（可批量） ------------------------------------------------- # 长度 127.0.0.1:6379> HLEN hash (integer) 2 ------------------------------------------------- # 是否存在 HEXISTS key field # 判断指定字段是否存在 ------------------------------------------------- 127.0.0.1:6379> HKEYS hash # 取全部字段名 1) "name" 2) "age" 127.0.0.1:6379> HVALS hash # 取全部字段的值 1) "xunlu" 2) "18" ------------------------------------------------- # 自增、自减 HINCRBY key field increment # field = field + increment （increment为负数即为减） ------------------------------------------------- HSETNX key field value # 和setnx作用类似 Zset（有序集合）【底层为跳表】 # 添加、查看 ZADD key score member [score member ...] # score用于排序 127.0.0.1:6379> ZADD salary 2500 mary 3000 alice 1000 lisa (integer) 3 ZRANGE salary 0 -1 # 返回所有数据 -------------------------------------------------- # 排序 ZRANGE salary 100 0 byscore rev withscores # ZRANGE 后可跟上多个参数来约束比较，如通过score、降序、带上score ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count] # 小到大 ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count] # 大到小 127.0.0.1:6379> ZRANGEBYSCORE salary -inf +inf # 返回score在-inf +inf之间元素的排序，小到大 1) "lisa" 2) "mary" 3) "alice" -------------------------------------------------- # 移除 ZREM key member [member ...] -------------------------------------------------- # 长度 127.0.0.1:6379> ZCARD salary # 总个数 (integer) 3 127.0.0.1:6379> zcount salary 2000 3000 # 指定区间个数（score的区间） (integer) 2 三种特殊数据类型 Geospatial 地理位置 【底层由Zset实现、因此可以使用zset的命令，如ZREM等】 # 添加城市及经纬度信息 GEOADD key [NX|XX] [CH] longitude latitude member [longitude latitude member ...] 127.0.0.1:6379> GEOADD china:city 116.40 39.90 beijing # 经度、纬度 (integer) 1 127.0.0.1:6379> GEOADD china:city 121.47 31.23 shanghai (integer) 1 127.0.0.1:6379> type china:city # 底层由Zset实现 zset ------------------------------------------------------------ # 获取指定城市的经纬度信息 GEOPOS key member [member ...] 127.0.0.1:6379> GEOPOS china:city beijing 1) 1) "116.39999896287918091" 2) "39.90000009167092543" ------------------------------------------------------------- # 获取两地的距离（直线距离） GEODIST key member1 member2 [m|km|ft|mi] # 可指定单位，默认为米 127.0.0.1:6379> GEODIST china:city beijing shanghai km "1067.3788" ------------------------------------------------------------- # 获取范围内的元素 GEORADIUS key longitude latitude radius m|km|ft|mi # 根据指定经纬度和半径获取范围内的元素 127.0.0.1:6379> GEORADIUS china:city 120 30 500 km # 经度、维度、半径 1) "hangzhou" 2) "shanghai" GEORADIUSBYMEMBER key member radius m|km|ft|mi # 根据元素名和半径获取范围内的元素 Hypeloglog（基数统计、即去重后计数）【占用内存很小，最大只需要12KB】（有0.81%错误率）— 使用伯努利概率分布，根据第一个 1 出现的位置推测有多少基数。 PFADD key element [element ...] # 添加 PFCOUNT key [key ...] # 基数统计 127.0.0.1:6379> pfadd key a a a a l k j h j k l d (integer) 1 127.0.0.1:6379> PFCOUNT key (integer) 6 PFMERGE destkey sourcekey [sourcekey ...] # 合并 Bitmaps（位图） 位存储、只有两种状态的都可以用它存储 SETBIT key offset value # 添加，其中value的值只能是 0 或 1 GETBIT key offset # 查看 BITCOUNT key [start end] # 统计value为 1 的个数 发布订阅 基于频道 基于频道(Channel)的发布/订阅有两个命令分别是 publish 和 subscribe 。
...</p></div><footer class=entry-footer><span title='2022-04-01 17:39:41 +0000 UTC'>2022-04-01</span>&nbsp;·&nbsp;1606 words&nbsp;·&nbsp;lu</footer><a class=entry-link aria-label="post link to Redis基础" href=https://ethereal-lu.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/redis%E7%AC%94%E8%AE%B0/></a></article></main><footer class=footer><span>&copy; 2025 <a href=https://ethereal-lu.github.io/>lu</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>