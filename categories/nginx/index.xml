<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Nginx on lu</title>
    <link>http://localhost:1313/categories/nginx/</link>
    <description>Recent content in Nginx on lu</description>
    <generator>Hugo -- 0.140.1</generator>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 30 May 2022 22:42:15 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/nginx/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Nginx基础</title>
      <link>http://localhost:1313/posts/%E5%88%86%E5%B8%83%E5%BC%8F/nginx/nginx%E5%9F%BA%E7%A1%80/</link>
      <pubDate>Mon, 30 May 2022 22:42:15 +0000</pubDate>
      <guid>http://localhost:1313/posts/%E5%88%86%E5%B8%83%E5%BC%8F/nginx/nginx%E5%9F%BA%E7%A1%80/</guid>
      <description>&lt;p&gt;Tomcat 稳定但不支持高并发，因此支持高并发的 Nginx 诞生了。Nginx使用基于事件驱动架构，使其可以支持数以百万级别的TCP连接。&lt;/p&gt;
&lt;h2 id=&#34;1nginx-应用场景&#34;&gt;1、Nginx 应用场景&lt;/h2&gt;
&lt;p&gt;Nginx是一款高性能的HTTP服务器和反向代理服务器。Nginx 最常用的应用场景就是这两个。&lt;/p&gt;
&lt;h3 id=&#34;11反向代理&#34;&gt;1.1、反向代理&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;正向代理&lt;/strong&gt;，&amp;ldquo;它代理的是客户端，代客户端发出请求&amp;rdquo;，是一个位于客户端和原始服务器之间的中间服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;反向代理&lt;/strong&gt;，&amp;ldquo;它代理的是服务端，代服务端接收请求&amp;rdquo;，主要用于服务器集群分布式部署的情况下，反向代理隐藏了服务器的信息。Nginx 作为服务端暴露的地址，所有客户端的请求都会进入 Nginx 服务器，然后由 Nginx 按照一定的规则将请求分发给具体的业务处理服务器，客户端并不知道是哪台服务器为自己服务，这里Nginx 扮演的就是反向代理服务器。&lt;/p&gt;
&lt;p&gt;反向代理的作用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;保证内网的安全，通常将反向代理作为公网访问地址，Web服务器是内网&lt;/li&gt;
&lt;li&gt;负载均衡，通过反向代理服务器来优化网站的负载&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;负载均衡&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上方提到的请求分发就是依据这里的负载均衡策略分发的。&lt;/p&gt;
&lt;p&gt;负载均衡分为硬件负载均衡和软件负载均衡两种，硬件如F5负载均衡，相对造价昂贵成本较高，但是数据的稳定性安全性高；除了移动联通等运营商使用的都是软件负载均衡，软件负载均衡是利用现有的技术结合主机硬件实现的一种消息队列分发机制。&lt;/p&gt;
&lt;p&gt;Nginx支持的负载均衡调度算法如下：&lt;strong&gt;重点掌握权重轮询即可，其余的基本不用。但作为面试还是要能说出来。&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;权重轮询(默认）：接收到的请求按照权重分配到不同的后端服务器，可以根据服务器的硬件性能配置不同的权重，权重越大被分配到请求的几率越大。&lt;/li&gt;
&lt;li&gt;ip_hash：每个请求按照发起客户端的ip的hash结果进行匹配，对于一个固定ip地址的客户端总会访问到同一个后端服务器，这也在一定程度上解决了集群部署环境下session共享的问题。但是移动端的ip可能一直变化，所以较为鸡肋。&lt;/li&gt;
&lt;li&gt;fair：智能调整调度算法，动态的根据后端服务器的响应时长进行均衡分配，响应时间短处理效率高的服务器分配到请求的概率高。Nginx默认不支持fair算法，需要安装upstream_fair模块。可能造成流量倾斜，大量请求进入响应时长短的服务器导致崩溃。&lt;/li&gt;
&lt;li&gt;url_hash：按照访问的url的hash结果分配请求，每个请求的url会指向后端固定的某个服务器，可以在Nginx作为静态服务器的情况下提高缓存效率。同样要注意Nginx默认不支持这种调度算法，要使用的话需要安装Nginx的hash软件包。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;12web-服务器&#34;&gt;1.2、web 服务器&lt;/h3&gt;
&lt;p&gt;可以先通过动态/静态内容分离，而后为静态内容（html/css/js/图片等）提供HTTP访问功能；而动态内容可以整合代理模块，代理给上游服务器，来支持对外部程序的直接调用或者解析。&lt;/p&gt;
&lt;h2 id=&#34;2nginx-基本架构&#34;&gt;2、Nginx 基本架构&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;一个master进程生成多个worker子进程（每个进程只有一个线程），一个worker进程可以响应多个用户请求；&lt;/li&gt;
&lt;li&gt;非阻塞、IO复用、事件驱动：select，poll， epoll， kqueue，/dev/poll；&lt;/li&gt;
&lt;li&gt;支持sendfile，sendfile64；&lt;/li&gt;
&lt;li&gt;支持文件AIO（异步I/O）；&lt;/li&gt;
&lt;li&gt;支持mmap；&lt;/li&gt;
&lt;li&gt;灵活的文件配置；&lt;/li&gt;
&lt;li&gt;占用内存小：10,000个非活动HTTP保持连接占用大约2.5M内存。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;3nginx-并发模型&#34;&gt;3、Nginx 并发模型&lt;/h2&gt;
&lt;p&gt;一个master进程生成多个worker子进程（每个进程只有一个线程），一个worker响应多个用户请求。如果单进程启动：仅有一个进程，既充当master进程的角色，也充当worker进程的角色。&lt;/p&gt;
&lt;h3 id=&#34;31master进程&#34;&gt;3.1、master进程&lt;/h3&gt;
&lt;p&gt;充当整个进程组与用户的交互接口（接收来自外界的信号，向各worker进程发送信号），同时监控worker进程的运行状态。&lt;/p&gt;
&lt;p&gt;它不需要处理网络事件，不负责业务的执行，只会通过管理worker进程来实现重启服务、平滑升级、更换日志文件、配置文件实时生效等功能。&lt;/p&gt;
&lt;h3 id=&#34;32worker进程&#34;&gt;3.2、worker进程&lt;/h3&gt;
&lt;p&gt;主要任务是处理基本的网络事件，完成具体的任务逻辑。多个worker进程之间是对等的，互相独立的。&lt;/p&gt;
&lt;p&gt;worker进程主要关注点是与客户端或后端服务器（此时nginx作为中间代理）之间的数据可读/可写等I/O交互事件，所以工作进程的阻塞点是在像select()、epoll_wait()等这样的I/O多路复用函数调用处，以等待发生数据可读/写事件。当然也可能被新收到的进程信号中断。&lt;/p&gt;
&lt;p&gt;worker进程个数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果负载以CPU密集型应用为主，一般会设置与机器cpu核数一致或少一个（用来处理用户等其他任务）；&lt;/li&gt;
&lt;li&gt;如果负载以IO密集型为主，如响应大量内容给客户端，则worker数应该为CPU个数的1.5或2倍。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因为更多的worker数，只会导致进程来竞争cpu资源了，从而带来不必要的上下文切换。而且，nginx为了更好的利用多核特性，具有cpu绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效。&lt;/p&gt;
&lt;h3 id=&#34;33并发处理&#34;&gt;3.3、并发处理&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;在master进程里面，先创建socket，并bind、listen在80端口（所以master进程需要root权限）；&lt;/li&gt;
&lt;li&gt;然后再fork出多个worker进程，这样每个worker进程都可以去accept这个socket（会产生惊群问题）， 或者使用锁机制，让抢到锁的一个worker进程去accept这个socket，注意这里一般使用select/poll/epoll机制来解决accept阻塞问题；&lt;/li&gt;
&lt;li&gt;当一个新连接进来后，而只有抢到锁的一个进程可以accept这个连接进行处理（也是放入epoll中）；&lt;/li&gt;
&lt;li&gt;抢到锁的worker进程accept到新连接后，会立即释放锁；然后所有worker进程再次参与抢锁，这样就回到了第二步，进行循环处理并发连接；&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;34惊群问题&#34;&gt;3.4、惊群问题&lt;/h3&gt;
&lt;p&gt;产生原因：像上面第二步，多个worker进程等待同一个socket的连接事件，当这个事件发生时，这些进程被同时唤醒，就是惊群。&lt;/p&gt;
&lt;p&gt;注意，在linux2.6内核上，accept系统调用已经不存在惊群，但用epoll机制来解决accept阻塞问题，epoll_wait会有惊群问题（新增 EPOLLEXCLUSIVE 选项解决了）。&lt;/p&gt;
&lt;p&gt;导致后果：许多worker进程被内核重新调度唤醒，只有一个进程可以accept这个连接进行处理，其他余者皆失败，导致性能浪费。&lt;/p&gt;
&lt;p&gt;nginx解决方案：使用锁机制，让抢到锁的一个worker进程去accept（epoll_wait）这个socket；如果操作系统支持原子整型，才会使用共享内存实现原子上锁，否则使用文件上锁。&lt;/p&gt;
&lt;h2 id=&#34;4nginx-配置&#34;&gt;4、Nginx 配置&lt;/h2&gt;
&lt;h3 id=&#34;41默认配置文件&#34;&gt;4.1、默认配置文件&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;/etc/nginx/nginx.conf&lt;/code&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
